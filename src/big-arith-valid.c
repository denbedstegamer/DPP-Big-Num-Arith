// Generated by Futhark 0.26.0 (prerelease - include info below when reporting bugs)
// git: 99000a627b4b21dd77a9325557157eb0ae291bce

// We need to define _GNU_SOURCE before
// _any_ headers files are imported to get
// the usage statistics of a thread (i.e. have RUSAGE_THREAD) on GNU/Linux
// https://manpages.courier-mta.org/htmlman2/getrusage.2.html
#ifndef _GNU_SOURCE // Avoid possible double-definition warning.
#define _GNU_SOURCE
#endif

#ifdef __clang__
#pragma clang diagnostic ignored "-Wunused-function"
#pragma clang diagnostic ignored "-Wunused-variable"
#pragma clang diagnostic ignored "-Wunused-const-variable"
#pragma clang diagnostic ignored "-Wparentheses"
#pragma clang diagnostic ignored "-Wunused-label"
#pragma clang diagnostic ignored "-Wunused-but-set-variable"
#elif __GNUC__
#pragma GCC diagnostic ignored "-Wunused-function"
#pragma GCC diagnostic ignored "-Wunused-variable"
#pragma GCC diagnostic ignored "-Wunused-const-variable"
#pragma GCC diagnostic ignored "-Wparentheses"
#pragma GCC diagnostic ignored "-Wunused-label"
#pragma GCC diagnostic ignored "-Wunused-but-set-variable"
#endif

// Headers
#include <stdint.h>
#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <float.h>

#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>

#ifdef __cplusplus
extern "C" {
#endif

// Initialisation
struct futhark_context_config;
struct futhark_context_config *futhark_context_config_new(void);
void futhark_context_config_free(struct futhark_context_config *cfg);
int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg, const char *param_name, size_t new_value);
struct futhark_context;
struct futhark_context *futhark_context_new(struct futhark_context_config *cfg);
void futhark_context_free(struct futhark_context *cfg);
void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt);
void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s);
const char *futhark_context_config_get_program(struct futhark_context_config *cfg);
void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *s);
void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size);
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag);
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag);
int futhark_get_tuning_param_count(void);
const char *futhark_get_tuning_param_name(int);
const char *futhark_get_tuning_param_class(int);

// Arrays
struct futhark_i64_1d;
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0);
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t offset, int64_t dim0);
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data);
CUdeviceptr futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr);
struct futhark_u64_1d;
struct futhark_u64_1d *futhark_new_u64_1d(struct futhark_context *ctx, const uint64_t *data, int64_t dim0);
struct futhark_u64_1d *futhark_new_raw_u64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t offset, int64_t dim0);
int futhark_free_u64_1d(struct futhark_context *ctx, struct futhark_u64_1d *arr);
int futhark_values_u64_1d(struct futhark_context *ctx, struct futhark_u64_1d *arr, uint64_t *data);
CUdeviceptr futhark_values_raw_u64_1d(struct futhark_context *ctx, struct futhark_u64_1d *arr);
const int64_t *futhark_shape_u64_1d(struct futhark_context *ctx, struct futhark_u64_1d *arr);

// Opaque values



// Entry points
int futhark_entry_big_add_debug(struct futhark_context *ctx, struct futhark_u64_1d **out0, struct futhark_u64_1d **out1, struct futhark_i64_1d **out2, const struct futhark_u64_1d *in0, const struct futhark_u64_1d *in1, const struct futhark_u64_1d *in2);
int futhark_entry_big_add_validation(struct futhark_context *ctx, bool *out0, const struct futhark_u64_1d *in0, const struct futhark_u64_1d *in1, const struct futhark_u64_1d *in2);
int futhark_entry_big_mul_debug(struct futhark_context *ctx, struct futhark_u64_1d **out0, struct futhark_u64_1d **out1, struct futhark_i64_1d **out2, const struct futhark_u64_1d *in0, const struct futhark_u64_1d *in1, const struct futhark_u64_1d *in2);
int futhark_entry_big_mul_validation(struct futhark_context *ctx, bool *out0, const struct futhark_u64_1d *in0, const struct futhark_u64_1d *in1, const struct futhark_u64_1d *in2);

// Miscellaneous
int futhark_context_sync(struct futhark_context *ctx);
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f);
char *futhark_context_report(struct futhark_context *ctx);
char *futhark_context_get_error(struct futhark_context *ctx);
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f);
void futhark_context_pause_profiling(struct futhark_context *ctx);
void futhark_context_unpause_profiling(struct futhark_context *ctx);
int futhark_context_clear_caches(struct futhark_context *ctx);
#define FUTHARK_BACKEND_cuda
#define FUTHARK_SUCCESS 0
#define FUTHARK_PROGRAM_ERROR 2
#define FUTHARK_OUT_OF_MEMORY 3

#ifdef __cplusplus
}
#endif

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <math.h>
#include <stdint.h>
// If NDEBUG is set, the assert() macro will do nothing. Since Futhark
// (unfortunately) makes use of assert() for error detection (and even some
// side effects), we want to avoid that.
#undef NDEBUG
#include <assert.h>
#include <stdarg.h>
#define SCALAR_FUN_ATTR static inline
// Start of util.h.
//
// Various helper functions that are useful in all generated C code.

#include <errno.h>
#include <string.h>

static const char *fut_progname = "(embedded Futhark)";

static void futhark_panic(int eval, const char *fmt, ...) __attribute__((noreturn));
static char* msgprintf(const char *s, ...);
static void* slurp_file(const char *filename, size_t *size);
static int dump_file(const char *file, const void *buf, size_t n);
struct str_builder;
static void str_builder_init(struct str_builder *b);
static void str_builder(struct str_builder *b, const char *s, ...);
static char *strclone(const char *str);

static void futhark_panic(int eval, const char *fmt, ...) {
  va_list ap;
  va_start(ap, fmt);
  fprintf(stderr, "%s: ", fut_progname);
  vfprintf(stderr, fmt, ap);
  va_end(ap);
  exit(eval);
}

// For generating arbitrary-sized error messages.  It is the callers
// responsibility to free the buffer at some point.
static char* msgprintf(const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = 1 + (size_t)vsnprintf(NULL, 0, s, vl);
  char *buffer = (char*) malloc(needed);
  va_start(vl, s); // Must re-init.
  vsnprintf(buffer, needed, s, vl);
  return buffer;
}

static inline void check_err(int errval, int sets_errno, const char *fun, int line,
                             const char *msg, ...) {
  if (errval) {
    char errnum[10];

    va_list vl;
    va_start(vl, msg);

    fprintf(stderr, "ERROR: ");
    vfprintf(stderr, msg, vl);
    fprintf(stderr, " in %s() at line %d with error code %s\n",
            fun, line,
            sets_errno ? strerror(errno) : errnum);
    exit(errval);
  }
}

#define CHECK_ERR(err, ...) check_err(err, 0, __func__, __LINE__, __VA_ARGS__)
#define CHECK_ERRNO(err, ...) check_err(err, 1, __func__, __LINE__, __VA_ARGS__)

// Read the rest of an open file into a NUL-terminated string; returns
// NULL on error.
static void* fslurp_file(FILE *f, size_t *size) {
  long start = ftell(f);
  fseek(f, 0, SEEK_END);
  long src_size = ftell(f)-start;
  fseek(f, start, SEEK_SET);
  unsigned char *s = (unsigned char*) malloc((size_t)src_size + 1);
  if (fread(s, 1, (size_t)src_size, f) != (size_t)src_size) {
    free(s);
    s = NULL;
  } else {
    s[src_size] = '\0';
  }

  if (size) {
    *size = (size_t)src_size;
  }

  return s;
}

// Read a file into a NUL-terminated string; returns NULL on error.
static void* slurp_file(const char *filename, size_t *size) {
  FILE *f = fopen(filename, "rb"); // To avoid Windows messing with linebreaks.
  if (f == NULL) return NULL;
  unsigned char *s = fslurp_file(f, size);
  fclose(f);
  return s;
}

// Dump 'n' bytes from 'buf' into the file at the designated location.
// Returns 0 on success.
static int dump_file(const char *file, const void *buf, size_t n) {
  FILE *f = fopen(file, "w");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(buf, sizeof(char), n, f) != n) {
    return 1;
  }

  if (fclose(f) != 0) {
    return 1;
  }

  return 0;
}

struct str_builder {
  char *str;
  size_t capacity; // Size of buffer.
  size_t used; // Bytes used, *not* including final zero.
};

static void str_builder_init(struct str_builder *b) {
  b->capacity = 10;
  b->used = 0;
  b->str = malloc(b->capacity);
  b->str[0] = 0;
}

static void str_builder(struct str_builder *b, const char *s, ...) {
  va_list vl;
  va_start(vl, s);
  size_t needed = (size_t)vsnprintf(NULL, 0, s, vl);

  while (b->capacity < b->used + needed + 1) {
    b->capacity *= 2;
    b->str = realloc(b->str, b->capacity);
  }

  va_start(vl, s); // Must re-init.
  vsnprintf(b->str+b->used, b->capacity-b->used, s, vl);
  b->used += needed;
}

struct cost_centre {
  const char *name;
  int64_t runs;
  int64_t runtime;
};

// Dynamic dictionary for tallying cost centres when aggregating
// profiling information.  Not performance-critical.
struct cost_centres {
  size_t capacity;
  size_t used;
  struct cost_centre* centres;
};

static struct cost_centres *cost_centres_new() {
  struct cost_centres *ccs = malloc(sizeof(struct cost_centres));
  ccs->capacity = 100;
  ccs->used = 0;
  ccs->centres = calloc(ccs->capacity, sizeof(struct cost_centre));
  return ccs;
}

static void cost_centres_free(struct cost_centres* ccs) {
  free(ccs->centres);
  free(ccs);
}

static void cost_centres_init(struct cost_centres* ccs, const char *name) {
  if (ccs->used == ccs->capacity) {
    ccs->capacity *= 2;
    ccs->centres = realloc(ccs->centres, ccs->capacity*sizeof(struct cost_centre));
  }
  ccs->centres[ccs->used].name = name;
  ccs->centres[ccs->used].runs = 0;
  ccs->centres[ccs->used].runtime = 0;
  ccs->used++;
}

static void cost_centres_add(struct cost_centres* ccs, struct cost_centre c) {
  size_t i = 0;
  for (i = 0; i < ccs->used; i++) {
    if (strcmp(c.name, ccs->centres[i].name) == 0) {
      ccs->centres[i].runs += c.runs;
      ccs->centres[i].runtime += c.runtime;
      return;
    }
  }
  if (i == ccs->capacity) {
    ccs->capacity *= 2;
    ccs->centres = realloc(ccs->centres, ccs->capacity*sizeof(struct cost_centre));
  }
  ccs->centres[i] = c;
  ccs->used++;
}

static void cost_centre_report(struct cost_centres* ccs, struct str_builder *b) {
  int64_t total_runs = 0;
  int64_t total_runtime = 0;
  for (size_t i = 0; i < ccs->used; i++) {
    struct cost_centre c = ccs->centres[i];
    str_builder(b,
                "%-40s ran %5d times; avg %8ldus; total: %8ldus\n",
                c.name,
                c.runs, c.runs == 0 ? 0 : c.runtime/c.runs, c.runtime);
    total_runs += c.runs;
    total_runtime += c.runtime;
  }
  str_builder(b,
              "%d operations with cumulative runtime: %6ldus\n",
              total_runs, total_runtime);
}

static char *strclone(const char *str) {
  size_t size = strlen(str) + 1;
  char *copy = (char*) malloc(size);
  if (copy == NULL) {
    return NULL;
  }

  memcpy(copy, str, size);
  return copy;
}

// Assumes NULL-terminated.
static char *strconcat(const char *src_fragments[]) {
  size_t src_len = 0;
  const char **p;

  for (p = src_fragments; *p; p++) {
    src_len += strlen(*p);
  }

  char *src = (char*) malloc(src_len + 1);
  size_t n = 0;
  for (p = src_fragments; *p; p++) {
    strcpy(src + n, *p);
    n += strlen(*p);
  }

  return src;
}

// End of util.h.
// Start of cache.h

#define CACHE_HASH_SIZE 8 // In 32-bit words.

struct cache_hash {
  uint32_t hash[CACHE_HASH_SIZE];
};

// Initialise a blank cache.
static void cache_hash_init(struct cache_hash *c);

// Hash some bytes and add them to the accumulated hash.
static void cache_hash(struct cache_hash *out, const char *in, size_t n);

// Try to restore cache contents from a file with the given name.
// Assumes the cache is invalid if it contains the given hash.
// Allocates memory and reads the cache conents, which is returned in
// *buf with size *buflen.  If the cache is successfully loaded, this
// function returns 0.  Otherwise it returns nonzero.  Errno is set if
// the failure to load the cache is due to anything except invalid
// cache conents.  Note that failing to restore the cache is not
// necessarily a problem: it might just be invalid or not created yet.
static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen);

// Store cache contents in the given file, with the given hash.
static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen);

// Now for the implementation.

static void cache_hash_init(struct cache_hash *c) {
  memset(c->hash, 0, CACHE_HASH_SIZE * sizeof(uint32_t));
}

static void cache_hash(struct cache_hash *out, const char *in, size_t n) {
  // Adaptation of djb2 for larger output size by storing intermediate
  // states.
  uint32_t hash = 5381;
  for (size_t i = 0; i < n; i++) {
    hash = ((hash << 5) + hash) + in[i];
    out->hash[i % CACHE_HASH_SIZE] ^= hash;
  }
}

#define CACHE_HEADER_SIZE 8
static const char cache_header[CACHE_HEADER_SIZE] = "FUTHARK\0";

static int cache_restore(const char *fname, const struct cache_hash *hash,
                         unsigned char **buf, size_t *buflen) {
  FILE *f = fopen(fname, "rb");

  if (f == NULL) {
    return 1;
  }

  char f_header[CACHE_HEADER_SIZE];

  if (fread(f_header, sizeof(char), CACHE_HEADER_SIZE, f) != CACHE_HEADER_SIZE) {
    goto error;
  }

  if (memcmp(f_header, cache_header, CACHE_HEADER_SIZE) != 0) {
    goto error;
  }

  if (fseek(f, 0, SEEK_END) != 0) {
    goto error;
  }
  int64_t f_size = (int64_t)ftell(f);
  if (fseek(f, CACHE_HEADER_SIZE, SEEK_SET) != 0) {
    goto error;
  }

  int64_t expected_size;

  if (fread(&expected_size, sizeof(int64_t), 1, f) != 1) {
    goto error;
  }

  if (f_size != expected_size) {
    errno = 0;
    goto error;
  }

  int32_t f_hash[CACHE_HASH_SIZE];

  if (fread(f_hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (memcmp(f_hash, hash->hash, CACHE_HASH_SIZE) != 0) {
    errno = 0;
    goto error;
  }

  *buflen = f_size - CACHE_HEADER_SIZE - sizeof(int64_t) - CACHE_HASH_SIZE*sizeof(int32_t);
  *buf = malloc(*buflen);
  if (fread(*buf, sizeof(char), *buflen, f) != *buflen) {
    free(*buf);
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

static int cache_store(const char *fname, const struct cache_hash *hash,
                       const unsigned char *buf, size_t buflen) {
  FILE *f = fopen(fname, "wb");

  if (f == NULL) {
    return 1;
  }

  if (fwrite(cache_header, CACHE_HEADER_SIZE, 1, f) != 1) {
    goto error;
  }

  int64_t size = CACHE_HEADER_SIZE + sizeof(int64_t) + CACHE_HASH_SIZE*sizeof(int32_t) + buflen;

  if (fwrite(&size, sizeof(size), 1, f) != 1) {
    goto error;
  }

  if (fwrite(hash->hash, sizeof(int32_t), CACHE_HASH_SIZE, f) != CACHE_HASH_SIZE) {
    goto error;
  }

  if (fwrite(buf, sizeof(unsigned char), buflen, f) != buflen) {
    goto error;
  }

  fclose(f);

  return 0;

 error:
  fclose(f);
  return 1;
}

// End of cache.h
// Start of half.h.

// Conversion functions are from http://half.sourceforge.net/, but
// translated to C.
//
// Copyright (c) 2012-2021 Christian Rau
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

#ifndef __OPENCL_VERSION__
#define __constant
#endif

__constant static const uint16_t base_table[512] = {
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,
  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,
  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,
  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,
  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,
  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,
  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,
  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };

__constant static const unsigned char shift_table[512] = {
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,
  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };

__constant static const uint32_t mantissa_table[2048] = {
  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,
  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,
  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,
  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,
  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,
  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,
  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,
  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,
  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,
  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B0000, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,
  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,
  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,
  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,
  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,
  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,
  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,
  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,
  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,
  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,
  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,
  0x37A00000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,
  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,
  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,
  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,
  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,
  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,
  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,
  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,
  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,
  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,
  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F28000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,
  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,
  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,
  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,
  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,
  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,
  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,
  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,
  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,
  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,
  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x38228000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,
  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,
  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,
  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,
  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,
  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,
  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,
  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,
  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,
  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,
  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384BC000,
  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,
  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,
  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,
  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,
  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,
  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,
  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,
  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,
  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,
  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,
  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,
  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,
  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,
  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,
  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,
  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,
  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,
  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,
  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,
  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,
  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x380F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,
  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,
  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,
  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,
  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,
  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,
  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,
  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,
  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,
  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,
  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x3823C000, 0x3823E000,
  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,
  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,
  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,
  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,
  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,
  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,
  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,
  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,
  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,
  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,
  0x38380000, 0x38382000, 0x38384000, 0x38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,
  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,
  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,
  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,
  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,
  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,
  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,
  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,
  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,
  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,
  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,
  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,
  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,
  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,
  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,
  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,
  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,
  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,
  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,
  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,
  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x3861A000, 0x3861C000, 0x3861E000,
  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,
  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,
  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,
  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,
  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,
  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,
  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,
  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,
  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,
  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,
  0x38760000, 0x38762000, 0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,
  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,
  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,
  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,
  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };
__constant static const uint32_t exponent_table[64] = {
  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,
  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,
  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,
  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };
__constant static const unsigned short offset_table[64] = {
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,
  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };

SCALAR_FUN_ATTR uint16_t float2halfbits(float value) {
  union { float x; uint32_t y; } u;
  u.x = value;
  uint32_t bits = u.y;

  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;

  return hbits;
}

SCALAR_FUN_ATTR float halfbits2float(uint16_t value) {
  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];

  union { uint32_t x; float y; } u;
  u.x = bits;
  return u.y;
}

SCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {
  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;
  if(fabs > 0x7C00 || tabs > 0x7C00) {
    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);
  }
  if(from == to || !(fabs|tabs)) {
    return to;
  }
  if(!fabs) {
    return (to&0x8000)+1;
  }
  unsigned int out =
    from +
    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)
    - 1;
  return out;
}

// End of half.h.
// Start of timing.h.

// The function get_wall_time() returns the wall time in microseconds
// (with an unspecified offset).

#ifdef _WIN32

#include <windows.h>

static int64_t get_wall_time(void) {
  LARGE_INTEGER time,freq;
  assert(QueryPerformanceFrequency(&freq));
  assert(QueryPerformanceCounter(&time));
  return ((double)time.QuadPart / freq.QuadPart) * 1000000;
}

#else
// Assuming POSIX

#include <time.h>
#include <sys/time.h>

static int64_t get_wall_time(void) {
  struct timeval time;
  assert(gettimeofday(&time,NULL) == 0);
  return time.tv_sec * 1000000 + time.tv_usec;
}

static int64_t get_wall_time_ns(void) {
  struct timespec time;
  assert(clock_gettime(CLOCK_REALTIME, &time) == 0);
  return time.tv_sec * 1000000000 + time.tv_nsec;
}

#endif

// End of timing.h.
// Start of lock.h.

// A very simple cross-platform implementation of locks.  Uses
// pthreads on Unix and some Windows thing there.  Futhark's
// host-level code is not multithreaded, but user code may be, so we
// need some mechanism for ensuring atomic access to API functions.
// This is that mechanism.  It is not exposed to user code at all, so
// we do not have to worry about name collisions.

#ifdef _WIN32

typedef HANDLE lock_t;

static void create_lock(lock_t *lock) {
  *lock = CreateMutex(NULL,  // Default security attributes.
                      FALSE, // Initially unlocked.
                      NULL); // Unnamed.
}

static void lock_lock(lock_t *lock) {
  assert(WaitForSingleObject(*lock, INFINITE) == WAIT_OBJECT_0);
}

static void lock_unlock(lock_t *lock) {
  assert(ReleaseMutex(*lock));
}

static void free_lock(lock_t *lock) {
  CloseHandle(*lock);
}

#else
// Assuming POSIX

#include <pthread.h>

typedef pthread_mutex_t lock_t;

static void create_lock(lock_t *lock) {
  int r = pthread_mutex_init(lock, NULL);
  assert(r == 0);
}

static void lock_lock(lock_t *lock) {
  int r = pthread_mutex_lock(lock);
  assert(r == 0);
}

static void lock_unlock(lock_t *lock) {
  int r = pthread_mutex_unlock(lock);
  assert(r == 0);
}

static void free_lock(lock_t *lock) {
  // Nothing to do for pthreads.
  (void)lock;
}

#endif

// End of lock.h.
// Start of free_list.h.

typedef uintptr_t fl_mem;

// An entry in the free list.  May be invalid, to avoid having to
// deallocate entries as soon as they are removed.  There is also a
// tag, to help with memory reuse.
struct free_list_entry {
  size_t size;
  fl_mem mem;
  const char *tag;
  unsigned char valid;
};

struct free_list {
  struct free_list_entry *entries; // Pointer to entries.
  int capacity;                    // Number of entries.
  int used;                        // Number of valid entries.
  lock_t lock;                     // Thread safety.
};

static void free_list_init(struct free_list *l) {
  l->capacity = 30; // Picked arbitrarily.
  l->used = 0;
  l->entries = (struct free_list_entry*) malloc(sizeof(struct free_list_entry) * l->capacity);
  for (int i = 0; i < l->capacity; i++) {
    l->entries[i].valid = 0;
  }
  create_lock(&l->lock);
}

// Remove invalid entries from the free list.
static void free_list_pack(struct free_list *l) {
  lock_lock(&l->lock);
  int p = 0;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[p] = l->entries[i];
      if (i > p) {
        l->entries[i].valid = 0;
      }
      p++;
    }
  }

  // Now p is the number of used elements.  We don't want it to go
  // less than the default capacity (although in practice it's OK as
  // long as it doesn't become 1).
  if (p < 30) {
    p = 30;
  }
  l->entries = realloc(l->entries, p * sizeof(struct free_list_entry));
  l->capacity = p;
  lock_unlock(&l->lock);
}

static void free_list_destroy(struct free_list *l) {
  assert(l->used == 0);
  free(l->entries);
  free_lock(&l->lock);
}

// Not part of the interface, so no locking.
static int free_list_find_invalid(struct free_list *l) {
  int i;
  for (i = 0; i < l->capacity; i++) {
    if (!l->entries[i].valid) {
      break;
    }
  }
  return i;
}

static void free_list_insert(struct free_list *l, size_t size, fl_mem mem, const char *tag) {
  lock_lock(&l->lock);
  int i = free_list_find_invalid(l);

  if (i == l->capacity) {
    // List is full; so we have to grow it.
    int new_capacity = l->capacity * 2 * sizeof(struct free_list_entry);
    l->entries = realloc(l->entries, new_capacity);
    for (int j = 0; j < l->capacity; j++) {
      l->entries[j+l->capacity].valid = 0;
    }
    l->capacity *= 2;
  }

  // Now 'i' points to the first invalid entry.
  l->entries[i].valid = 1;
  l->entries[i].size = size;
  l->entries[i].mem = mem;
  l->entries[i].tag = tag;

  l->used++;
  lock_unlock(&l->lock);
}

// Determine whether this entry in the free list is acceptable for
// satisfying the request.  Not public, so no locking.
static bool free_list_acceptable(size_t size, const char* tag, struct free_list_entry *entry) {
  // We check not just the hard requirement (is the entry acceptable
  // and big enough?) but also put a cap on how much wasted space
  // (internal fragmentation) we allow.  This is necessarily a
  // heuristic, and a crude one.

  if (!entry->valid) {
    return false;
  }

  if (size > entry->size) {
    return false;
  }

  // We know the block fits.  Now the question is whether it is too
  // big.  Our policy is as follows:
  //
  // 1) We don't care about wasted space below 4096 bytes (to avoid
  // churn in tiny allocations).
  //
  // 2) If the tag matches, we allow _any_ amount of wasted space.
  //
  // 3) Otherwise we allow up to 50% wasted space.

  if (entry->size < 4096) {
    return true;
  }

  if (entry->tag == tag) {
    return true;
  }

  if (entry->size < size * 2) {
    return true;
  }

  return false;
}

// Find and remove a memory block of the indicated tag, or if that
// does not exist, another memory block with exactly the desired size.
// Returns 0 on success.
static int free_list_find(struct free_list *l, size_t size, const char *tag,
                          size_t *size_out, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int size_match = -1;
  int i;
  int ret = 1;
  for (i = 0; i < l->capacity; i++) {
    if (free_list_acceptable(size, tag, &l->entries[i]) &&
        (size_match < 0 || l->entries[i].size < l->entries[size_match].size)) {
      // If this entry is valid, has sufficient size, and is smaller than the
      // best entry found so far, use this entry.
      size_match = i;
    }
  }

  if (size_match >= 0) {
    l->entries[size_match].valid = 0;
    *size_out = l->entries[size_match].size;
    *mem_out = l->entries[size_match].mem;
    l->used--;
    ret = 0;
  }
  lock_unlock(&l->lock);
  return ret;
}

// Remove the first block in the free list.  Returns 0 if a block was
// removed, and nonzero if the free list was already empty.
static int free_list_first(struct free_list *l, fl_mem *mem_out) {
  lock_lock(&l->lock);
  int ret = 1;
  for (int i = 0; i < l->capacity; i++) {
    if (l->entries[i].valid) {
      l->entries[i].valid = 0;
      *mem_out = l->entries[i].mem;
      l->used--;
      ret = 0;
      break;
    }
  }
  lock_unlock(&l->lock);
  return ret;
}

// End of free_list.h.
#include <getopt.h>
#include <ctype.h>
#include <inttypes.h>
#include <unistd.h>
// Start of values.h.

//// Text I/O

typedef int (*writer)(FILE*, const void*);
typedef int (*bin_reader)(void*);
typedef int (*str_reader)(const char *, void*);

struct array_reader {
  char* elems;
  int64_t n_elems_space;
  int64_t elem_size;
  int64_t n_elems_used;
  int64_t *shape;
  str_reader elem_reader;
};

static void skipspaces(FILE *f) {
  int c;
  do {
    c = getc(f);
  } while (isspace(c));

  if (c != EOF) {
    ungetc(c, f);
  }
}

static int constituent(char c) {
  return isalnum(c) || c == '.' || c == '-' || c == '+' || c == '_';
}

// Produces an empty token only on EOF.
static void next_token(FILE *f, char *buf, int bufsize) {
 start:
  skipspaces(f);

  int i = 0;
  while (i < bufsize) {
    int c = getc(f);
    buf[i] = (char)c;

    if (c == EOF) {
      buf[i] = 0;
      return;
    } else if (c == '-' && i == 1 && buf[0] == '-') {
      // Line comment, so skip to end of line and start over.
      for (; c != '\n' && c != EOF; c = getc(f));
      goto start;
    } else if (!constituent((char)c)) {
      if (i == 0) {
        // We permit single-character tokens that are not
        // constituents; this lets things like ']' and ',' be
        // tokens.
        buf[i+1] = 0;
        return;
      } else {
        ungetc(c, f);
        buf[i] = 0;
        return;
      }
    }

    i++;
  }

  buf[bufsize-1] = 0;
}

static int next_token_is(FILE *f, char *buf, int bufsize, const char* expected) {
  next_token(f, buf, bufsize);
  return strcmp(buf, expected) == 0;
}

static void remove_underscores(char *buf) {
  char *w = buf;

  for (char *r = buf; *r; r++) {
    if (*r != '_') {
      *w++ = *r;
    }
  }

  *w++ = 0;
}

static int read_str_elem(char *buf, struct array_reader *reader) {
  int ret;
  if (reader->n_elems_used == reader->n_elems_space) {
    reader->n_elems_space *= 2;
    reader->elems = (char*) realloc(reader->elems,
                                    (size_t)(reader->n_elems_space * reader->elem_size));
  }

  ret = reader->elem_reader(buf, reader->elems + reader->n_elems_used * reader->elem_size);

  if (ret == 0) {
    reader->n_elems_used++;
  }

  return ret;
}

static int read_str_array_elems(FILE *f,
                                char *buf, int bufsize,
                                struct array_reader *reader, int64_t dims) {
  int ret;
  int first = 1;
  char *knows_dimsize = (char*) calloc((size_t)dims, sizeof(char));
  int cur_dim = (int)dims-1;
  int64_t *elems_read_in_dim = (int64_t*) calloc((size_t)dims, sizeof(int64_t));

  while (1) {
    next_token(f, buf, bufsize);

    if (strcmp(buf, "]") == 0) {
      if (knows_dimsize[cur_dim]) {
        if (reader->shape[cur_dim] != elems_read_in_dim[cur_dim]) {
          ret = 1;
          break;
        }
      } else {
        knows_dimsize[cur_dim] = 1;
        reader->shape[cur_dim] = elems_read_in_dim[cur_dim];
      }
      if (cur_dim == 0) {
        ret = 0;
        break;
      } else {
        cur_dim--;
        elems_read_in_dim[cur_dim]++;
      }
    } else if (strcmp(buf, ",") == 0) {
      next_token(f, buf, bufsize);
      if (strcmp(buf, "[") == 0) {
        if (cur_dim == dims - 1) {
          ret = 1;
          break;
        }
        first = 1;
        cur_dim++;
        elems_read_in_dim[cur_dim] = 0;
      } else if (cur_dim == dims - 1) {
        ret = read_str_elem(buf, reader);
        if (ret != 0) {
          break;
        }
        elems_read_in_dim[cur_dim]++;
      } else {
        ret = 1;
        break;
      }
    } else if (strlen(buf) == 0) {
      // EOF
      ret = 1;
      break;
    } else if (first) {
      if (strcmp(buf, "[") == 0) {
        if (cur_dim == dims - 1) {
          ret = 1;
          break;
        }
        cur_dim++;
        elems_read_in_dim[cur_dim] = 0;
      } else {
        ret = read_str_elem(buf, reader);
        if (ret != 0) {
          break;
        }
        elems_read_in_dim[cur_dim]++;
        first = 0;
      }
    } else {
      ret = 1;
      break;
    }
  }

  free(knows_dimsize);
  free(elems_read_in_dim);
  return ret;
}

static int read_str_empty_array(FILE *f, char *buf, int bufsize,
                                const char *type_name, int64_t *shape, int64_t dims) {
  if (strlen(buf) == 0) {
    // EOF
    return 1;
  }

  if (strcmp(buf, "empty") != 0) {
    return 1;
  }

  if (!next_token_is(f, buf, bufsize, "(")) {
    return 1;
  }

  for (int i = 0; i < dims; i++) {
    if (!next_token_is(f, buf, bufsize, "[")) {
      return 1;
    }

    next_token(f, buf, bufsize);

    if (sscanf(buf, "%"SCNu64, (uint64_t*)&shape[i]) != 1) {
      return 1;
    }

    if (!next_token_is(f, buf, bufsize, "]")) {
      return 1;
    }
  }

  if (!next_token_is(f, buf, bufsize, type_name)) {
    return 1;
  }


  if (!next_token_is(f, buf, bufsize, ")")) {
    return 1;
  }

  // Check whether the array really is empty.
  for (int i = 0; i < dims; i++) {
    if (shape[i] == 0) {
      return 0;
    }
  }

  // Not an empty array!
  return 1;
}

static int read_str_array(FILE *f,
                          int64_t elem_size, str_reader elem_reader,
                          const char *type_name,
                          void **data, int64_t *shape, int64_t dims) {
  int ret;
  struct array_reader reader;
  char buf[100];

  int dims_seen;
  for (dims_seen = 0; dims_seen < dims; dims_seen++) {
    if (!next_token_is(f, buf, sizeof(buf), "[")) {
      break;
    }
  }

  if (dims_seen == 0) {
    return read_str_empty_array(f, buf, sizeof(buf), type_name, shape, dims);
  }

  if (dims_seen != dims) {
    return 1;
  }

  reader.shape = shape;
  reader.n_elems_used = 0;
  reader.elem_size = elem_size;
  reader.n_elems_space = 16;
  reader.elems = (char*) realloc(*data, (size_t)(elem_size*reader.n_elems_space));
  reader.elem_reader = elem_reader;

  ret = read_str_array_elems(f, buf, sizeof(buf), &reader, dims);

  *data = reader.elems;

  return ret;
}

#define READ_STR(MACRO, PTR, SUFFIX)                                   \
  remove_underscores(buf);                                              \
  int j;                                                                \
  if (sscanf(buf, "%"MACRO"%n", (PTR*)dest, &j) == 1) {                 \
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, SUFFIX) == 0);     \
  } else {                                                              \
    return 1;                                                           \
  }

static int read_str_i8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNi8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(int8_t*)dest = (int8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "i8") == 0);
  } else {
    return 1;
  }
}

static int read_str_u8(char *buf, void* dest) {
  // Some platforms (WINDOWS) does not support scanf %hhd or its
  // cousin, %SCNu8.  Read into int first to avoid corrupting
  // memory.
  //
  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=63417
  remove_underscores(buf);
  int j, x;
  if (sscanf(buf, "%i%n", &x, &j) == 1) {
    *(uint8_t*)dest = (uint8_t)x;
    return !(strcmp(buf+j, "") == 0 || strcmp(buf+j, "u8") == 0);
  } else {
    return 1;
  }
}

static int read_str_i16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "i16");
}

static int read_str_u16(char *buf, void* dest) {
  READ_STR(SCNi16, int16_t, "u16");
}

static int read_str_i32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "i32");
}

static int read_str_u32(char *buf, void* dest) {
  READ_STR(SCNi32, int32_t, "u32");
}

static int read_str_i64(char *buf, void* dest) {
  READ_STR(SCNi64, int64_t, "i64");
}

static int read_str_u64(char *buf, void* dest) {
  // FIXME: This is not correct, as SCNu64 only permits decimal
  // literals.  However, SCNi64 does not handle very large numbers
  // correctly (it's really for signed numbers, so that's fair).
  READ_STR(SCNu64, uint64_t, "u64");
}

static int read_str_f16(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f16.nan") == 0) {
    *(uint16_t*)dest = float2halfbits(NAN);
    return 0;
  } else if (strcmp(buf, "f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(INFINITY);
    return 0;
  } else if (strcmp(buf, "-f16.inf") == 0) {
    *(uint16_t*)dest = float2halfbits(-INFINITY);
    return 0;
  } else {
    int j;
    float x;
    if (sscanf(buf, "%f%n", &x, &j) == 1) {
      if (strcmp(buf+j, "") == 0 || strcmp(buf+j, "f16") == 0) {
        *(uint16_t*)dest = float2halfbits(x);
        return 0;
      }
    }
    return 1;
  }
}

static int read_str_f32(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f32.nan") == 0) {
    *(float*)dest = (float)NAN;
    return 0;
  } else if (strcmp(buf, "f32.inf") == 0) {
    *(float*)dest = (float)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f32.inf") == 0) {
    *(float*)dest = (float)-INFINITY;
    return 0;
  } else {
    READ_STR("f", float, "f32");
  }
}

static int read_str_f64(char *buf, void* dest) {
  remove_underscores(buf);
  if (strcmp(buf, "f64.nan") == 0) {
    *(double*)dest = (double)NAN;
    return 0;
  } else if (strcmp(buf, "f64.inf") == 0) {
    *(double*)dest = (double)INFINITY;
    return 0;
  } else if (strcmp(buf, "-f64.inf") == 0) {
    *(double*)dest = (double)-INFINITY;
    return 0;
  } else {
    READ_STR("lf", double, "f64");
  }
}

static int read_str_bool(char *buf, void* dest) {
  if (strcmp(buf, "true") == 0) {
    *(char*)dest = 1;
    return 0;
  } else if (strcmp(buf, "false") == 0) {
    *(char*)dest = 0;
    return 0;
  } else {
    return 1;
  }
}

static int write_str_i8(FILE *out, int8_t *src) {
  return fprintf(out, "%hhdi8", *src);
}

static int write_str_u8(FILE *out, uint8_t *src) {
  return fprintf(out, "%hhuu8", *src);
}

static int write_str_i16(FILE *out, int16_t *src) {
  return fprintf(out, "%hdi16", *src);
}

static int write_str_u16(FILE *out, uint16_t *src) {
  return fprintf(out, "%huu16", *src);
}

static int write_str_i32(FILE *out, int32_t *src) {
  return fprintf(out, "%di32", *src);
}

static int write_str_u32(FILE *out, uint32_t *src) {
  return fprintf(out, "%uu32", *src);
}

static int write_str_i64(FILE *out, int64_t *src) {
  return fprintf(out, "%"PRIi64"i64", *src);
}

static int write_str_u64(FILE *out, uint64_t *src) {
  return fprintf(out, "%"PRIu64"u64", *src);
}

static int write_str_f16(FILE *out, uint16_t *src) {
  float x = halfbits2float(*src);
  if (isnan(x)) {
    return fprintf(out, "f16.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f16.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f16.inf");
  } else {
    return fprintf(out, "%.6ff16", x);
  }
}

static int write_str_f32(FILE *out, float *src) {
  float x = *src;
  if (isnan(x)) {
    return fprintf(out, "f32.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f32.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f32.inf");
  } else {
    return fprintf(out, "%.6ff32", x);
  }
}

static int write_str_f64(FILE *out, double *src) {
  double x = *src;
  if (isnan(x)) {
    return fprintf(out, "f64.nan");
  } else if (isinf(x) && x >= 0) {
    return fprintf(out, "f64.inf");
  } else if (isinf(x)) {
    return fprintf(out, "-f64.inf");
  } else {
    return fprintf(out, "%.6ff64", *src);
  }
}

static int write_str_bool(FILE *out, void *src) {
  return fprintf(out, *(char*)src ? "true" : "false");
}

//// Binary I/O

#define BINARY_FORMAT_VERSION 2
#define IS_BIG_ENDIAN (!*(unsigned char *)&(uint16_t){1})

static void flip_bytes(size_t elem_size, unsigned char *elem) {
  for (size_t j=0; j<elem_size/2; j++) {
    unsigned char head = elem[j];
    size_t tail_index = elem_size-1-j;
    elem[j] = elem[tail_index];
    elem[tail_index] = head;
  }
}

// On Windows we need to explicitly set the file mode to not mangle
// newline characters.  On *nix there is no difference.
#ifdef _WIN32
#include <io.h>
#include <fcntl.h>
static void set_binary_mode(FILE *f) {
  setmode(fileno(f), O_BINARY);
}
#else
static void set_binary_mode(FILE *f) {
  (void)f;
}
#endif

static int read_byte(FILE *f, void* dest) {
  size_t num_elems_read = fread(dest, 1, 1, f);
  return num_elems_read == 1 ? 0 : 1;
}

//// Types

struct primtype_info_t {
  const char binname[4]; // Used for parsing binary data.
  const char* type_name; // Same name as in Futhark.
  const int64_t size; // in bytes
  const writer write_str; // Write in text format.
  const str_reader read_str; // Read in text format.
};

static const struct primtype_info_t i8_info =
  {.binname = "  i8", .type_name = "i8",   .size = 1,
   .write_str = (writer)write_str_i8, .read_str = (str_reader)read_str_i8};
static const struct primtype_info_t i16_info =
  {.binname = " i16", .type_name = "i16",  .size = 2,
   .write_str = (writer)write_str_i16, .read_str = (str_reader)read_str_i16};
static const struct primtype_info_t i32_info =
  {.binname = " i32", .type_name = "i32",  .size = 4,
   .write_str = (writer)write_str_i32, .read_str = (str_reader)read_str_i32};
static const struct primtype_info_t i64_info =
  {.binname = " i64", .type_name = "i64",  .size = 8,
   .write_str = (writer)write_str_i64, .read_str = (str_reader)read_str_i64};
static const struct primtype_info_t u8_info =
  {.binname = "  u8", .type_name = "u8",   .size = 1,
   .write_str = (writer)write_str_u8, .read_str = (str_reader)read_str_u8};
static const struct primtype_info_t u16_info =
  {.binname = " u16", .type_name = "u16",  .size = 2,
   .write_str = (writer)write_str_u16, .read_str = (str_reader)read_str_u16};
static const struct primtype_info_t u32_info =
  {.binname = " u32", .type_name = "u32",  .size = 4,
   .write_str = (writer)write_str_u32, .read_str = (str_reader)read_str_u32};
static const struct primtype_info_t u64_info =
  {.binname = " u64", .type_name = "u64",  .size = 8,
   .write_str = (writer)write_str_u64, .read_str = (str_reader)read_str_u64};
static const struct primtype_info_t f16_info =
  {.binname = " f16", .type_name = "f16",  .size = 2,
   .write_str = (writer)write_str_f16, .read_str = (str_reader)read_str_f16};
static const struct primtype_info_t f32_info =
  {.binname = " f32", .type_name = "f32",  .size = 4,
   .write_str = (writer)write_str_f32, .read_str = (str_reader)read_str_f32};
static const struct primtype_info_t f64_info =
  {.binname = " f64", .type_name = "f64",  .size = 8,
   .write_str = (writer)write_str_f64, .read_str = (str_reader)read_str_f64};
static const struct primtype_info_t bool_info =
  {.binname = "bool", .type_name = "bool", .size = 1,
   .write_str = (writer)write_str_bool, .read_str = (str_reader)read_str_bool};

static const struct primtype_info_t* primtypes[] = {
  &i8_info, &i16_info, &i32_info, &i64_info,
  &u8_info, &u16_info, &u32_info, &u64_info,
  &f16_info, &f32_info, &f64_info,
  &bool_info,
  NULL // NULL-terminated
};

// General value interface.  All endian business taken care of at
// lower layers.

static int read_is_binary(FILE *f) {
  skipspaces(f);
  int c = getc(f);
  if (c == 'b') {
    int8_t bin_version;
    int ret = read_byte(f, &bin_version);

    if (ret != 0) { futhark_panic(1, "binary-input: could not read version.\n"); }

    if (bin_version != BINARY_FORMAT_VERSION) {
      futhark_panic(1, "binary-input: File uses version %i, but I only understand version %i.\n",
            bin_version, BINARY_FORMAT_VERSION);
    }

    return 1;
  }
  ungetc(c, f);
  return 0;
}

static const struct primtype_info_t* read_bin_read_type_enum(FILE *f) {
  char read_binname[4];

  int num_matched = fscanf(f, "%4c", read_binname);
  if (num_matched != 1) { futhark_panic(1, "binary-input: Couldn't read element type.\n"); }

  const struct primtype_info_t **type = primtypes;

  for (; *type != NULL; type++) {
    // I compare the 4 characters manually instead of using strncmp because
    // this allows any value to be used, also NULL bytes
    if (memcmp(read_binname, (*type)->binname, 4) == 0) {
      return *type;
    }
  }
  futhark_panic(1, "binary-input: Did not recognize the type '%s'.\n", read_binname);
  return NULL;
}

static void read_bin_ensure_scalar(FILE *f, const struct primtype_info_t *expected_type) {
  int8_t bin_dims;
  int ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != 0) {
    futhark_panic(1, "binary-input: Expected scalar (0 dimensions), but got array with %i dimensions.\n",
          bin_dims);
  }

  const struct primtype_info_t *bin_type = read_bin_read_type_enum(f);
  if (bin_type != expected_type) {
    futhark_panic(1, "binary-input: Expected scalar of type %s but got scalar of type %s.\n",
          expected_type->type_name,
          bin_type->type_name);
  }
}

//// High-level interface

static int read_bin_array(FILE *f,
                          const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  int ret;

  int8_t bin_dims;
  ret = read_byte(f, &bin_dims);
  if (ret != 0) { futhark_panic(1, "binary-input: Couldn't get dims.\n"); }

  if (bin_dims != dims) {
    futhark_panic(1, "binary-input: Expected %i dimensions, but got array with %i dimensions.\n",
          dims, bin_dims);
  }

  const struct primtype_info_t *bin_primtype = read_bin_read_type_enum(f);
  if (expected_type != bin_primtype) {
    futhark_panic(1, "binary-input: Expected %iD-array with element type '%s' but got %iD-array with element type '%s'.\n",
          dims, expected_type->type_name, dims, bin_primtype->type_name);
  }

  int64_t elem_count = 1;
  for (int i=0; i<dims; i++) {
    int64_t bin_shape;
    ret = (int)fread(&bin_shape, sizeof(bin_shape), 1, f);
    if (ret != 1) {
      futhark_panic(1, "binary-input: Couldn't read size for dimension %i of array.\n", i);
    }
    if (IS_BIG_ENDIAN) {
      flip_bytes(sizeof(bin_shape), (unsigned char*) &bin_shape);
    }
    elem_count *= bin_shape;
    shape[i] = bin_shape;
  }

  int64_t elem_size = expected_type->size;
  void* tmp = realloc(*data, (size_t)(elem_count * elem_size));
  if (tmp == NULL) {
    futhark_panic(1, "binary-input: Failed to allocate array of size %i.\n",
          elem_count * elem_size);
  }
  *data = tmp;

  int64_t num_elems_read = (int64_t)fread(*data, (size_t)elem_size, (size_t)elem_count, f);
  if (num_elems_read != elem_count) {
    futhark_panic(1, "binary-input: tried to read %i elements of an array, but only got %i elements.\n",
          elem_count, num_elems_read);
  }

  // If we're on big endian platform we must change all multibyte elements
  // from using little endian to big endian
  if (IS_BIG_ENDIAN && elem_size != 1) {
    flip_bytes((size_t)elem_size, (unsigned char*) *data);
  }

  return 0;
}

static int read_array(FILE *f, const struct primtype_info_t *expected_type, void **data, int64_t *shape, int64_t dims) {
  if (!read_is_binary(f)) {
    return read_str_array(f, expected_type->size, (str_reader)expected_type->read_str, expected_type->type_name, data, shape, dims);
  } else {
    return read_bin_array(f, expected_type, data, shape, dims);
  }
}

static int end_of_input(FILE *f) {
  skipspaces(f);
  char token[2];
  next_token(f, token, sizeof(token));
  if (strcmp(token, "") == 0) {
    return 0;
  } else {
    return 1;
  }
}

static int write_str_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  if (rank==0) {
    elem_type->write_str(out, (const void*)data);
  } else {
    int64_t len = (int64_t)shape[0];
    int64_t slice_size = 1;

    int64_t elem_size = elem_type->size;
    for (int8_t i = 1; i < rank; i++) {
      slice_size *= shape[i];
    }

    if (len*slice_size == 0) {
      fprintf(out, "empty(");
      for (int64_t i = 0; i < rank; i++) {
        fprintf(out, "[%"PRIi64"]", shape[i]);
      }
      fprintf(out, "%s", elem_type->type_name);
      fprintf(out, ")");
    } else if (rank==1) {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        elem_type->write_str(out, (const void*) (data + i * elem_size));
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    } else {
      fputc('[', out);
      for (int64_t i = 0; i < len; i++) {
        write_str_array(out, elem_type, data + i * slice_size * elem_size, shape+1, rank-1);
        if (i != len-1) {
          fprintf(out, ", ");
        }
      }
      fputc(']', out);
    }
  }
  return 0;
}

static int write_bin_array(FILE *out,
                           const struct primtype_info_t *elem_type,
                           const unsigned char *data,
                           const int64_t *shape,
                           int8_t rank) {
  int64_t num_elems = 1;
  for (int64_t i = 0; i < rank; i++) {
    num_elems *= shape[i];
  }

  fputc('b', out);
  fputc((char)BINARY_FORMAT_VERSION, out);
  fwrite(&rank, sizeof(int8_t), 1, out);
  fwrite(elem_type->binname, 4, 1, out);
  if (shape != NULL) {
    fwrite(shape, sizeof(int64_t), (size_t)rank, out);
  }

  if (IS_BIG_ENDIAN) {
    for (int64_t i = 0; i < num_elems; i++) {
      const unsigned char *elem = data+i*elem_type->size;
      for (int64_t j = 0; j < elem_type->size; j++) {
        fwrite(&elem[elem_type->size-j], 1, 1, out);
      }
    }
  } else {
    fwrite(data, (size_t)elem_type->size, (size_t)num_elems, out);
  }

  return 0;
}

static int write_array(FILE *out, int write_binary,
                       const struct primtype_info_t *elem_type,
                       const void *data,
                       const int64_t *shape,
                       const int8_t rank) {
  if (write_binary) {
    return write_bin_array(out, elem_type, data, shape, rank);
  } else {
    return write_str_array(out, elem_type, data, shape, rank);
  }
}

static int read_scalar(FILE *f,
                       const struct primtype_info_t *expected_type, void *dest) {
  if (!read_is_binary(f)) {
    char buf[100];
    next_token(f, buf, sizeof(buf));
    return expected_type->read_str(buf, dest);
  } else {
    read_bin_ensure_scalar(f, expected_type);
    size_t elem_size = (size_t)expected_type->size;
    size_t num_elems_read = fread(dest, elem_size, 1, f);
    if (IS_BIG_ENDIAN) {
      flip_bytes(elem_size, (unsigned char*) dest);
    }
    return num_elems_read == 1 ? 0 : 1;
  }
}

static int write_scalar(FILE *out, int write_binary, const struct primtype_info_t *type, void *src) {
  if (write_binary) {
    return write_bin_array(out, type, src, NULL, 0);
  } else {
    return type->write_str(out, src);
  }
}

// End of values.h.

static int binary_output = 0;
static int print_result = 1;
static int print_report = 0;
static FILE *runtime_file;
static int perform_warmup = 0;
static int num_runs = 1;
static const char *entry_point = "main";
// Start of tuning.h.

static char* load_tuning_file(const char *fname,
                              void *cfg,
                              int (*set_tuning_param)(void*, const char*, size_t)) {
  const int max_line_len = 1024;
  char* line = (char*) malloc(max_line_len);

  FILE *f = fopen(fname, "r");

  if (f == NULL) {
    snprintf(line, max_line_len, "Cannot open file: %s", strerror(errno));
    return line;
  }

  int lineno = 0;
  while (fgets(line, max_line_len, f) != NULL) {
    lineno++;
    char *eql = strstr(line, "=");
    if (eql) {
      *eql = 0;
      int value = atoi(eql+1);
      if (set_tuning_param(cfg, line, (size_t)value) != 0) {
        char* err = (char*) malloc(max_line_len + 50);
        snprintf(err, max_line_len + 50, "Unknown name '%s' on line %d.", line, lineno);
        free(line);
        return err;
      }
    } else {
      snprintf(line, max_line_len, "Invalid line %d (must be of form 'name=int').",
               lineno);
      return line;
    }
  }

  free(line);

  return NULL;
}

// End of tuning.h.

int parse_options(struct futhark_context_config *cfg, int argc, char *const argv[])
{
    int ch;
    static struct option long_options[] = {{"write-runtime-to", required_argument, NULL, 1}, {"runs", required_argument, NULL, 2}, {"debugging", no_argument, NULL, 3}, {"log", no_argument, NULL, 4}, {"entry-point", required_argument, NULL, 5}, {"binary-output", no_argument, NULL, 6}, {"no-print-result", no_argument, NULL, 7}, {"help", no_argument, NULL, 8}, {"print-params", no_argument, NULL, 9}, {"param", required_argument, NULL, 10}, {"tuning", required_argument, NULL, 11}, {"cache-file", required_argument, NULL, 12}, {"device", required_argument, NULL, 13}, {"default-group-size", required_argument, NULL, 14}, {"default-num-groups", required_argument, NULL, 15}, {"default-tile-size", required_argument, NULL, 16}, {"default-reg-tile-size", required_argument, NULL, 17}, {"default-threshold", required_argument, NULL, 18}, {"dump-cuda", required_argument, NULL, 19}, {"load-cuda", required_argument, NULL, 20}, {"dump-ptx", required_argument, NULL, 21}, {"load-ptx", required_argument, NULL, 22}, {"nvrtc-option", required_argument, NULL, 23}, {"profile", no_argument, NULL, 24}, {0, 0, 0, 0}};
    static char *option_descriptions = "  -t/--write-runtime-to FILE  Print the time taken to execute the program to the indicated file, an integral number of microseconds.\n  -r/--runs INT               Perform NUM runs of the program.\n  -D/--debugging              Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                    Print various low-overhead logging information to stderr while running.\n  -e/--entry-point NAME       The entry point to run. Defaults to main.\n  -b/--binary-output          Print the program result in the binary output format.\n  -n/--no-print-result        Do not print the program result.\n  -h/--help                   Print help information and exit.\n  --print-params              Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT          Set a tuning parameter to the given value.\n  --tuning FILE               Read size=value assignments from the given file.\n  --cache-file FILE           Store program cache here.\n  -d/--device NAME            Use the first device whose name contains the given string.\n  --default-group-size INT    The default size of workgroups that are launched.\n  --default-num-groups INT    The default number of workgroups that are launched.\n  --default-tile-size INT     The default tile size used when performing two-dimensional tiling.\n  --default-reg-tile-size INT The default register tile size used when performing two-dimensional tiling.\n  --default-threshold INT     The default parallelism threshold.\n  --dump-cuda FILE            Dump the embedded CUDA kernels to the indicated file.\n  --load-cuda FILE            Instead of using the embedded CUDA kernels, load them from the indicated file.\n  --dump-ptx FILE             Dump the PTX-compiled version of the embedded kernels to the indicated file.\n  --load-ptx FILE             Load PTX code from the indicated file.\n  --nvrtc-option OPT          Add an additional build option to the string passed to NVRTC.\n  -P/--profile                Gather profiling data while executing and print out a summary at the end.\n";
    
    while ((ch = getopt_long(argc, argv, ":t:r:DLe:bnhd:P", long_options, NULL)) != -1) {
        if (ch == 1 || ch == 't') {
            runtime_file = fopen(optarg, "w");
            if (runtime_file == NULL)
                futhark_panic(1, "Cannot open %s: %s\n", optarg, strerror(errno));
        }
        if (ch == 2 || ch == 'r') {
            num_runs = atoi(optarg);
            perform_warmup = 1;
            if (num_runs <= 0)
                futhark_panic(1, "Need a positive number of runs, not %s\n", optarg);
        }
        if (ch == 3 || ch == 'D') {
            futhark_context_config_set_debugging(cfg, 1);
            print_report = 1;
        }
        if (ch == 4 || ch == 'L') {
            futhark_context_config_set_logging(cfg, 1);
            print_report = 1;
        }
        if (ch == 5 || ch == 'e') {
            if (entry_point != NULL)
                entry_point = optarg;
        }
        if (ch == 6 || ch == 'b')
            binary_output = 1;
        if (ch == 7 || ch == 'n')
            print_result = 0;
        if (ch == 8 || ch == 'h') {
            printf("Usage: %s [OPTION]...\nOptions:\n\n%s\nFor more information, consult the Futhark User's Guide or the man pages.\n", fut_progname, option_descriptions);
            exit(0);
        }
        if (ch == 9) {
            int n = futhark_get_tuning_param_count();
            
            for (int i = 0; i < n; i++)
                printf("%s (%s)\n", futhark_get_tuning_param_name(i), futhark_get_tuning_param_class(i));
            exit(0);
        }
        if (ch == 10) {
            char *name = optarg;
            char *equals = strstr(optarg, "=");
            char *value_str = equals != NULL ? equals + 1 : optarg;
            int value = atoi(value_str);
            
            if (equals != NULL) {
                *equals = 0;
                if (futhark_context_config_set_tuning_param(cfg, name, (size_t) value) != 0)
                    futhark_panic(1, "Unknown size: %s\n", name);
            } else
                futhark_panic(1, "Invalid argument for size option: %s\n", optarg);
        }
        if (ch == 11) {
            char *ret = load_tuning_file(optarg, cfg, (int (*)(void *, const char *, size_t)) futhark_context_config_set_tuning_param);
            
            if (ret != NULL)
                futhark_panic(1, "When loading tuning from '%s': %s\n", optarg, ret);
        }
        if (ch == 12)
            futhark_context_config_set_cache_file(cfg, optarg);
        if (ch == 13 || ch == 'd')
            futhark_context_config_set_device(cfg, optarg);
        if (ch == 14)
            futhark_context_config_set_default_group_size(cfg, atoi(optarg));
        if (ch == 15)
            futhark_context_config_set_default_num_groups(cfg, atoi(optarg));
        if (ch == 16)
            futhark_context_config_set_default_tile_size(cfg, atoi(optarg));
        if (ch == 17)
            futhark_context_config_set_default_reg_tile_size(cfg, atoi(optarg));
        if (ch == 18)
            futhark_context_config_set_default_threshold(cfg, atoi(optarg));
        if (ch == 19) {
            const char *prog = futhark_context_config_get_program(cfg);
            
            if (dump_file(optarg, prog, strlen(prog)) != 0) {
                fprintf(stderr, "%s: %s\n", optarg, strerror(errno));
                exit(1);
            }
            exit(1);
        }
        if (ch == 20) {
            size_t n;
            const char *s = slurp_file(optarg, &n);
            
            if (s == NULL) {
                fprintf(stderr, "%s: %s\n", optarg, strerror(errno));
                exit(1);
            }
            futhark_context_config_set_program(cfg, s);
        }
        if (ch == 21) {
            futhark_context_config_dump_ptx_to(cfg, optarg);
            entry_point = NULL;
        }
        if (ch == 22)
            futhark_context_config_load_ptx_from(cfg, optarg);
        if (ch == 23)
            futhark_context_config_add_nvrtc_option(cfg, optarg);
        if (ch == 24 || ch == 'P')
            futhark_context_config_set_profiling(cfg, 1);
        if (ch == ':')
            futhark_panic(-1, "Missing argument for option %s\n", argv[optind - 1]);
        if (ch == '?') {
            fprintf(stderr, "Usage: %s [OPTIONS]...\nOptions:\n\n%s\n", fut_progname, "  -t/--write-runtime-to FILE  Print the time taken to execute the program to the indicated file, an integral number of microseconds.\n  -r/--runs INT               Perform NUM runs of the program.\n  -D/--debugging              Perform possibly expensive internal correctness checks and verbose logging.\n  -L/--log                    Print various low-overhead logging information to stderr while running.\n  -e/--entry-point NAME       The entry point to run. Defaults to main.\n  -b/--binary-output          Print the program result in the binary output format.\n  -n/--no-print-result        Do not print the program result.\n  -h/--help                   Print help information and exit.\n  --print-params              Print all tuning parameters that can be set with --param or --tuning.\n  --param ASSIGNMENT          Set a tuning parameter to the given value.\n  --tuning FILE               Read size=value assignments from the given file.\n  --cache-file FILE           Store program cache here.\n  -d/--device NAME            Use the first device whose name contains the given string.\n  --default-group-size INT    The default size of workgroups that are launched.\n  --default-num-groups INT    The default number of workgroups that are launched.\n  --default-tile-size INT     The default tile size used when performing two-dimensional tiling.\n  --default-reg-tile-size INT The default register tile size used when performing two-dimensional tiling.\n  --default-threshold INT     The default parallelism threshold.\n  --dump-cuda FILE            Dump the embedded CUDA kernels to the indicated file.\n  --load-cuda FILE            Instead of using the embedded CUDA kernels, load them from the indicated file.\n  --dump-ptx FILE             Dump the PTX-compiled version of the embedded kernels to the indicated file.\n  --load-ptx FILE             Load PTX code from the indicated file.\n  --nvrtc-option OPT          Add an additional build option to the string passed to NVRTC.\n  -P/--profile                Gather profiling data while executing and print out a summary at the end.\n");
            futhark_panic(1, "Unknown option: %s\n", argv[optind - 1]);
        }
    }
    return optind;
}
static int futrts_cli_entry_big_add_debug(struct futhark_context *ctx)
{
    int64_t t_start, t_end;
    int time_runs = 0, profile_run = 0;
    int retval = 0;
    
    // We do not want to profile all the initialisation.
    futhark_context_pause_profiling(ctx);
    // Declare and read input.
    set_binary_mode(stdin);
    
    struct futhark_u64_1d * read_value_0;
    int64_t read_shape_0[1];
    uint64_t *read_arr_0 = NULL;
    
    errno = 0;
    if (read_array(stdin, &u64_info, (void **) &read_arr_0, read_shape_0, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 0, "[]u64", strerror(errno));
    
    struct futhark_u64_1d * read_value_1;
    int64_t read_shape_1[1];
    uint64_t *read_arr_1 = NULL;
    
    errno = 0;
    if (read_array(stdin, &u64_info, (void **) &read_arr_1, read_shape_1, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 1, "[]u64", strerror(errno));
    
    struct futhark_u64_1d * read_value_2;
    int64_t read_shape_2[1];
    uint64_t *read_arr_2 = NULL;
    
    errno = 0;
    if (read_array(stdin, &u64_info, (void **) &read_arr_2, read_shape_2, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 2, "[]u64", strerror(errno));
    if (end_of_input(stdin) != 0)
        futhark_panic(1, "Expected EOF on stdin after reading input for \"%s\".\n", "big_add_debug");
    
    struct futhark_u64_1d * result_0;
    struct futhark_u64_1d * result_1;
    struct futhark_i64_1d * result_2;
    
    if (perform_warmup) {
        int r;
        
        assert((read_value_0 = futhark_new_u64_1d(ctx, read_arr_0, read_shape_0[0])) != NULL);
        assert((read_value_1 = futhark_new_u64_1d(ctx, read_arr_1, read_shape_1[0])) != NULL);
        assert((read_value_2 = futhark_new_u64_1d(ctx, read_arr_2, read_shape_2[0])) != NULL);
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        // Only profile last run.
        if (profile_run)
            futhark_context_unpause_profiling(ctx);
        t_start = get_wall_time();
        r = futhark_entry_big_add_debug(ctx, &result_0, &result_1, &result_2, read_value_0, read_value_1, read_value_2);
        if (r != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        if (profile_run)
            futhark_context_pause_profiling(ctx);
        t_end = get_wall_time();
        
        long elapsed_usec = t_end - t_start;
        
        if (time_runs && runtime_file != NULL) {
            fprintf(runtime_file, "%lld\n", (long long) elapsed_usec);
            fflush(runtime_file);
        }
        assert(futhark_free_u64_1d(ctx, read_value_0) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_1) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_2) == 0);
        assert(futhark_free_u64_1d(ctx, result_0) == 0);
        assert(futhark_free_u64_1d(ctx, result_1) == 0);
        assert(futhark_free_i64_1d(ctx, result_2) == 0);
    }
    time_runs = 1;
    // Proper run.
    for (int run = 0; run < num_runs; run++) {
        // Only profile last run.
        profile_run = run == num_runs - 1;
        
        int r;
        
        assert((read_value_0 = futhark_new_u64_1d(ctx, read_arr_0, read_shape_0[0])) != NULL);
        assert((read_value_1 = futhark_new_u64_1d(ctx, read_arr_1, read_shape_1[0])) != NULL);
        assert((read_value_2 = futhark_new_u64_1d(ctx, read_arr_2, read_shape_2[0])) != NULL);
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        // Only profile last run.
        if (profile_run)
            futhark_context_unpause_profiling(ctx);
        t_start = get_wall_time();
        r = futhark_entry_big_add_debug(ctx, &result_0, &result_1, &result_2, read_value_0, read_value_1, read_value_2);
        if (r != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        if (profile_run)
            futhark_context_pause_profiling(ctx);
        t_end = get_wall_time();
        
        long elapsed_usec = t_end - t_start;
        
        if (time_runs && runtime_file != NULL) {
            fprintf(runtime_file, "%lld\n", (long long) elapsed_usec);
            fflush(runtime_file);
        }
        assert(futhark_free_u64_1d(ctx, read_value_0) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_1) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_2) == 0);
        if (run < num_runs - 1) {
            assert(futhark_free_u64_1d(ctx, result_0) == 0);
            assert(futhark_free_u64_1d(ctx, result_1) == 0);
            assert(futhark_free_i64_1d(ctx, result_2) == 0);
        }
    }
    free(read_arr_0);
    free(read_arr_1);
    free(read_arr_2);
    if (print_result) {
        // Print the final result.
        if (binary_output)
            set_binary_mode(stdout);
        {
            uint64_t *arr = calloc(futhark_shape_u64_1d(ctx, result_0)[0], u64_info.size);
            
            assert(arr != NULL);
            assert(futhark_values_u64_1d(ctx, result_0, arr) == 0);
            assert(futhark_context_sync(ctx) == 0);
            write_array(stdout, binary_output, &u64_info, arr, futhark_shape_u64_1d(ctx, result_0), 1);
            free(arr);
        }
        printf("\n");
        {
            uint64_t *arr = calloc(futhark_shape_u64_1d(ctx, result_1)[0], u64_info.size);
            
            assert(arr != NULL);
            assert(futhark_values_u64_1d(ctx, result_1, arr) == 0);
            assert(futhark_context_sync(ctx) == 0);
            write_array(stdout, binary_output, &u64_info, arr, futhark_shape_u64_1d(ctx, result_1), 1);
            free(arr);
        }
        printf("\n");
        {
            int64_t *arr = calloc(futhark_shape_i64_1d(ctx, result_2)[0], i64_info.size);
            
            assert(arr != NULL);
            assert(futhark_values_i64_1d(ctx, result_2, arr) == 0);
            assert(futhark_context_sync(ctx) == 0);
            write_array(stdout, binary_output, &i64_info, arr, futhark_shape_i64_1d(ctx, result_2), 1);
            free(arr);
        }
        printf("\n");
    }
    
  print_end:
    { }
    assert(futhark_free_u64_1d(ctx, result_0) == 0);
    assert(futhark_free_u64_1d(ctx, result_1) == 0);
    assert(futhark_free_i64_1d(ctx, result_2) == 0);
    return retval;
}
static int futrts_cli_entry_big_add_validation(struct futhark_context *ctx)
{
    int64_t t_start, t_end;
    int time_runs = 0, profile_run = 0;
    int retval = 0;
    
    // We do not want to profile all the initialisation.
    futhark_context_pause_profiling(ctx);
    // Declare and read input.
    set_binary_mode(stdin);
    
    struct futhark_u64_1d * read_value_0;
    int64_t read_shape_0[1];
    uint64_t *read_arr_0 = NULL;
    
    errno = 0;
    if (read_array(stdin, &u64_info, (void **) &read_arr_0, read_shape_0, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 0, "[]u64", strerror(errno));
    
    struct futhark_u64_1d * read_value_1;
    int64_t read_shape_1[1];
    uint64_t *read_arr_1 = NULL;
    
    errno = 0;
    if (read_array(stdin, &u64_info, (void **) &read_arr_1, read_shape_1, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 1, "[]u64", strerror(errno));
    
    struct futhark_u64_1d * read_value_2;
    int64_t read_shape_2[1];
    uint64_t *read_arr_2 = NULL;
    
    errno = 0;
    if (read_array(stdin, &u64_info, (void **) &read_arr_2, read_shape_2, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 2, "[]u64", strerror(errno));
    if (end_of_input(stdin) != 0)
        futhark_panic(1, "Expected EOF on stdin after reading input for \"%s\".\n", "big_add_validation");
    
    bool result_0;
    
    if (perform_warmup) {
        int r;
        
        assert((read_value_0 = futhark_new_u64_1d(ctx, read_arr_0, read_shape_0[0])) != NULL);
        assert((read_value_1 = futhark_new_u64_1d(ctx, read_arr_1, read_shape_1[0])) != NULL);
        assert((read_value_2 = futhark_new_u64_1d(ctx, read_arr_2, read_shape_2[0])) != NULL);
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        // Only profile last run.
        if (profile_run)
            futhark_context_unpause_profiling(ctx);
        t_start = get_wall_time();
        r = futhark_entry_big_add_validation(ctx, &result_0, read_value_0, read_value_1, read_value_2);
        if (r != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        if (profile_run)
            futhark_context_pause_profiling(ctx);
        t_end = get_wall_time();
        
        long elapsed_usec = t_end - t_start;
        
        if (time_runs && runtime_file != NULL) {
            fprintf(runtime_file, "%lld\n", (long long) elapsed_usec);
            fflush(runtime_file);
        }
        assert(futhark_free_u64_1d(ctx, read_value_0) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_1) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_2) == 0);
        ;
    }
    time_runs = 1;
    // Proper run.
    for (int run = 0; run < num_runs; run++) {
        // Only profile last run.
        profile_run = run == num_runs - 1;
        
        int r;
        
        assert((read_value_0 = futhark_new_u64_1d(ctx, read_arr_0, read_shape_0[0])) != NULL);
        assert((read_value_1 = futhark_new_u64_1d(ctx, read_arr_1, read_shape_1[0])) != NULL);
        assert((read_value_2 = futhark_new_u64_1d(ctx, read_arr_2, read_shape_2[0])) != NULL);
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        // Only profile last run.
        if (profile_run)
            futhark_context_unpause_profiling(ctx);
        t_start = get_wall_time();
        r = futhark_entry_big_add_validation(ctx, &result_0, read_value_0, read_value_1, read_value_2);
        if (r != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        if (profile_run)
            futhark_context_pause_profiling(ctx);
        t_end = get_wall_time();
        
        long elapsed_usec = t_end - t_start;
        
        if (time_runs && runtime_file != NULL) {
            fprintf(runtime_file, "%lld\n", (long long) elapsed_usec);
            fflush(runtime_file);
        }
        assert(futhark_free_u64_1d(ctx, read_value_0) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_1) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_2) == 0);
        if (run < num_runs - 1) {
            ;
        }
    }
    free(read_arr_0);
    free(read_arr_1);
    free(read_arr_2);
    if (print_result) {
        // Print the final result.
        if (binary_output)
            set_binary_mode(stdout);
        write_scalar(stdout, binary_output, &bool_info, &result_0);
        printf("\n");
    }
    
  print_end:
    { }
    ;
    return retval;
}
static int futrts_cli_entry_big_mul_debug(struct futhark_context *ctx)
{
    int64_t t_start, t_end;
    int time_runs = 0, profile_run = 0;
    int retval = 0;
    
    // We do not want to profile all the initialisation.
    futhark_context_pause_profiling(ctx);
    // Declare and read input.
    set_binary_mode(stdin);
    
    struct futhark_u64_1d * read_value_0;
    int64_t read_shape_0[1];
    uint64_t *read_arr_0 = NULL;
    
    errno = 0;
    if (read_array(stdin, &u64_info, (void **) &read_arr_0, read_shape_0, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 0, "[]u64", strerror(errno));
    
    struct futhark_u64_1d * read_value_1;
    int64_t read_shape_1[1];
    uint64_t *read_arr_1 = NULL;
    
    errno = 0;
    if (read_array(stdin, &u64_info, (void **) &read_arr_1, read_shape_1, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 1, "[]u64", strerror(errno));
    
    struct futhark_u64_1d * read_value_2;
    int64_t read_shape_2[1];
    uint64_t *read_arr_2 = NULL;
    
    errno = 0;
    if (read_array(stdin, &u64_info, (void **) &read_arr_2, read_shape_2, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 2, "[]u64", strerror(errno));
    if (end_of_input(stdin) != 0)
        futhark_panic(1, "Expected EOF on stdin after reading input for \"%s\".\n", "big_mul_debug");
    
    struct futhark_u64_1d * result_0;
    struct futhark_u64_1d * result_1;
    struct futhark_i64_1d * result_2;
    
    if (perform_warmup) {
        int r;
        
        assert((read_value_0 = futhark_new_u64_1d(ctx, read_arr_0, read_shape_0[0])) != NULL);
        assert((read_value_1 = futhark_new_u64_1d(ctx, read_arr_1, read_shape_1[0])) != NULL);
        assert((read_value_2 = futhark_new_u64_1d(ctx, read_arr_2, read_shape_2[0])) != NULL);
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        // Only profile last run.
        if (profile_run)
            futhark_context_unpause_profiling(ctx);
        t_start = get_wall_time();
        r = futhark_entry_big_mul_debug(ctx, &result_0, &result_1, &result_2, read_value_0, read_value_1, read_value_2);
        if (r != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        if (profile_run)
            futhark_context_pause_profiling(ctx);
        t_end = get_wall_time();
        
        long elapsed_usec = t_end - t_start;
        
        if (time_runs && runtime_file != NULL) {
            fprintf(runtime_file, "%lld\n", (long long) elapsed_usec);
            fflush(runtime_file);
        }
        assert(futhark_free_u64_1d(ctx, read_value_0) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_1) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_2) == 0);
        assert(futhark_free_u64_1d(ctx, result_0) == 0);
        assert(futhark_free_u64_1d(ctx, result_1) == 0);
        assert(futhark_free_i64_1d(ctx, result_2) == 0);
    }
    time_runs = 1;
    // Proper run.
    for (int run = 0; run < num_runs; run++) {
        // Only profile last run.
        profile_run = run == num_runs - 1;
        
        int r;
        
        assert((read_value_0 = futhark_new_u64_1d(ctx, read_arr_0, read_shape_0[0])) != NULL);
        assert((read_value_1 = futhark_new_u64_1d(ctx, read_arr_1, read_shape_1[0])) != NULL);
        assert((read_value_2 = futhark_new_u64_1d(ctx, read_arr_2, read_shape_2[0])) != NULL);
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        // Only profile last run.
        if (profile_run)
            futhark_context_unpause_profiling(ctx);
        t_start = get_wall_time();
        r = futhark_entry_big_mul_debug(ctx, &result_0, &result_1, &result_2, read_value_0, read_value_1, read_value_2);
        if (r != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        if (profile_run)
            futhark_context_pause_profiling(ctx);
        t_end = get_wall_time();
        
        long elapsed_usec = t_end - t_start;
        
        if (time_runs && runtime_file != NULL) {
            fprintf(runtime_file, "%lld\n", (long long) elapsed_usec);
            fflush(runtime_file);
        }
        assert(futhark_free_u64_1d(ctx, read_value_0) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_1) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_2) == 0);
        if (run < num_runs - 1) {
            assert(futhark_free_u64_1d(ctx, result_0) == 0);
            assert(futhark_free_u64_1d(ctx, result_1) == 0);
            assert(futhark_free_i64_1d(ctx, result_2) == 0);
        }
    }
    free(read_arr_0);
    free(read_arr_1);
    free(read_arr_2);
    if (print_result) {
        // Print the final result.
        if (binary_output)
            set_binary_mode(stdout);
        {
            uint64_t *arr = calloc(futhark_shape_u64_1d(ctx, result_0)[0], u64_info.size);
            
            assert(arr != NULL);
            assert(futhark_values_u64_1d(ctx, result_0, arr) == 0);
            assert(futhark_context_sync(ctx) == 0);
            write_array(stdout, binary_output, &u64_info, arr, futhark_shape_u64_1d(ctx, result_0), 1);
            free(arr);
        }
        printf("\n");
        {
            uint64_t *arr = calloc(futhark_shape_u64_1d(ctx, result_1)[0], u64_info.size);
            
            assert(arr != NULL);
            assert(futhark_values_u64_1d(ctx, result_1, arr) == 0);
            assert(futhark_context_sync(ctx) == 0);
            write_array(stdout, binary_output, &u64_info, arr, futhark_shape_u64_1d(ctx, result_1), 1);
            free(arr);
        }
        printf("\n");
        {
            int64_t *arr = calloc(futhark_shape_i64_1d(ctx, result_2)[0], i64_info.size);
            
            assert(arr != NULL);
            assert(futhark_values_i64_1d(ctx, result_2, arr) == 0);
            assert(futhark_context_sync(ctx) == 0);
            write_array(stdout, binary_output, &i64_info, arr, futhark_shape_i64_1d(ctx, result_2), 1);
            free(arr);
        }
        printf("\n");
    }
    
  print_end:
    { }
    assert(futhark_free_u64_1d(ctx, result_0) == 0);
    assert(futhark_free_u64_1d(ctx, result_1) == 0);
    assert(futhark_free_i64_1d(ctx, result_2) == 0);
    return retval;
}
static int futrts_cli_entry_big_mul_validation(struct futhark_context *ctx)
{
    int64_t t_start, t_end;
    int time_runs = 0, profile_run = 0;
    int retval = 0;
    
    // We do not want to profile all the initialisation.
    futhark_context_pause_profiling(ctx);
    // Declare and read input.
    set_binary_mode(stdin);
    
    struct futhark_u64_1d * read_value_0;
    int64_t read_shape_0[1];
    uint64_t *read_arr_0 = NULL;
    
    errno = 0;
    if (read_array(stdin, &u64_info, (void **) &read_arr_0, read_shape_0, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 0, "[]u64", strerror(errno));
    
    struct futhark_u64_1d * read_value_1;
    int64_t read_shape_1[1];
    uint64_t *read_arr_1 = NULL;
    
    errno = 0;
    if (read_array(stdin, &u64_info, (void **) &read_arr_1, read_shape_1, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 1, "[]u64", strerror(errno));
    
    struct futhark_u64_1d * read_value_2;
    int64_t read_shape_2[1];
    uint64_t *read_arr_2 = NULL;
    
    errno = 0;
    if (read_array(stdin, &u64_info, (void **) &read_arr_2, read_shape_2, 1) != 0)
        futhark_panic(1, "Cannot read input #%d of type %s (errno: %s).\n", 2, "[]u64", strerror(errno));
    if (end_of_input(stdin) != 0)
        futhark_panic(1, "Expected EOF on stdin after reading input for \"%s\".\n", "big_mul_validation");
    
    bool result_0;
    
    if (perform_warmup) {
        int r;
        
        assert((read_value_0 = futhark_new_u64_1d(ctx, read_arr_0, read_shape_0[0])) != NULL);
        assert((read_value_1 = futhark_new_u64_1d(ctx, read_arr_1, read_shape_1[0])) != NULL);
        assert((read_value_2 = futhark_new_u64_1d(ctx, read_arr_2, read_shape_2[0])) != NULL);
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        // Only profile last run.
        if (profile_run)
            futhark_context_unpause_profiling(ctx);
        t_start = get_wall_time();
        r = futhark_entry_big_mul_validation(ctx, &result_0, read_value_0, read_value_1, read_value_2);
        if (r != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        if (profile_run)
            futhark_context_pause_profiling(ctx);
        t_end = get_wall_time();
        
        long elapsed_usec = t_end - t_start;
        
        if (time_runs && runtime_file != NULL) {
            fprintf(runtime_file, "%lld\n", (long long) elapsed_usec);
            fflush(runtime_file);
        }
        assert(futhark_free_u64_1d(ctx, read_value_0) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_1) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_2) == 0);
        ;
    }
    time_runs = 1;
    // Proper run.
    for (int run = 0; run < num_runs; run++) {
        // Only profile last run.
        profile_run = run == num_runs - 1;
        
        int r;
        
        assert((read_value_0 = futhark_new_u64_1d(ctx, read_arr_0, read_shape_0[0])) != NULL);
        assert((read_value_1 = futhark_new_u64_1d(ctx, read_arr_1, read_shape_1[0])) != NULL);
        assert((read_value_2 = futhark_new_u64_1d(ctx, read_arr_2, read_shape_2[0])) != NULL);
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        // Only profile last run.
        if (profile_run)
            futhark_context_unpause_profiling(ctx);
        t_start = get_wall_time();
        r = futhark_entry_big_mul_validation(ctx, &result_0, read_value_0, read_value_1, read_value_2);
        if (r != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        if (futhark_context_sync(ctx) != 0)
            futhark_panic(1, "%s", futhark_context_get_error(ctx));
        ;
        if (profile_run)
            futhark_context_pause_profiling(ctx);
        t_end = get_wall_time();
        
        long elapsed_usec = t_end - t_start;
        
        if (time_runs && runtime_file != NULL) {
            fprintf(runtime_file, "%lld\n", (long long) elapsed_usec);
            fflush(runtime_file);
        }
        assert(futhark_free_u64_1d(ctx, read_value_0) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_1) == 0);
        assert(futhark_free_u64_1d(ctx, read_value_2) == 0);
        if (run < num_runs - 1) {
            ;
        }
    }
    free(read_arr_0);
    free(read_arr_1);
    free(read_arr_2);
    if (print_result) {
        // Print the final result.
        if (binary_output)
            set_binary_mode(stdout);
        write_scalar(stdout, binary_output, &bool_info, &result_0);
        printf("\n");
    }
    
  print_end:
    { }
    ;
    return retval;
}
typedef int entry_point_fun(struct futhark_context *);
struct entry_point_entry {
    const char *name;
    entry_point_fun *fun;
};
int main(int argc, char **argv)
{
    int retval = 0;
    
    fut_progname = argv[0];
    
    struct futhark_context_config *cfg = futhark_context_config_new();
    
    assert(cfg != NULL);
    
    int parsed_options = parse_options(cfg, argc, argv);
    
    argc -= parsed_options;
    argv += parsed_options;
    if (argc != 0)
        futhark_panic(1, "Excess non-option: %s\n", argv[0]);
    
    struct futhark_context *ctx = futhark_context_new(cfg);
    
    assert(ctx != NULL);
    
    char *error = futhark_context_get_error(ctx);
    
    if (error != NULL)
        futhark_panic(1, "%s", error);
    
    struct entry_point_entry entry_points[] = {{.name ="big_add_debug", .fun =futrts_cli_entry_big_add_debug}, {.name ="big_add_validation", .fun =futrts_cli_entry_big_add_validation}, {.name ="big_mul_debug", .fun =futrts_cli_entry_big_mul_debug}, {.name ="big_mul_validation", .fun =futrts_cli_entry_big_mul_validation}};
    
    if (entry_point != NULL) {
        int num_entry_points = sizeof(entry_points) / sizeof(entry_points[0]);
        entry_point_fun *entry_point_fun = NULL;
        
        for (int i = 0; i < num_entry_points; i++) {
            if (strcmp(entry_points[i].name, entry_point) == 0) {
                entry_point_fun = entry_points[i].fun;
                break;
            }
        }
        if (entry_point_fun == NULL) {
            fprintf(stderr, "No entry point '%s'.  Select another with --entry-point.  Options are:\n", entry_point);
            for (int i = 0; i < num_entry_points; i++)
                fprintf(stderr, "%s\n", entry_points[i].name);
            return 1;
        }
        if (isatty(fileno(stdin))) {
            fprintf(stderr, "Reading input from TTY.\n");
            fprintf(stderr, "Send EOF (CTRL-d) after typing all input values.\n");
        }
        retval = entry_point_fun(ctx);
        if (runtime_file != NULL)
            fclose(runtime_file);
        if (print_report) {
            char *report = futhark_context_report(ctx);
            
            fputs(report, stderr);
            free(report);
        }
    }
    futhark_context_free(ctx);
    futhark_context_config_free(cfg);
    return retval;
}

#ifdef _MSC_VER
#define inline __inline
#endif
#include <string.h>
#include <string.h>
#include <errno.h>
#include <assert.h>
#include <ctype.h>


#include <cuda.h>
#include <cuda_runtime.h>
#include <nvrtc.h>


#define FUTHARK_F64_ENABLED

// Start of scalar.h.

// Implementation of the primitive scalar operations.  Very
// repetitive.  This code is inserted directly into both CUDA and
// OpenCL programs, as well as the CPU code, so it has some #ifdefs to
// work everywhere.  Some operations are defined as macros because
// this allows us to use them as constant expressions in things like
// array sizes and static initialisers.

// Some of the #ifdefs are because OpenCL uses type-generic functions
// for some operations (e.g. sqrt), while C and CUDA sensibly use
// distinct functions for different precisions (e.g. sqrtf() and
// sqrt()).  This is quite annoying.  Due to C's unfortunate casting
// rules, it is also really easy to accidentally implement
// floating-point functions in the wrong precision, so be careful.

// Double-precision definitions are only included if the preprocessor
// macro FUTHARK_F64_ENABLED is set.

SCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {
  return x + y;
}

SCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {
  return x - y;
}

SCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {
  return x * y;
}

SCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {
  return x * y;
}

#if ISPC

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  // This strange pattern is used to prevent the ISPC compiler from
  // causing SIGFPEs and bogus results on divisions where inactive lanes
  // have 0-valued divisors. It ensures that any inactive lane instead
  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }


  return x % ys;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : (x + y - 1) / ys;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  uint8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  uint16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  uint32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  uint64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t q = x / ys;
  int8_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t q = x / ys;
  int16_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }
  int32_t q = x / ys;
  int32_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t q = x / ys;
  int64_t r = x % ys;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int8_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int16_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int32_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  int64_t r = x % ys;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x / ys;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return x % ys;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x / ys;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  int8_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  int16_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  int32_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  int64_t ys = 1;
  foreach_active(i){
    ys = y;
  }

  return y == 0 ? 0 : x % ys;
}

#else

SCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {
  return (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : (x + y - 1) / y;
}

SCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {
  int8_t q = x / y;
  int8_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {
  int16_t q = x / y;
  int16_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {
  int32_t q = x / y;
  int32_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {
  int64_t q = x / y;
  int64_t r = x % y;

  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);
}

SCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {
  return sdiv8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {
  return sdiv16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {
  return sdiv32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {
  return sdiv64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {
  int8_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {
  int16_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {
  int32_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {
  int64_t r = x % y;

  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);
}

SCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : sdiv8(x, y);
}

SCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : sdiv16(x, y);
}

SCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : sdiv32(x, y);
}

SCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : sdiv64(x, y);
}

SCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {
  return sdiv_safe8(x + y - 1, y);
}

SCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {
  return sdiv_safe16(x + y - 1, y);
}

SCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {
  return sdiv_safe32(x + y - 1, y);
}

SCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {
  return sdiv_safe64(x + y - 1, y);
}

SCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : smod8(x, y);
}

SCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : smod16(x, y);
}

SCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : smod32(x, y);
}

SCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : smod64(x, y);
}

SCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {
  return x / y;
}

SCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {
  return x % y;
}

SCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x / y;
}

SCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {
  return y == 0 ? 0 : x % y;
}

SCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {
  return y == 0 ? 0 : x % y;
}

#endif

SCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {
  return x < y ? x : y;
}

SCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {
  return x < y ? y : x;
}

SCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {
  return (uint8_t)(x << y);
}

SCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {
  return (uint16_t)(x << y);
}

SCALAR_FUN_ATTR uint32_t shl32(uint32_t x, uint32_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {
  return x << y;
}

SCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {
  return x >> y;
}

SCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {
  return x & y;
}

SCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {
  return x | y;
}

SCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {
  return x ^ y;
}

SCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule16(uint16_t x, uint16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {
  return x < y;
}

SCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {
  return x <= y;
}

SCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {
  uint8_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {
  uint16_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {
  uint32_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {
  uint64_t res = 1, rem = y;

  while (rem != 0) {
    if (rem & 1)
      res *= x;
    rem >>= 1;
    x *= x;
  }
  return res;
}

SCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {
  return x != 0;
}

SCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {
  return x;
}

SCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) {
  return x;
}

SCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {
  return x;
}

SCALAR_FUN_ATTR int64_t btoi_bool_i64(bool x) {
  return x;
}

#define sext_i8_i8(x) ((int8_t) (int8_t) (x))
#define sext_i8_i16(x) ((int16_t) (int8_t) (x))
#define sext_i8_i32(x) ((int32_t) (int8_t) (x))
#define sext_i8_i64(x) ((int64_t) (int8_t) (x))
#define sext_i16_i8(x) ((int8_t) (int16_t) (x))
#define sext_i16_i16(x) ((int16_t) (int16_t) (x))
#define sext_i16_i32(x) ((int32_t) (int16_t) (x))
#define sext_i16_i64(x) ((int64_t) (int16_t) (x))
#define sext_i32_i8(x) ((int8_t) (int32_t) (x))
#define sext_i32_i16(x) ((int16_t) (int32_t) (x))
#define sext_i32_i32(x) ((int32_t) (int32_t) (x))
#define sext_i32_i64(x) ((int64_t) (int32_t) (x))
#define sext_i64_i8(x) ((int8_t) (int64_t) (x))
#define sext_i64_i16(x) ((int16_t) (int64_t) (x))
#define sext_i64_i32(x) ((int32_t) (int64_t) (x))
#define sext_i64_i64(x) ((int64_t) (int64_t) (x))
#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))
#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))
#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))
#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))
#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))
#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))
#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))
#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))
#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))
#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))
#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))
#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))
#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))
#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))
#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))
#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))

SCALAR_FUN_ATTR int8_t abs8(int8_t x) {
  return (int8_t)abs(x);
}

SCALAR_FUN_ATTR int16_t abs16(int16_t x) {
  return (int16_t)abs(x);
}

SCALAR_FUN_ATTR int32_t abs32(int32_t x) {
  return abs(x);
}

SCALAR_FUN_ATTR int64_t abs64(int64_t x) {
#if defined(__OPENCL_VERSION__) || defined(ISPC)
  return abs(x);
#else
  return llabs(x);
#endif
}

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return popcount(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return popcount(x);
}
#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {
  return __popc(zext_i8_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {
  return __popc(zext_i16_i32(x));
}

SCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {
  return __popc(x);
}

SCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {
  return __popcll(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}

SCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {
  int c = 0;
  for (; x; ++c) { x &= x - 1; }
  return c;
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }
#elif defined(__CUDA_ARCH__)
SCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }
SCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }
SCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }
#elif ISPC
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 = al * bl;
  uint64_t p2 = al * bh;
  uint64_t p3 = ah * bl;
  uint64_t p4 = ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}
SCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) {
  uint64_t ah = a >> 32;
  uint64_t al = a & 0xffffffff;
  uint64_t bh = b >> 32;
  uint64_t bl = b & 0xffffffff;

  uint64_t p1 =  al * bl;
  int64_t  p2 = al * bh;
  int64_t  p3 = ah * bl;
  uint64_t p4 =  ah * bh;

  uint64_t p1h = p1 >> 32;
  uint64_t p2h = p2 >> 32;
  uint64_t p3h = p3 >> 32;
  uint64_t p2l = p2 & 0xffffffff;
  uint64_t p3l = p3 & 0xffffffff;

  uint64_t l = p1h + p2l + p3l;
  uint64_t m = (p2 >> 32) + (p3 >> 32);
  uint64_t h = (l >> 32) + m + p4;

  return h;
}

#else // Not OpenCL, ISPC, or CUDA, but plain C.
SCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }
SCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }
SCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }
SCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }
SCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }
SCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }
SCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }
SCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  int8_t b,   int8_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }
#else // Not OpenCL

SCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }
SCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }
SCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }
SCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }
SCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return clz(x);
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return __clz(zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return __clz(zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return __clz(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return __clzll(x);
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return count_leading_zeros((int32_t)(uint8_t)x)-24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return count_leading_zeros((int32_t)(uint16_t)x)-16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return count_leading_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return count_leading_zeros(x);
}

#else // Not OpenCL, ISPC or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;
}

SCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;
}

SCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_clz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);
}
#endif

#if defined(__OPENCL_VERSION__)
SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int i = 0;
  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int i = 0;
  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int i = 0;
  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int i = 0;
  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)
    ;
  return i;
}

#elif defined(__CUDA_ARCH__)

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  int y = __ffs(x);
  return y == 0 ? 8 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  int y = __ffs(x);
  return y == 0 ? 16 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  int y = __ffs(x);
  return y == 0 ? 32 : y - 1;
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  int y = __ffsll(x);
  return y == 0 ? 64 : y - 1;
}

#elif ISPC

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return count_trailing_zeros(x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return count_trailing_zeros(x);
}

#else // Not OpenCL or CUDA, but plain C.

SCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {
  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {
  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {
  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);
}

SCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {
  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);
}
#endif

SCALAR_FUN_ATTR float fdiv32(float x, float y) {
  return x / y;
}

SCALAR_FUN_ATTR float fadd32(float x, float y) {
  return x + y;
}

SCALAR_FUN_ATTR float fsub32(float x, float y) {
  return x - y;
}

SCALAR_FUN_ATTR float fmul32(float x, float y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt32(float x, float y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple32(float x, float y) {
  return x <= y;
}

SCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {
  return (float) x;
}

SCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {
  return (float) x;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float fabs32(float x) {
  return fabs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return pow(x, y);
}

#elif ISPC

SCALAR_FUN_ATTR float fabs32(float x) {
  return abs(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR float fpow32(float a, float b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

#else // Not OpenCL, but CUDA or plain C.

SCALAR_FUN_ATTR float fabs32(float x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR float fmax32(float x, float y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR float fmin32(float x, float y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR float fpow32(float x, float y) {
  return powf(x, y);
}
#endif

SCALAR_FUN_ATTR bool futrts_isnan32(float x) {
  return isnan(x);
}

#if ISPC

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite32(float x) {
  return !isnan(x) && !futrts_isinf32(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf32(float x) {
  return isinf(x);
}

#endif

SCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (int64_t) x;
  };
}

SCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {
  if (futrts_isnan32(x) || futrts_isinf32(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f32_bool(float x) {
  return x != 0;
}

SCALAR_FUN_ATTR float btof_bool_f32(bool x) {
  return x ? 1 : 0;
}

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR float futrts_log32(float x) {
  return log(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1p(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return cosh(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinh(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanh(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acosh(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinh(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanh(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erf(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfc(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rint(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fma(a, b, c);
}

#elif ISPC

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return futrts_log32(x) / log(2.0f);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return futrts_log32(x) / log(10.0f);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;
  float y = 1.0f + x;
  float z = y - 1.0f;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrt(x);
}

extern "C" unmasked uniform float cbrtf(uniform float);
SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return exp(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cos(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sin(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tan(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acos(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asin(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atan(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return (exp(x)+exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return (exp(x)-exp(-x)) / 2.0f;
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return futrts_sinh32(x)/futrts_cosh32(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  float f = x+sqrt(x*x-1);
  if(futrts_isfinite32(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  float f = x+sqrt(x*x+1);
  if(futrts_isfinite32(f)) return log(f);
  return f;

}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  float f = (1+x)/(1-x);
  if(futrts_isfinite32(f)) return log(f)/2.0f;
  return f;

}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {
    x = abs(x);
    y = abs(y);
    float a;
    float b;
    if (x >= y){
        a = x;
        b = y;
    } else {
        a = y;
        b = x;
    }
    if(b == 0){
      return a;
    }

    int e;
    float an;
    float bn;
    an = frexp (a, &e);
    bn = ldexp (b, - e);
    float cn;
    cn = sqrt (an * an + bn * bn);
    return ldexp (cn, e);
  } else {
    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;
    else return x + y;
  }

}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = tgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = lgammaf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erff(uniform float x);
SCALAR_FUN_ATTR float futrts_erf32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erff(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float erfcf(uniform float x);
SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  float res;
  foreach_active (i) {
    uniform float r = erfcf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return round(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floor(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceil(x);
}

extern "C" unmasked uniform float nextafterf(uniform float x, uniform float y);
SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  float res;
  foreach_active (i) {
    uniform float r = nextafterf(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return a * b + c;
}

#else // Not OpenCL or ISPC, but CUDA or plain C.

SCALAR_FUN_ATTR float futrts_log32(float x) {
  return logf(x);
}

SCALAR_FUN_ATTR float futrts_log2_32(float x) {
  return log2f(x);
}

SCALAR_FUN_ATTR float futrts_log10_32(float x) {
  return log10f(x);
}

SCALAR_FUN_ATTR float futrts_log1p_32(float x) {
  return log1pf(x);
}

SCALAR_FUN_ATTR float futrts_sqrt32(float x) {
  return sqrtf(x);
}

SCALAR_FUN_ATTR float futrts_cbrt32(float x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR float futrts_exp32(float x) {
  return expf(x);
}

SCALAR_FUN_ATTR float futrts_cos32(float x) {
  return cosf(x);
}

SCALAR_FUN_ATTR float futrts_sin32(float x) {
  return sinf(x);
}

SCALAR_FUN_ATTR float futrts_tan32(float x) {
  return tanf(x);
}

SCALAR_FUN_ATTR float futrts_acos32(float x) {
  return acosf(x);
}

SCALAR_FUN_ATTR float futrts_asin32(float x) {
  return asinf(x);
}

SCALAR_FUN_ATTR float futrts_atan32(float x) {
  return atanf(x);
}

SCALAR_FUN_ATTR float futrts_cosh32(float x) {
  return coshf(x);
}

SCALAR_FUN_ATTR float futrts_sinh32(float x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR float futrts_tanh32(float x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR float futrts_acosh32(float x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR float futrts_asinh32(float x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR float futrts_atanh32(float x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR float futrts_gamma32(float x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR float futrts_lgamma32(float x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR float futrts_erf32(float x) {
  return erff(x);
}

SCALAR_FUN_ATTR float futrts_erfc32(float x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR float fmod32(float x, float y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR float futrts_round32(float x) {
  return rintf(x);
}

SCALAR_FUN_ATTR float futrts_floor32(float x) {
  return floorf(x);
}

SCALAR_FUN_ATTR float futrts_ceil32(float x) {
  return ceilf(x);
}

SCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {
  return nextafterf(x, y);
}

SCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {
  return fmaf(a, b, c);
}
#endif

#if ISPC
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  return intbits(x);
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  return floatbits(x);
}
#else
SCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {
  union {
    float f;
    int32_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {
  union {
    int32_t f;
    float t;
  } p;

  p.f = x;
  return p.t;
}
#endif

SCALAR_FUN_ATTR float fsignum32(float x) {
  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#ifdef FUTHARK_F64_ENABLED

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf64(float x) {
  return !isnan(x) && isnan(x - x);
}

SCALAR_FUN_ATTR bool futrts_isfinite64(float x) {
  return !isnan(x) && !futrts_isinf64(x);
}

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return abs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return isnan(x) ? y : isnan(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR double fpow64(double a, double b) {
  float ret;
  foreach_active (i) {
      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));
      ret = insert(ret, i, r);
  }
  return ret;
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return futrts_log64(x)/log(2.0d);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return futrts_log64(x)/log(10.0d);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;
  double y = 1.0d + x;
  double z = y - 1.0d;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

extern "C" unmasked uniform double cbrt(uniform double);
SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = cbrtf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return (exp(x)+exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return (exp(x)-exp(-x)) / 2.0d;
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return futrts_sinh64(x)/futrts_cosh64(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  double f = x+sqrt(x*x-1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  double f = x+sqrt(x*x+1.0d);
  if(futrts_isfinite64(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  double f = (1.0d+x)/(1.0d-x);
  if(futrts_isfinite64(f)) return log(f)/2.0d;
  return f;

}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

extern "C" unmasked uniform double hypot(uniform double x, uniform double y);
SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = hypot(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double tgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = tgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double lgamma(uniform double x);
SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = lgamma(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erf(uniform double x);
SCALAR_FUN_ATTR double futrts_erf64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erf(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform double erfc(uniform double x);
SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  double res;
  foreach_active (i) {
    uniform double r = erfc(extract(x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return round(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

extern "C" unmasked uniform double nextafter(uniform float x, uniform double y);
SCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {
  double res;
  foreach_active (i) {
    uniform double r = nextafter(extract(x, i), extract(y, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0.0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1.0 : 0.0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  int64_t res;
  foreach_active (i) {
    uniform double tmp = extract(x, i);
    uniform int64_t r = *((uniform int64_t* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  double res;
  foreach_active (i) {
    uniform int64_t tmp = extract(x, i);
    uniform double r = *((uniform double* uniform)&tmp);
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return x - y * trunc(x/y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
  return a * b + c;
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#else

SCALAR_FUN_ATTR double fdiv64(double x, double y) {
  return x / y;
}

SCALAR_FUN_ATTR double fadd64(double x, double y) {
  return x + y;
}

SCALAR_FUN_ATTR double fsub64(double x, double y) {
  return x - y;
}

SCALAR_FUN_ATTR double fmul64(double x, double y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt64(double x, double y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple64(double x, double y) {
  return x <= y;
}

SCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {
  return (double) x;
}

SCALAR_FUN_ATTR double fabs64(double x) {
  return fabs(x);
}

SCALAR_FUN_ATTR double fmax64(double x, double y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR double fmin64(double x, double y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR double fpow64(double x, double y) {
  return pow(x, y);
}

SCALAR_FUN_ATTR double futrts_log64(double x) {
  return log(x);
}

SCALAR_FUN_ATTR double futrts_log2_64(double x) {
  return log2(x);
}

SCALAR_FUN_ATTR double futrts_log10_64(double x) {
  return log10(x);
}

SCALAR_FUN_ATTR double futrts_log1p_64(double x) {
  return log1p(x);
}

SCALAR_FUN_ATTR double futrts_sqrt64(double x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR double futrts_cbrt64(double x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR double futrts_exp64(double x) {
  return exp(x);
}

SCALAR_FUN_ATTR double futrts_cos64(double x) {
  return cos(x);
}

SCALAR_FUN_ATTR double futrts_sin64(double x) {
  return sin(x);
}

SCALAR_FUN_ATTR double futrts_tan64(double x) {
  return tan(x);
}

SCALAR_FUN_ATTR double futrts_acos64(double x) {
  return acos(x);
}

SCALAR_FUN_ATTR double futrts_asin64(double x) {
  return asin(x);
}

SCALAR_FUN_ATTR double futrts_atan64(double x) {
  return atan(x);
}

SCALAR_FUN_ATTR double futrts_cosh64(double x) {
  return cosh(x);
}

SCALAR_FUN_ATTR double futrts_sinh64(double x) {
  return sinh(x);
}

SCALAR_FUN_ATTR double futrts_tanh64(double x) {
  return tanh(x);
}

SCALAR_FUN_ATTR double futrts_acosh64(double x) {
  return acosh(x);
}

SCALAR_FUN_ATTR double futrts_asinh64(double x) {
  return asinh(x);
}

SCALAR_FUN_ATTR double futrts_atanh64(double x) {
  return atanh(x);
}

SCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR double futrts_gamma64(double x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR double futrts_lgamma64(double x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR double futrts_erf64(double x) {
  return erf(x);
}

SCALAR_FUN_ATTR double futrts_erfc64(double x) {
  return erfc(x);
}

SCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {
  return fma(a, b, c);
}

SCALAR_FUN_ATTR double futrts_round64(double x) {
  return rint(x);
}

SCALAR_FUN_ATTR double futrts_ceil64(double x) {
  return ceil(x);
}

SCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR double futrts_floor64(double x) {
  return floor(x);
}

SCALAR_FUN_ATTR bool futrts_isnan64(double x) {
  return isnan(x);
}

SCALAR_FUN_ATTR bool futrts_isinf64(double x) {
  return isinf(x);
}

SCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int8_t) x;
  }
}

SCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int16_t) x;
  }
}

SCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int32_t) x;
  }
}

SCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (int64_t) x;
  }
}

SCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint8_t) (int8_t) x;
  }
}

SCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint16_t) (int16_t) x;
  }
}

SCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint32_t) (int32_t) x;
  }
}

SCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {
  if (futrts_isnan64(x) || futrts_isinf64(x)) {
    return 0;
  } else {
    return (uint64_t) (int64_t) x;
  }
}

SCALAR_FUN_ATTR bool ftob_f64_bool(double x) {
  return x != 0;
}

SCALAR_FUN_ATTR double btof_bool_f64(bool x) {
  return x ? 1 : 0;
}

SCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {
  union {
    double f;
    int64_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {
  union {
    int64_t f;
    double t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR double fmod64(double x, double y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR double fsignum64(double x) {
  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);
}

SCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {
#ifdef __OPENCL_VERSION__
  return mix(v0, v1, t);
#else
  return v0 + (v1 - v0) * t;
#endif
}

SCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {
#ifdef __OPENCL_VERSION__
  return mad(a, b, c);
#else
  return a * b + c;
#endif
}

SCALAR_FUN_ATTR float fpconv_f32_f32(float x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f32_f64(float x) {
  return (double) x;
}

SCALAR_FUN_ATTR float fpconv_f64_f32(double x) {
  return (float) x;
}

SCALAR_FUN_ATTR double fpconv_f64_f64(double x) {
  return (double) x;
}

#endif

#endif

// End of scalar.h.
// Start of scalar_f16.h.

// Half-precision is emulated if needed (e.g. in straight C) with the
// native type used if possible.  The emulation works by typedef'ing
// 'float' to 'f16', and then implementing all operations on single
// precision.  To cut down on duplication, we use the same code for
// those Futhark functions that require just operators or casts.  The
// in-memory representation for arrays will still be 16 bits even
// under emulation, so the compiler will have to be careful when
// generating reads or writes.

#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))
#define EMULATE_F16
#endif

#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)
#pragma OPENCL EXTENSION cl_khr_fp16 : enable
#endif

#ifdef EMULATE_F16

// Note that the half-precision storage format is still 16 bits - the
// compiler will have to be real careful!
typedef float f16;

#elif ISPC
typedef float16 f16;

#else

#ifdef __CUDA_ARCH__
#include <cuda_fp16.h>
#endif

typedef half f16;

#endif

// Some of these functions convert to single precision because half
// precision versions are not available.

SCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {
  return x + y;
}

SCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {
  return x - y;
}

SCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {
  return x * y;
}

SCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {
  return x < y;
}

SCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {
  return x <= y;
}

SCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {
  return (f16) x;
}

SCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {
  return (int8_t) (float) x;
}

SCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {
  return (int16_t) x;
}

SCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {
  return (int32_t) x;
}

SCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {
  return (int64_t) x;
}

SCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {
  return (uint8_t) (float) x;
}

SCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {
  return (uint16_t) x;
}

SCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {
  return (uint32_t) x;
}

SCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {
  return (uint64_t) x;
}

SCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {
  return x != (f16)0;
}

SCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {
  return x ? 1 : 0;
}

#ifndef EMULATE_F16
SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return isnan((float)x);
}

#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}

#elif ISPC
SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return abs(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return pow(x, y);
}
#else // Assuming CUDA.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabsf(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmaxf(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fminf(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return powf(x, y);
}
#endif

#if ISPC
SCALAR_FUN_ATTR bool futrts_isinf16(float x) {
  return !futrts_isnan16(x) && futrts_isnan16(x - x);
}
SCALAR_FUN_ATTR bool futrts_isfinite16(float x) {
  return !futrts_isnan16(x) && !futrts_isinf16(x);
}

#else

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return isinf((float)x);
}
#endif

#ifdef __OPENCL_VERSION__
SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return log(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return log2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return log10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return log1p(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return sqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrt(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return cos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return sin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tan(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acos(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asin(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atan(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return cosh(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinh(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanh(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acosh(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinh(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanh(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypot(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgamma(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erf(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfc(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rint(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return floor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return ceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return nextafter(x, y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return mix(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return mad(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fma(a, b, c);
}
#elif ISPC

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log16(x) / log(2.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log16(x) / log(10.0f16);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;
  f16 y = 1.0f16 + x;
  f16 z = y - 1.0f16;
  return log(y) - (z-x)/y;
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return (float16)sqrt((float)x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return exp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return (float16)cos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return (float16)sin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return (float16)tan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return (float16)acos((float)x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return (float16)asin((float)x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return (float16)atan((float)x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return (exp(x)+exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return (exp(x)-exp(-x)) / 2.0f16;
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_sinh16(x)/futrts_cosh16(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x-1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  float16 f = x+(float16)sqrt((float)(x*x+1));
  if(futrts_isfinite16(f)) return log(f);
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  float16 f = (1+x)/(1-x);
  if(futrts_isfinite16(f)) return log(f)/2.0f16;
  return f;
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return (float16)atan2((float)x, (float)y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return (float16)futrts_hypot32((float)x, (float)y);
}

extern "C" unmasked uniform float tgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)tgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

extern "C" unmasked uniform float lgammaf(uniform float x);
SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  f16 res;
  foreach_active (i) {
    uniform f16 r = (f16)lgammaf(extract((float)x, i));
    res = insert(res, i, r);
  }
  return res;
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  f16 res = (f16)futrts_cbrt32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  f16 res = (f16)futrts_erf32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  f16 res = (f16)futrts_erfc32((float)x);
  return res;
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return x - y * (float16)trunc((float) (x/y));
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return (float16)round((float)x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return (float16)floor((float)x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return (float16)ceil((float)x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return (float16)futrts_nextafter32((float)x, (float) y);
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

#else // Assume CUDA.

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return hlog(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return hlog2(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return hlog10(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return (f16)log1pf((float)x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return hsqrt(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return cbrtf(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return hexp(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return hcos(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return hsin(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return tanf(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return acosf(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return asinf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return atanf(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return coshf(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return sinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return tanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return acoshf(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return asinhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return atanhf(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return atan2f(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return hypotf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return tgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return lgammaf(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return erff(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return erfcf(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmodf(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return rintf(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return hfloor(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return hceil(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return v0 + (v1 - v0) * t;
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return a * b + c;
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return fmaf(a, b, c);
}

#endif

// The CUDA __half type cannot be put in unions for some reason, so we
// use bespoke conversion functions instead.
#ifdef __CUDA_ARCH__
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return __half_as_ushort(x);
}
SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return __ushort_as_half(x);
}
#elif ISPC

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  varying int16_t y = *((varying int16_t * uniform)&x);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  varying f16 y = *((varying f16 * uniform)&x);
  return y;
}
#else
SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  union {
    f16 f;
    int16_t t;
  } p;

  p.f = x;
  return p.t;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  union {
    int16_t f;
    f16 t;
  } p;

  p.f = x;
  return p.t;
}
#endif

#else // No native f16 - emulate.

SCALAR_FUN_ATTR f16 fabs16(f16 x) {
  return fabs32(x);
}

SCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {
  return fmax32(x, y);
}

SCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {
  return fmin32(x, y);
}

SCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {
  return fpow32(x, y);
}

SCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {
  return futrts_isnan32(x);
}

SCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {
  return futrts_isinf32(x);
}

SCALAR_FUN_ATTR f16 futrts_log16(f16 x) {
  return futrts_log32(x);
}

SCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {
  return futrts_log2_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {
  return futrts_log10_32(x);
}

SCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {
  return futrts_log1p_32(x);
}

SCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {
  return futrts_sqrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {
  return futrts_cbrt32(x);
}

SCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {
  return futrts_exp32(x);
}

SCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {
  return futrts_cos32(x);
}

SCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {
  return futrts_sin32(x);
}

SCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {
  return futrts_tan32(x);
}

SCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {
  return futrts_acos32(x);
}

SCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {
  return futrts_asin32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {
  return futrts_atan32(x);
}

SCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {
  return futrts_cosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {
  return futrts_sinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {
  return futrts_tanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {
  return futrts_acosh32(x);
}

SCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {
  return futrts_asinh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {
  return futrts_atanh32(x);
}

SCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {
  return futrts_atan2_32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {
  return futrts_hypot32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {
  return futrts_gamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {
  return futrts_lgamma32(x);
}

SCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {
  return futrts_erf32(x);
}

SCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {
  return futrts_erfc32(x);
}

SCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {
  return fmod32(x, y);
}

SCALAR_FUN_ATTR f16 futrts_round16(f16 x) {
  return futrts_round32(x);
}

SCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {
  return futrts_floor32(x);
}

SCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {
  return futrts_ceil32(x);
}

SCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {
  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));
}

SCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {
  return futrts_lerp32(v0, v1, t);
}

SCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {
  return futrts_mad32(a, b, c);
}

SCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {
  return futrts_fma32(a, b, c);
}

// Even when we are using an OpenCL that does not support cl_khr_fp16,
// it must still support vload_half for actually creating a
// half-precision number, which can then be efficiently converted to a
// float.  Similarly for vstore_half.
#ifdef __OPENCL_VERSION__

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  int16_t y;
  // Violating strict aliasing here.
  vstore_half((float)x, 0, (half*)&y);
  return y;
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return (f16)vload_half(0, (half*)&x);
}

#else

SCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {
  return (int16_t)float2halfbits(x);
}

SCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {
  return halfbits2float((uint16_t)x);
}

SCALAR_FUN_ATTR f16 fsignum16(f16 x) {
  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);
}

#endif

#endif

SCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {
  return x;
}

SCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {
  return x;
}

SCALAR_FUN_ATTR f16 fpconv_f32_f16(float x) {
  return (f16) x;
}

#ifdef FUTHARK_F64_ENABLED

SCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {
  return (double) x;
}

#if ISPC
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) ((float)x);
}
#else
SCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {
  return (f16) x;
}
#endif
#endif


// End of scalar_f16.h.

// Start of context_prototypes.h
//
// Prototypes for the functions in context.h, or that will be called
// from those functions, that need to be available very early.

struct futhark_context_config;
struct futhark_context;

static void set_error(struct futhark_context* ctx, char *error);

// These are called in context/config new/free functions and contain
// shared setup.  They are generated by the compiler itself.
static int init_constants(struct futhark_context*);
static int free_constants(struct futhark_context*);
static void setup_program(struct futhark_context* ctx);
static void teardown_program(struct futhark_context *ctx);

// Allocate host memory.  Must be freed with host_free().
static void host_alloc(struct futhark_context* ctx, size_t size, const char* tag, size_t* size_out, void** mem_out);
// Allocate memory allocated with host_alloc().
static void host_free(struct futhark_context* ctx, size_t size, const char* tag, void* mem);

// Log that a copy has occurred.
static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]);

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t m, int64_t n);

static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]);

static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]);

static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]);

// Functions that must be defined by the backend.
static void backend_context_config_setup(struct futhark_context_config* cfg);
static void backend_context_config_teardown(struct futhark_context_config* cfg);
static int backend_context_setup(struct futhark_context *ctx);
static void backend_context_teardown(struct futhark_context *ctx);

// End of of context_prototypes.h

struct memblock_device {
    int *references;
    CUdeviceptr mem;
    int64_t size;
    const char *desc;
};
struct memblock {
    int *references;
    unsigned char *mem;
    int64_t size;
    const char *desc;
};
struct constants {
    int dummy;
    struct memblock_device counters_mem_13188;
    struct memblock_device counters_mem_13253;
    struct memblock_device id_counter_mem_13014;
    struct memblock_device id_counter_mem_13017;
    struct memblock_device id_counter_mem_13080;
    struct memblock_device id_counter_mem_13083;
    struct memblock_device id_counter_mem_13202;
    struct memblock_device id_counter_mem_13258;
};
struct tuning_params {
    int64_t *big_add_debugzisegmap_group_sizze_12302;
    int64_t *big_add_debugzisegmap_group_sizze_12397;
    int64_t *big_add_debugzisegmap_group_sizze_12447;
    int64_t *big_add_debugzisegscan_group_sizze_12387;
    int64_t *big_add_debugzisegscan_group_sizze_12437;
    int64_t *big_add_debugzisegscan_num_groups_12389;
    int64_t *big_add_debugzisegscan_num_groups_12439;
    int64_t *big_add_validationzisegmap_group_sizze_11786;
    int64_t *big_add_validationzisegred_group_sizze_11879;
    int64_t *big_add_validationzisegred_num_groups_11881;
    int64_t *big_add_validationzisegscan_group_sizze_11871;
    int64_t *big_add_validationzisegscan_num_groups_11873;
    int64_t *big_mul_debugzisegmap_group_sizze_12453;
    int64_t *big_mul_debugzisegmap_group_sizze_12804;
    int64_t *big_mul_debugzisegmap_group_sizze_12810;
    int64_t *big_mul_debugzisegmap_group_sizze_12816;
    int64_t *big_mul_debugzisegmap_group_sizze_12862;
    int64_t *big_mul_debugzisegscan_group_sizze_12844;
    int64_t *big_mul_debugzisegscan_group_sizze_12852;
    int64_t *big_mul_debugzisegscan_num_groups_12846;
    int64_t *big_mul_debugzisegscan_num_groups_12854;
    int64_t *big_mul_validationzisegmap_group_sizze_11891;
    int64_t *big_mul_validationzisegmap_group_sizze_12242;
    int64_t *big_mul_validationzisegmap_group_sizze_12248;
    int64_t *big_mul_validationzisegmap_group_sizze_12254;
    int64_t *big_mul_validationzisegred_group_sizze_12290;
    int64_t *big_mul_validationzisegred_num_groups_12292;
    int64_t *big_mul_validationzisegscan_group_sizze_12282;
    int64_t *big_mul_validationzisegscan_num_groups_12284;
    int64_t *builtinzhreplicate_i32zigroup_sizze_13094;
    int64_t *builtinzhreplicate_i64zigroup_sizze_13014;
    int64_t *builtinzhreplicate_i8zigroup_sizze_13120;
};
static const int num_tuning_params = 32;
static const char *tuning_param_names[] = {"big_add_debug.segmap_group_size_12302", "big_add_debug.segmap_group_size_12397", "big_add_debug.segmap_group_size_12447", "big_add_debug.segscan_group_size_12387", "big_add_debug.segscan_group_size_12437", "big_add_debug.segscan_num_groups_12389", "big_add_debug.segscan_num_groups_12439", "big_add_validation.segmap_group_size_11786", "big_add_validation.segred_group_size_11879", "big_add_validation.segred_num_groups_11881", "big_add_validation.segscan_group_size_11871", "big_add_validation.segscan_num_groups_11873", "big_mul_debug.segmap_group_size_12453", "big_mul_debug.segmap_group_size_12804", "big_mul_debug.segmap_group_size_12810", "big_mul_debug.segmap_group_size_12816", "big_mul_debug.segmap_group_size_12862", "big_mul_debug.segscan_group_size_12844", "big_mul_debug.segscan_group_size_12852", "big_mul_debug.segscan_num_groups_12846", "big_mul_debug.segscan_num_groups_12854", "big_mul_validation.segmap_group_size_11891", "big_mul_validation.segmap_group_size_12242", "big_mul_validation.segmap_group_size_12248", "big_mul_validation.segmap_group_size_12254", "big_mul_validation.segred_group_size_12290", "big_mul_validation.segred_num_groups_12292", "big_mul_validation.segscan_group_size_12282", "big_mul_validation.segscan_num_groups_12284", "builtin#replicate_i32.group_size_13094", "builtin#replicate_i64.group_size_13014", "builtin#replicate_i8.group_size_13120", NULL};
static const char *tuning_param_vars[] = {"big_add_debugzisegmap_group_sizze_12302", "big_add_debugzisegmap_group_sizze_12397", "big_add_debugzisegmap_group_sizze_12447", "big_add_debugzisegscan_group_sizze_12387", "big_add_debugzisegscan_group_sizze_12437", "big_add_debugzisegscan_num_groups_12389", "big_add_debugzisegscan_num_groups_12439", "big_add_validationzisegmap_group_sizze_11786", "big_add_validationzisegred_group_sizze_11879", "big_add_validationzisegred_num_groups_11881", "big_add_validationzisegscan_group_sizze_11871", "big_add_validationzisegscan_num_groups_11873", "big_mul_debugzisegmap_group_sizze_12453", "big_mul_debugzisegmap_group_sizze_12804", "big_mul_debugzisegmap_group_sizze_12810", "big_mul_debugzisegmap_group_sizze_12816", "big_mul_debugzisegmap_group_sizze_12862", "big_mul_debugzisegscan_group_sizze_12844", "big_mul_debugzisegscan_group_sizze_12852", "big_mul_debugzisegscan_num_groups_12846", "big_mul_debugzisegscan_num_groups_12854", "big_mul_validationzisegmap_group_sizze_11891", "big_mul_validationzisegmap_group_sizze_12242", "big_mul_validationzisegmap_group_sizze_12248", "big_mul_validationzisegmap_group_sizze_12254", "big_mul_validationzisegred_group_sizze_12290", "big_mul_validationzisegred_num_groups_12292", "big_mul_validationzisegscan_group_sizze_12282", "big_mul_validationzisegscan_num_groups_12284", "builtinzhreplicate_i32zigroup_sizze_13094", "builtinzhreplicate_i64zigroup_sizze_13014", "builtinzhreplicate_i8zigroup_sizze_13120", NULL};
static const char *tuning_param_classes[] = {"group_size", "group_size", "group_size", "group_size", "group_size", "num_groups", "num_groups", "group_size", "group_size", "num_groups", "group_size", "num_groups", "group_size", "group_size", "group_size", "group_size", "group_size", "group_size", "group_size", "num_groups", "num_groups", "group_size", "group_size", "group_size", "group_size", "group_size", "num_groups", "group_size", "num_groups", "group_size", "group_size", "group_size", NULL};
static int64_t tuning_param_defaults[] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
static const int max_failure_args = 2;
static const int f64_required = 0;
static const char *gpu_program[] = {"#define FUTHARK_CUDA\n// start of prelude.cu\n\n#define SCALAR_FUN_ATTR __device__ static inline\n#define FUTHARK_FUN_ATTR __device__ static\n#define FUTHARK_F64_ENABLED\n\ntypedef char int8_t;\ntypedef short int16_t;\ntypedef int int32_t;\ntypedef long long int64_t;\ntypedef unsigned char uint8_t;\ntypedef unsigned short uint16_t;\ntypedef unsigned int uint32_t;\ntypedef unsigned long long uint64_t;\n\n#define __global\n#define __local\n#define __private\n#define __constant\n#define __write_only\n#define __read_only\n\nstatic inline __device__ int get_group_id(int d) {\n  switch (d) {\n  case 0: return blockIdx.x;\n  case 1: return blockIdx.y;\n  case 2: return blockIdx.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_num_groups(int d) {\n  switch(d) {\n  case 0: return gridDim.x;\n  case 1: return gridDim.y;\n  case 2: return gridDim.z;\n  default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x + blockIdx.x * blockDim.x;\n    case 1: return threadIdx.y + blockIdx.y * blockDim.y;\n    case 2: return threadIdx.z + blockIdx.z * blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_id(int d) {\n  switch (d) {\n    case 0: return threadIdx.x;\n    case 1: return threadIdx.y;\n    case 2: return threadIdx.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_local_size(int d) {\n  switch (d) {\n    case 0: return blockDim.x;\n    case 1: return blockDim.y;\n    case 2: return blockDim.z;\n    default: return 0;\n  }\n}\n\nstatic inline __device__ int get_global_size(int d) {\n  switch (d) {\n    case 0: return gridDim.x * blockDim.x;\n    case 1: return gridDim.y * blockDim.y;\n    case 2: return gridDim.z * blockDim.z;\n    default: return 0;\n  }\n}\n\n\n#define CLK_LOCAL_MEM_FENCE 1\n#define CLK_GLOBAL_MEM_FENCE 2\nstatic inline __device__ void barrier(int x) {\n  __syncthreads();\n}\nstatic inline __device__ void mem_fence_local() {\n  __threadfence_block();\n}\nstatic inline __device__ void mem_fence_global()", " {\n  __threadfence();\n}\n\nstatic inline __device__ void barrier_local() {\n  __syncthreads();\n}\n\n#define NAN (0.0/0.0)\n#define INFINITY (1.0/0.0)\nextern volatile __shared__ unsigned char local_mem[];\n\n#define LOCAL_MEM_PARAM\n#define FUTHARK_KERNEL extern \"C\" __global__ __launch_bounds__(MAX_THREADS_PER_BLOCK)\n#define FUTHARK_KERNEL_SIZED(a,b,c) extern \"C\" __global__ __launch_bounds__(a*b*c)\n\n// End of prelude.cu\n// Start of half.h.\n\n// Conversion functions are from http://half.sourceforge.net/, but\n// translated to C.\n//\n// Copyright (c) 2012-2021 Christian Rau\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n#ifndef __OPENCL_VERSION__\n#define __constant\n#endif\n\n__constant static const uint16_t base_table[512] = {\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,", " 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000,\n  0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, 0x0040, 0x0080, 0x0100,\n  0x0200, 0x0400, 0x0800, 0x0C00, 0x1000, 0x1400, 0x1800, 0x1C00, 0x2000, 0x2400, 0x2800, 0x2C00, 0x3000, 0x3400, 0x3800, 0x3C00,\n  0x4000, 0x4400, 0x4800, 0x4C00, 0x5000, 0x5400, 0x5800, 0x5C00, 0x6000, 0x6400, 0x6800, 0x6C00, 0x7000, 0x7400, 0x7800, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00, 0x7C00,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000,",
                                    " 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000,\n  0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8000, 0x8001, 0x8002, 0x8004, 0x8008, 0x8010, 0x8020, 0x8040, 0x8080, 0x8100,\n  0x8200, 0x8400, 0x8800, 0x8C00, 0x9000, 0x9400, 0x9800, 0x9C00, 0xA000, 0xA400, 0xA800, 0xAC00, 0xB000, 0xB400, 0xB800, 0xBC00,\n  0xC000, 0xC400, 0xC800, 0xCC00, 0xD000, 0xD400, 0xD800, 0xDC00, 0xE000, 0xE400, 0xE800, 0xEC00, 0xF000, 0xF400, 0xF800, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00,\n  0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00, 0xFC00 };\n\n__constant static const unsigned char shift_table[512] = {\n  24, 24, 24, 24, 24, 24, 24,", " 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n  13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n  24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 2", "4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 13 };\n\n__constant static const uint32_t mantissa_table[2048] = {\n  0x00000000, 0x33800000, 0x34000000, 0x34400000, 0x34800000, 0x34A00000, 0x34C00000, 0x34E00000, 0x35000000, 0x35100000, 0x35200000, 0x35300000, 0x35400000, 0x35500000, 0x35600000, 0x35700000,\n  0x35800000, 0x35880000, 0x35900000, 0x35980000, 0x35A00000, 0x35A80000, 0x35B00000, 0x35B80000, 0x35C00000, 0x35C80000, 0x35D00000, 0x35D80000, 0x35E00000, 0x35E80000, 0x35F00000, 0x35F80000,\n  0x36000000, 0x36040000, 0x36080000, 0x360C0000, 0x36100000, 0x36140000, 0x36180000, 0x361C0000, 0x36200000, 0x36240000, 0x36280000, 0x362C0000, 0x36300000, 0x36340000, 0x36380000, 0x363C0000,\n  0x36400000, 0x36440000, 0x36480000, 0x364C0000, 0x36500000, 0x36540000, 0x36580000, 0x365C0000, 0x36600000, 0x36640000, 0x36680000, 0x366C0000, 0x36700000, 0x36740000, 0x36780000, 0x367C0000,\n  0x36800000, 0x36820000, 0x36840000, 0x36860000, 0x36880000, 0x368A0000, 0x368C0000, 0x368E0000, 0x36900000, 0x36920000, 0x36940000, 0x36960000, 0x36980000, 0x369A0000, 0x369C0000, 0x369E0000,\n  0x36A00000, 0x36A20000, 0x36A40000, 0x36A60000, 0x36A80000, 0x36AA0000, 0x36AC0000, 0x36AE0000, 0x36B00000, 0x36B20000, 0x36B40000, 0x36B60000, 0x36B80000, 0x36BA0000, 0x36BC0000, 0x36BE0000,\n  0x36C00000, 0x36C20000, 0x36C40000, 0x36C60000, 0x36C80000, 0x36CA0000, 0x36CC0000, 0x36CE0000, 0x36D00000, 0x36D20000, 0x36D40000, 0x36D60000, 0x36D80000, 0x36DA0000, 0x36DC0000, 0x36DE0000,\n  0x36E00000, 0x36E20000, 0x36E40000, 0x36E60000, 0x36E80000, 0x36EA0000, 0x36EC0000, 0x36EE0000, 0x36F00000, 0x36F20000, 0x36F40000, 0x36F60000, 0x36F80000, 0x36FA0000, 0x36FC0000, 0x36FE0000,\n  0x37000000, 0x37010000, 0x37020000, 0x37030000, 0x37040000, 0x37050000, 0x37060000, 0x37070000, 0x37080000, 0x37090000, 0x370A0000, 0x370B0000, 0x370C0000, 0x370D0000, 0x370E0000, 0x370F0000,\n  0x37100000, 0x37110000, 0x37120000, 0x37130000, 0x37140000, 0x37150000, 0x37160000, 0x37170000, 0x37180000, 0x37190000, 0x371A0000, 0x371B00",
                                    "00, 0x371C0000, 0x371D0000, 0x371E0000, 0x371F0000,\n  0x37200000, 0x37210000, 0x37220000, 0x37230000, 0x37240000, 0x37250000, 0x37260000, 0x37270000, 0x37280000, 0x37290000, 0x372A0000, 0x372B0000, 0x372C0000, 0x372D0000, 0x372E0000, 0x372F0000,\n  0x37300000, 0x37310000, 0x37320000, 0x37330000, 0x37340000, 0x37350000, 0x37360000, 0x37370000, 0x37380000, 0x37390000, 0x373A0000, 0x373B0000, 0x373C0000, 0x373D0000, 0x373E0000, 0x373F0000,\n  0x37400000, 0x37410000, 0x37420000, 0x37430000, 0x37440000, 0x37450000, 0x37460000, 0x37470000, 0x37480000, 0x37490000, 0x374A0000, 0x374B0000, 0x374C0000, 0x374D0000, 0x374E0000, 0x374F0000,\n  0x37500000, 0x37510000, 0x37520000, 0x37530000, 0x37540000, 0x37550000, 0x37560000, 0x37570000, 0x37580000, 0x37590000, 0x375A0000, 0x375B0000, 0x375C0000, 0x375D0000, 0x375E0000, 0x375F0000,\n  0x37600000, 0x37610000, 0x37620000, 0x37630000, 0x37640000, 0x37650000, 0x37660000, 0x37670000, 0x37680000, 0x37690000, 0x376A0000, 0x376B0000, 0x376C0000, 0x376D0000, 0x376E0000, 0x376F0000,\n  0x37700000, 0x37710000, 0x37720000, 0x37730000, 0x37740000, 0x37750000, 0x37760000, 0x37770000, 0x37780000, 0x37790000, 0x377A0000, 0x377B0000, 0x377C0000, 0x377D0000, 0x377E0000, 0x377F0000,\n  0x37800000, 0x37808000, 0x37810000, 0x37818000, 0x37820000, 0x37828000, 0x37830000, 0x37838000, 0x37840000, 0x37848000, 0x37850000, 0x37858000, 0x37860000, 0x37868000, 0x37870000, 0x37878000,\n  0x37880000, 0x37888000, 0x37890000, 0x37898000, 0x378A0000, 0x378A8000, 0x378B0000, 0x378B8000, 0x378C0000, 0x378C8000, 0x378D0000, 0x378D8000, 0x378E0000, 0x378E8000, 0x378F0000, 0x378F8000,\n  0x37900000, 0x37908000, 0x37910000, 0x37918000, 0x37920000, 0x37928000, 0x37930000, 0x37938000, 0x37940000, 0x37948000, 0x37950000, 0x37958000, 0x37960000, 0x37968000, 0x37970000, 0x37978000,\n  0x37980000, 0x37988000, 0x37990000, 0x37998000, 0x379A0000, 0x379A8000, 0x379B0000, 0x379B8000, 0x379C0000, 0x379C8000, 0x379D0000, 0x379D8000, 0x379E0000, 0x379E8000, 0x379F0000, 0x379F8000,\n  0x37A0", "0000, 0x37A08000, 0x37A10000, 0x37A18000, 0x37A20000, 0x37A28000, 0x37A30000, 0x37A38000, 0x37A40000, 0x37A48000, 0x37A50000, 0x37A58000, 0x37A60000, 0x37A68000, 0x37A70000, 0x37A78000,\n  0x37A80000, 0x37A88000, 0x37A90000, 0x37A98000, 0x37AA0000, 0x37AA8000, 0x37AB0000, 0x37AB8000, 0x37AC0000, 0x37AC8000, 0x37AD0000, 0x37AD8000, 0x37AE0000, 0x37AE8000, 0x37AF0000, 0x37AF8000,\n  0x37B00000, 0x37B08000, 0x37B10000, 0x37B18000, 0x37B20000, 0x37B28000, 0x37B30000, 0x37B38000, 0x37B40000, 0x37B48000, 0x37B50000, 0x37B58000, 0x37B60000, 0x37B68000, 0x37B70000, 0x37B78000,\n  0x37B80000, 0x37B88000, 0x37B90000, 0x37B98000, 0x37BA0000, 0x37BA8000, 0x37BB0000, 0x37BB8000, 0x37BC0000, 0x37BC8000, 0x37BD0000, 0x37BD8000, 0x37BE0000, 0x37BE8000, 0x37BF0000, 0x37BF8000,\n  0x37C00000, 0x37C08000, 0x37C10000, 0x37C18000, 0x37C20000, 0x37C28000, 0x37C30000, 0x37C38000, 0x37C40000, 0x37C48000, 0x37C50000, 0x37C58000, 0x37C60000, 0x37C68000, 0x37C70000, 0x37C78000,\n  0x37C80000, 0x37C88000, 0x37C90000, 0x37C98000, 0x37CA0000, 0x37CA8000, 0x37CB0000, 0x37CB8000, 0x37CC0000, 0x37CC8000, 0x37CD0000, 0x37CD8000, 0x37CE0000, 0x37CE8000, 0x37CF0000, 0x37CF8000,\n  0x37D00000, 0x37D08000, 0x37D10000, 0x37D18000, 0x37D20000, 0x37D28000, 0x37D30000, 0x37D38000, 0x37D40000, 0x37D48000, 0x37D50000, 0x37D58000, 0x37D60000, 0x37D68000, 0x37D70000, 0x37D78000,\n  0x37D80000, 0x37D88000, 0x37D90000, 0x37D98000, 0x37DA0000, 0x37DA8000, 0x37DB0000, 0x37DB8000, 0x37DC0000, 0x37DC8000, 0x37DD0000, 0x37DD8000, 0x37DE0000, 0x37DE8000, 0x37DF0000, 0x37DF8000,\n  0x37E00000, 0x37E08000, 0x37E10000, 0x37E18000, 0x37E20000, 0x37E28000, 0x37E30000, 0x37E38000, 0x37E40000, 0x37E48000, 0x37E50000, 0x37E58000, 0x37E60000, 0x37E68000, 0x37E70000, 0x37E78000,\n  0x37E80000, 0x37E88000, 0x37E90000, 0x37E98000, 0x37EA0000, 0x37EA8000, 0x37EB0000, 0x37EB8000, 0x37EC0000, 0x37EC8000, 0x37ED0000, 0x37ED8000, 0x37EE0000, 0x37EE8000, 0x37EF0000, 0x37EF8000,\n  0x37F00000, 0x37F08000, 0x37F10000, 0x37F18000, 0x37F20000, 0x37F2", "8000, 0x37F30000, 0x37F38000, 0x37F40000, 0x37F48000, 0x37F50000, 0x37F58000, 0x37F60000, 0x37F68000, 0x37F70000, 0x37F78000,\n  0x37F80000, 0x37F88000, 0x37F90000, 0x37F98000, 0x37FA0000, 0x37FA8000, 0x37FB0000, 0x37FB8000, 0x37FC0000, 0x37FC8000, 0x37FD0000, 0x37FD8000, 0x37FE0000, 0x37FE8000, 0x37FF0000, 0x37FF8000,\n  0x38000000, 0x38004000, 0x38008000, 0x3800C000, 0x38010000, 0x38014000, 0x38018000, 0x3801C000, 0x38020000, 0x38024000, 0x38028000, 0x3802C000, 0x38030000, 0x38034000, 0x38038000, 0x3803C000,\n  0x38040000, 0x38044000, 0x38048000, 0x3804C000, 0x38050000, 0x38054000, 0x38058000, 0x3805C000, 0x38060000, 0x38064000, 0x38068000, 0x3806C000, 0x38070000, 0x38074000, 0x38078000, 0x3807C000,\n  0x38080000, 0x38084000, 0x38088000, 0x3808C000, 0x38090000, 0x38094000, 0x38098000, 0x3809C000, 0x380A0000, 0x380A4000, 0x380A8000, 0x380AC000, 0x380B0000, 0x380B4000, 0x380B8000, 0x380BC000,\n  0x380C0000, 0x380C4000, 0x380C8000, 0x380CC000, 0x380D0000, 0x380D4000, 0x380D8000, 0x380DC000, 0x380E0000, 0x380E4000, 0x380E8000, 0x380EC000, 0x380F0000, 0x380F4000, 0x380F8000, 0x380FC000,\n  0x38100000, 0x38104000, 0x38108000, 0x3810C000, 0x38110000, 0x38114000, 0x38118000, 0x3811C000, 0x38120000, 0x38124000, 0x38128000, 0x3812C000, 0x38130000, 0x38134000, 0x38138000, 0x3813C000,\n  0x38140000, 0x38144000, 0x38148000, 0x3814C000, 0x38150000, 0x38154000, 0x38158000, 0x3815C000, 0x38160000, 0x38164000, 0x38168000, 0x3816C000, 0x38170000, 0x38174000, 0x38178000, 0x3817C000,\n  0x38180000, 0x38184000, 0x38188000, 0x3818C000, 0x38190000, 0x38194000, 0x38198000, 0x3819C000, 0x381A0000, 0x381A4000, 0x381A8000, 0x381AC000, 0x381B0000, 0x381B4000, 0x381B8000, 0x381BC000,\n  0x381C0000, 0x381C4000, 0x381C8000, 0x381CC000, 0x381D0000, 0x381D4000, 0x381D8000, 0x381DC000, 0x381E0000, 0x381E4000, 0x381E8000, 0x381EC000, 0x381F0000, 0x381F4000, 0x381F8000, 0x381FC000,\n  0x38200000, 0x38204000, 0x38208000, 0x3820C000, 0x38210000, 0x38214000, 0x38218000, 0x3821C000, 0x38220000, 0x38224000, 0x3822",
                                    "8000, 0x3822C000, 0x38230000, 0x38234000, 0x38238000, 0x3823C000,\n  0x38240000, 0x38244000, 0x38248000, 0x3824C000, 0x38250000, 0x38254000, 0x38258000, 0x3825C000, 0x38260000, 0x38264000, 0x38268000, 0x3826C000, 0x38270000, 0x38274000, 0x38278000, 0x3827C000,\n  0x38280000, 0x38284000, 0x38288000, 0x3828C000, 0x38290000, 0x38294000, 0x38298000, 0x3829C000, 0x382A0000, 0x382A4000, 0x382A8000, 0x382AC000, 0x382B0000, 0x382B4000, 0x382B8000, 0x382BC000,\n  0x382C0000, 0x382C4000, 0x382C8000, 0x382CC000, 0x382D0000, 0x382D4000, 0x382D8000, 0x382DC000, 0x382E0000, 0x382E4000, 0x382E8000, 0x382EC000, 0x382F0000, 0x382F4000, 0x382F8000, 0x382FC000,\n  0x38300000, 0x38304000, 0x38308000, 0x3830C000, 0x38310000, 0x38314000, 0x38318000, 0x3831C000, 0x38320000, 0x38324000, 0x38328000, 0x3832C000, 0x38330000, 0x38334000, 0x38338000, 0x3833C000,\n  0x38340000, 0x38344000, 0x38348000, 0x3834C000, 0x38350000, 0x38354000, 0x38358000, 0x3835C000, 0x38360000, 0x38364000, 0x38368000, 0x3836C000, 0x38370000, 0x38374000, 0x38378000, 0x3837C000,\n  0x38380000, 0x38384000, 0x38388000, 0x3838C000, 0x38390000, 0x38394000, 0x38398000, 0x3839C000, 0x383A0000, 0x383A4000, 0x383A8000, 0x383AC000, 0x383B0000, 0x383B4000, 0x383B8000, 0x383BC000,\n  0x383C0000, 0x383C4000, 0x383C8000, 0x383CC000, 0x383D0000, 0x383D4000, 0x383D8000, 0x383DC000, 0x383E0000, 0x383E4000, 0x383E8000, 0x383EC000, 0x383F0000, 0x383F4000, 0x383F8000, 0x383FC000,\n  0x38400000, 0x38404000, 0x38408000, 0x3840C000, 0x38410000, 0x38414000, 0x38418000, 0x3841C000, 0x38420000, 0x38424000, 0x38428000, 0x3842C000, 0x38430000, 0x38434000, 0x38438000, 0x3843C000,\n  0x38440000, 0x38444000, 0x38448000, 0x3844C000, 0x38450000, 0x38454000, 0x38458000, 0x3845C000, 0x38460000, 0x38464000, 0x38468000, 0x3846C000, 0x38470000, 0x38474000, 0x38478000, 0x3847C000,\n  0x38480000, 0x38484000, 0x38488000, 0x3848C000, 0x38490000, 0x38494000, 0x38498000, 0x3849C000, 0x384A0000, 0x384A4000, 0x384A8000, 0x384AC000, 0x384B0000, 0x384B4000, 0x384B8000, 0x384B", "C000,\n  0x384C0000, 0x384C4000, 0x384C8000, 0x384CC000, 0x384D0000, 0x384D4000, 0x384D8000, 0x384DC000, 0x384E0000, 0x384E4000, 0x384E8000, 0x384EC000, 0x384F0000, 0x384F4000, 0x384F8000, 0x384FC000,\n  0x38500000, 0x38504000, 0x38508000, 0x3850C000, 0x38510000, 0x38514000, 0x38518000, 0x3851C000, 0x38520000, 0x38524000, 0x38528000, 0x3852C000, 0x38530000, 0x38534000, 0x38538000, 0x3853C000,\n  0x38540000, 0x38544000, 0x38548000, 0x3854C000, 0x38550000, 0x38554000, 0x38558000, 0x3855C000, 0x38560000, 0x38564000, 0x38568000, 0x3856C000, 0x38570000, 0x38574000, 0x38578000, 0x3857C000,\n  0x38580000, 0x38584000, 0x38588000, 0x3858C000, 0x38590000, 0x38594000, 0x38598000, 0x3859C000, 0x385A0000, 0x385A4000, 0x385A8000, 0x385AC000, 0x385B0000, 0x385B4000, 0x385B8000, 0x385BC000,\n  0x385C0000, 0x385C4000, 0x385C8000, 0x385CC000, 0x385D0000, 0x385D4000, 0x385D8000, 0x385DC000, 0x385E0000, 0x385E4000, 0x385E8000, 0x385EC000, 0x385F0000, 0x385F4000, 0x385F8000, 0x385FC000,\n  0x38600000, 0x38604000, 0x38608000, 0x3860C000, 0x38610000, 0x38614000, 0x38618000, 0x3861C000, 0x38620000, 0x38624000, 0x38628000, 0x3862C000, 0x38630000, 0x38634000, 0x38638000, 0x3863C000,\n  0x38640000, 0x38644000, 0x38648000, 0x3864C000, 0x38650000, 0x38654000, 0x38658000, 0x3865C000, 0x38660000, 0x38664000, 0x38668000, 0x3866C000, 0x38670000, 0x38674000, 0x38678000, 0x3867C000,\n  0x38680000, 0x38684000, 0x38688000, 0x3868C000, 0x38690000, 0x38694000, 0x38698000, 0x3869C000, 0x386A0000, 0x386A4000, 0x386A8000, 0x386AC000, 0x386B0000, 0x386B4000, 0x386B8000, 0x386BC000,\n  0x386C0000, 0x386C4000, 0x386C8000, 0x386CC000, 0x386D0000, 0x386D4000, 0x386D8000, 0x386DC000, 0x386E0000, 0x386E4000, 0x386E8000, 0x386EC000, 0x386F0000, 0x386F4000, 0x386F8000, 0x386FC000,\n  0x38700000, 0x38704000, 0x38708000, 0x3870C000, 0x38710000, 0x38714000, 0x38718000, 0x3871C000, 0x38720000, 0x38724000, 0x38728000, 0x3872C000, 0x38730000, 0x38734000, 0x38738000, 0x3873C000,\n  0x38740000, 0x38744000, 0x38748000, 0x3874C000, 0x38", "750000, 0x38754000, 0x38758000, 0x3875C000, 0x38760000, 0x38764000, 0x38768000, 0x3876C000, 0x38770000, 0x38774000, 0x38778000, 0x3877C000,\n  0x38780000, 0x38784000, 0x38788000, 0x3878C000, 0x38790000, 0x38794000, 0x38798000, 0x3879C000, 0x387A0000, 0x387A4000, 0x387A8000, 0x387AC000, 0x387B0000, 0x387B4000, 0x387B8000, 0x387BC000,\n  0x387C0000, 0x387C4000, 0x387C8000, 0x387CC000, 0x387D0000, 0x387D4000, 0x387D8000, 0x387DC000, 0x387E0000, 0x387E4000, 0x387E8000, 0x387EC000, 0x387F0000, 0x387F4000, 0x387F8000, 0x387FC000,\n  0x38000000, 0x38002000, 0x38004000, 0x38006000, 0x38008000, 0x3800A000, 0x3800C000, 0x3800E000, 0x38010000, 0x38012000, 0x38014000, 0x38016000, 0x38018000, 0x3801A000, 0x3801C000, 0x3801E000,\n  0x38020000, 0x38022000, 0x38024000, 0x38026000, 0x38028000, 0x3802A000, 0x3802C000, 0x3802E000, 0x38030000, 0x38032000, 0x38034000, 0x38036000, 0x38038000, 0x3803A000, 0x3803C000, 0x3803E000,\n  0x38040000, 0x38042000, 0x38044000, 0x38046000, 0x38048000, 0x3804A000, 0x3804C000, 0x3804E000, 0x38050000, 0x38052000, 0x38054000, 0x38056000, 0x38058000, 0x3805A000, 0x3805C000, 0x3805E000,\n  0x38060000, 0x38062000, 0x38064000, 0x38066000, 0x38068000, 0x3806A000, 0x3806C000, 0x3806E000, 0x38070000, 0x38072000, 0x38074000, 0x38076000, 0x38078000, 0x3807A000, 0x3807C000, 0x3807E000,\n  0x38080000, 0x38082000, 0x38084000, 0x38086000, 0x38088000, 0x3808A000, 0x3808C000, 0x3808E000, 0x38090000, 0x38092000, 0x38094000, 0x38096000, 0x38098000, 0x3809A000, 0x3809C000, 0x3809E000,\n  0x380A0000, 0x380A2000, 0x380A4000, 0x380A6000, 0x380A8000, 0x380AA000, 0x380AC000, 0x380AE000, 0x380B0000, 0x380B2000, 0x380B4000, 0x380B6000, 0x380B8000, 0x380BA000, 0x380BC000, 0x380BE000,\n  0x380C0000, 0x380C2000, 0x380C4000, 0x380C6000, 0x380C8000, 0x380CA000, 0x380CC000, 0x380CE000, 0x380D0000, 0x380D2000, 0x380D4000, 0x380D6000, 0x380D8000, 0x380DA000, 0x380DC000, 0x380DE000,\n  0x380E0000, 0x380E2000, 0x380E4000, 0x380E6000, 0x380E8000, 0x380EA000, 0x380EC000, 0x380EE000, 0x380F0000, 0x38",
                                    "0F2000, 0x380F4000, 0x380F6000, 0x380F8000, 0x380FA000, 0x380FC000, 0x380FE000,\n  0x38100000, 0x38102000, 0x38104000, 0x38106000, 0x38108000, 0x3810A000, 0x3810C000, 0x3810E000, 0x38110000, 0x38112000, 0x38114000, 0x38116000, 0x38118000, 0x3811A000, 0x3811C000, 0x3811E000,\n  0x38120000, 0x38122000, 0x38124000, 0x38126000, 0x38128000, 0x3812A000, 0x3812C000, 0x3812E000, 0x38130000, 0x38132000, 0x38134000, 0x38136000, 0x38138000, 0x3813A000, 0x3813C000, 0x3813E000,\n  0x38140000, 0x38142000, 0x38144000, 0x38146000, 0x38148000, 0x3814A000, 0x3814C000, 0x3814E000, 0x38150000, 0x38152000, 0x38154000, 0x38156000, 0x38158000, 0x3815A000, 0x3815C000, 0x3815E000,\n  0x38160000, 0x38162000, 0x38164000, 0x38166000, 0x38168000, 0x3816A000, 0x3816C000, 0x3816E000, 0x38170000, 0x38172000, 0x38174000, 0x38176000, 0x38178000, 0x3817A000, 0x3817C000, 0x3817E000,\n  0x38180000, 0x38182000, 0x38184000, 0x38186000, 0x38188000, 0x3818A000, 0x3818C000, 0x3818E000, 0x38190000, 0x38192000, 0x38194000, 0x38196000, 0x38198000, 0x3819A000, 0x3819C000, 0x3819E000,\n  0x381A0000, 0x381A2000, 0x381A4000, 0x381A6000, 0x381A8000, 0x381AA000, 0x381AC000, 0x381AE000, 0x381B0000, 0x381B2000, 0x381B4000, 0x381B6000, 0x381B8000, 0x381BA000, 0x381BC000, 0x381BE000,\n  0x381C0000, 0x381C2000, 0x381C4000, 0x381C6000, 0x381C8000, 0x381CA000, 0x381CC000, 0x381CE000, 0x381D0000, 0x381D2000, 0x381D4000, 0x381D6000, 0x381D8000, 0x381DA000, 0x381DC000, 0x381DE000,\n  0x381E0000, 0x381E2000, 0x381E4000, 0x381E6000, 0x381E8000, 0x381EA000, 0x381EC000, 0x381EE000, 0x381F0000, 0x381F2000, 0x381F4000, 0x381F6000, 0x381F8000, 0x381FA000, 0x381FC000, 0x381FE000,\n  0x38200000, 0x38202000, 0x38204000, 0x38206000, 0x38208000, 0x3820A000, 0x3820C000, 0x3820E000, 0x38210000, 0x38212000, 0x38214000, 0x38216000, 0x38218000, 0x3821A000, 0x3821C000, 0x3821E000,\n  0x38220000, 0x38222000, 0x38224000, 0x38226000, 0x38228000, 0x3822A000, 0x3822C000, 0x3822E000, 0x38230000, 0x38232000, 0x38234000, 0x38236000, 0x38238000, 0x3823A000, 0x38", "23C000, 0x3823E000,\n  0x38240000, 0x38242000, 0x38244000, 0x38246000, 0x38248000, 0x3824A000, 0x3824C000, 0x3824E000, 0x38250000, 0x38252000, 0x38254000, 0x38256000, 0x38258000, 0x3825A000, 0x3825C000, 0x3825E000,\n  0x38260000, 0x38262000, 0x38264000, 0x38266000, 0x38268000, 0x3826A000, 0x3826C000, 0x3826E000, 0x38270000, 0x38272000, 0x38274000, 0x38276000, 0x38278000, 0x3827A000, 0x3827C000, 0x3827E000,\n  0x38280000, 0x38282000, 0x38284000, 0x38286000, 0x38288000, 0x3828A000, 0x3828C000, 0x3828E000, 0x38290000, 0x38292000, 0x38294000, 0x38296000, 0x38298000, 0x3829A000, 0x3829C000, 0x3829E000,\n  0x382A0000, 0x382A2000, 0x382A4000, 0x382A6000, 0x382A8000, 0x382AA000, 0x382AC000, 0x382AE000, 0x382B0000, 0x382B2000, 0x382B4000, 0x382B6000, 0x382B8000, 0x382BA000, 0x382BC000, 0x382BE000,\n  0x382C0000, 0x382C2000, 0x382C4000, 0x382C6000, 0x382C8000, 0x382CA000, 0x382CC000, 0x382CE000, 0x382D0000, 0x382D2000, 0x382D4000, 0x382D6000, 0x382D8000, 0x382DA000, 0x382DC000, 0x382DE000,\n  0x382E0000, 0x382E2000, 0x382E4000, 0x382E6000, 0x382E8000, 0x382EA000, 0x382EC000, 0x382EE000, 0x382F0000, 0x382F2000, 0x382F4000, 0x382F6000, 0x382F8000, 0x382FA000, 0x382FC000, 0x382FE000,\n  0x38300000, 0x38302000, 0x38304000, 0x38306000, 0x38308000, 0x3830A000, 0x3830C000, 0x3830E000, 0x38310000, 0x38312000, 0x38314000, 0x38316000, 0x38318000, 0x3831A000, 0x3831C000, 0x3831E000,\n  0x38320000, 0x38322000, 0x38324000, 0x38326000, 0x38328000, 0x3832A000, 0x3832C000, 0x3832E000, 0x38330000, 0x38332000, 0x38334000, 0x38336000, 0x38338000, 0x3833A000, 0x3833C000, 0x3833E000,\n  0x38340000, 0x38342000, 0x38344000, 0x38346000, 0x38348000, 0x3834A000, 0x3834C000, 0x3834E000, 0x38350000, 0x38352000, 0x38354000, 0x38356000, 0x38358000, 0x3835A000, 0x3835C000, 0x3835E000,\n  0x38360000, 0x38362000, 0x38364000, 0x38366000, 0x38368000, 0x3836A000, 0x3836C000, 0x3836E000, 0x38370000, 0x38372000, 0x38374000, 0x38376000, 0x38378000, 0x3837A000, 0x3837C000, 0x3837E000,\n  0x38380000, 0x38382000, 0x38384000, 0x", "38386000, 0x38388000, 0x3838A000, 0x3838C000, 0x3838E000, 0x38390000, 0x38392000, 0x38394000, 0x38396000, 0x38398000, 0x3839A000, 0x3839C000, 0x3839E000,\n  0x383A0000, 0x383A2000, 0x383A4000, 0x383A6000, 0x383A8000, 0x383AA000, 0x383AC000, 0x383AE000, 0x383B0000, 0x383B2000, 0x383B4000, 0x383B6000, 0x383B8000, 0x383BA000, 0x383BC000, 0x383BE000,\n  0x383C0000, 0x383C2000, 0x383C4000, 0x383C6000, 0x383C8000, 0x383CA000, 0x383CC000, 0x383CE000, 0x383D0000, 0x383D2000, 0x383D4000, 0x383D6000, 0x383D8000, 0x383DA000, 0x383DC000, 0x383DE000,\n  0x383E0000, 0x383E2000, 0x383E4000, 0x383E6000, 0x383E8000, 0x383EA000, 0x383EC000, 0x383EE000, 0x383F0000, 0x383F2000, 0x383F4000, 0x383F6000, 0x383F8000, 0x383FA000, 0x383FC000, 0x383FE000,\n  0x38400000, 0x38402000, 0x38404000, 0x38406000, 0x38408000, 0x3840A000, 0x3840C000, 0x3840E000, 0x38410000, 0x38412000, 0x38414000, 0x38416000, 0x38418000, 0x3841A000, 0x3841C000, 0x3841E000,\n  0x38420000, 0x38422000, 0x38424000, 0x38426000, 0x38428000, 0x3842A000, 0x3842C000, 0x3842E000, 0x38430000, 0x38432000, 0x38434000, 0x38436000, 0x38438000, 0x3843A000, 0x3843C000, 0x3843E000,\n  0x38440000, 0x38442000, 0x38444000, 0x38446000, 0x38448000, 0x3844A000, 0x3844C000, 0x3844E000, 0x38450000, 0x38452000, 0x38454000, 0x38456000, 0x38458000, 0x3845A000, 0x3845C000, 0x3845E000,\n  0x38460000, 0x38462000, 0x38464000, 0x38466000, 0x38468000, 0x3846A000, 0x3846C000, 0x3846E000, 0x38470000, 0x38472000, 0x38474000, 0x38476000, 0x38478000, 0x3847A000, 0x3847C000, 0x3847E000,\n  0x38480000, 0x38482000, 0x38484000, 0x38486000, 0x38488000, 0x3848A000, 0x3848C000, 0x3848E000, 0x38490000, 0x38492000, 0x38494000, 0x38496000, 0x38498000, 0x3849A000, 0x3849C000, 0x3849E000,\n  0x384A0000, 0x384A2000, 0x384A4000, 0x384A6000, 0x384A8000, 0x384AA000, 0x384AC000, 0x384AE000, 0x384B0000, 0x384B2000, 0x384B4000, 0x384B6000, 0x384B8000, 0x384BA000, 0x384BC000, 0x384BE000,\n  0x384C0000, 0x384C2000, 0x384C4000, 0x384C6000, 0x384C8000, 0x384CA000, 0x384CC000, 0x384CE000, 0x",
                                    "384D0000, 0x384D2000, 0x384D4000, 0x384D6000, 0x384D8000, 0x384DA000, 0x384DC000, 0x384DE000,\n  0x384E0000, 0x384E2000, 0x384E4000, 0x384E6000, 0x384E8000, 0x384EA000, 0x384EC000, 0x384EE000, 0x384F0000, 0x384F2000, 0x384F4000, 0x384F6000, 0x384F8000, 0x384FA000, 0x384FC000, 0x384FE000,\n  0x38500000, 0x38502000, 0x38504000, 0x38506000, 0x38508000, 0x3850A000, 0x3850C000, 0x3850E000, 0x38510000, 0x38512000, 0x38514000, 0x38516000, 0x38518000, 0x3851A000, 0x3851C000, 0x3851E000,\n  0x38520000, 0x38522000, 0x38524000, 0x38526000, 0x38528000, 0x3852A000, 0x3852C000, 0x3852E000, 0x38530000, 0x38532000, 0x38534000, 0x38536000, 0x38538000, 0x3853A000, 0x3853C000, 0x3853E000,\n  0x38540000, 0x38542000, 0x38544000, 0x38546000, 0x38548000, 0x3854A000, 0x3854C000, 0x3854E000, 0x38550000, 0x38552000, 0x38554000, 0x38556000, 0x38558000, 0x3855A000, 0x3855C000, 0x3855E000,\n  0x38560000, 0x38562000, 0x38564000, 0x38566000, 0x38568000, 0x3856A000, 0x3856C000, 0x3856E000, 0x38570000, 0x38572000, 0x38574000, 0x38576000, 0x38578000, 0x3857A000, 0x3857C000, 0x3857E000,\n  0x38580000, 0x38582000, 0x38584000, 0x38586000, 0x38588000, 0x3858A000, 0x3858C000, 0x3858E000, 0x38590000, 0x38592000, 0x38594000, 0x38596000, 0x38598000, 0x3859A000, 0x3859C000, 0x3859E000,\n  0x385A0000, 0x385A2000, 0x385A4000, 0x385A6000, 0x385A8000, 0x385AA000, 0x385AC000, 0x385AE000, 0x385B0000, 0x385B2000, 0x385B4000, 0x385B6000, 0x385B8000, 0x385BA000, 0x385BC000, 0x385BE000,\n  0x385C0000, 0x385C2000, 0x385C4000, 0x385C6000, 0x385C8000, 0x385CA000, 0x385CC000, 0x385CE000, 0x385D0000, 0x385D2000, 0x385D4000, 0x385D6000, 0x385D8000, 0x385DA000, 0x385DC000, 0x385DE000,\n  0x385E0000, 0x385E2000, 0x385E4000, 0x385E6000, 0x385E8000, 0x385EA000, 0x385EC000, 0x385EE000, 0x385F0000, 0x385F2000, 0x385F4000, 0x385F6000, 0x385F8000, 0x385FA000, 0x385FC000, 0x385FE000,\n  0x38600000, 0x38602000, 0x38604000, 0x38606000, 0x38608000, 0x3860A000, 0x3860C000, 0x3860E000, 0x38610000, 0x38612000, 0x38614000, 0x38616000, 0x38618000, 0x", "3861A000, 0x3861C000, 0x3861E000,\n  0x38620000, 0x38622000, 0x38624000, 0x38626000, 0x38628000, 0x3862A000, 0x3862C000, 0x3862E000, 0x38630000, 0x38632000, 0x38634000, 0x38636000, 0x38638000, 0x3863A000, 0x3863C000, 0x3863E000,\n  0x38640000, 0x38642000, 0x38644000, 0x38646000, 0x38648000, 0x3864A000, 0x3864C000, 0x3864E000, 0x38650000, 0x38652000, 0x38654000, 0x38656000, 0x38658000, 0x3865A000, 0x3865C000, 0x3865E000,\n  0x38660000, 0x38662000, 0x38664000, 0x38666000, 0x38668000, 0x3866A000, 0x3866C000, 0x3866E000, 0x38670000, 0x38672000, 0x38674000, 0x38676000, 0x38678000, 0x3867A000, 0x3867C000, 0x3867E000,\n  0x38680000, 0x38682000, 0x38684000, 0x38686000, 0x38688000, 0x3868A000, 0x3868C000, 0x3868E000, 0x38690000, 0x38692000, 0x38694000, 0x38696000, 0x38698000, 0x3869A000, 0x3869C000, 0x3869E000,\n  0x386A0000, 0x386A2000, 0x386A4000, 0x386A6000, 0x386A8000, 0x386AA000, 0x386AC000, 0x386AE000, 0x386B0000, 0x386B2000, 0x386B4000, 0x386B6000, 0x386B8000, 0x386BA000, 0x386BC000, 0x386BE000,\n  0x386C0000, 0x386C2000, 0x386C4000, 0x386C6000, 0x386C8000, 0x386CA000, 0x386CC000, 0x386CE000, 0x386D0000, 0x386D2000, 0x386D4000, 0x386D6000, 0x386D8000, 0x386DA000, 0x386DC000, 0x386DE000,\n  0x386E0000, 0x386E2000, 0x386E4000, 0x386E6000, 0x386E8000, 0x386EA000, 0x386EC000, 0x386EE000, 0x386F0000, 0x386F2000, 0x386F4000, 0x386F6000, 0x386F8000, 0x386FA000, 0x386FC000, 0x386FE000,\n  0x38700000, 0x38702000, 0x38704000, 0x38706000, 0x38708000, 0x3870A000, 0x3870C000, 0x3870E000, 0x38710000, 0x38712000, 0x38714000, 0x38716000, 0x38718000, 0x3871A000, 0x3871C000, 0x3871E000,\n  0x38720000, 0x38722000, 0x38724000, 0x38726000, 0x38728000, 0x3872A000, 0x3872C000, 0x3872E000, 0x38730000, 0x38732000, 0x38734000, 0x38736000, 0x38738000, 0x3873A000, 0x3873C000, 0x3873E000,\n  0x38740000, 0x38742000, 0x38744000, 0x38746000, 0x38748000, 0x3874A000, 0x3874C000, 0x3874E000, 0x38750000, 0x38752000, 0x38754000, 0x38756000, 0x38758000, 0x3875A000, 0x3875C000, 0x3875E000,\n  0x38760000, 0x38762000, ", "0x38764000, 0x38766000, 0x38768000, 0x3876A000, 0x3876C000, 0x3876E000, 0x38770000, 0x38772000, 0x38774000, 0x38776000, 0x38778000, 0x3877A000, 0x3877C000, 0x3877E000,\n  0x38780000, 0x38782000, 0x38784000, 0x38786000, 0x38788000, 0x3878A000, 0x3878C000, 0x3878E000, 0x38790000, 0x38792000, 0x38794000, 0x38796000, 0x38798000, 0x3879A000, 0x3879C000, 0x3879E000,\n  0x387A0000, 0x387A2000, 0x387A4000, 0x387A6000, 0x387A8000, 0x387AA000, 0x387AC000, 0x387AE000, 0x387B0000, 0x387B2000, 0x387B4000, 0x387B6000, 0x387B8000, 0x387BA000, 0x387BC000, 0x387BE000,\n  0x387C0000, 0x387C2000, 0x387C4000, 0x387C6000, 0x387C8000, 0x387CA000, 0x387CC000, 0x387CE000, 0x387D0000, 0x387D2000, 0x387D4000, 0x387D6000, 0x387D8000, 0x387DA000, 0x387DC000, 0x387DE000,\n  0x387E0000, 0x387E2000, 0x387E4000, 0x387E6000, 0x387E8000, 0x387EA000, 0x387EC000, 0x387EE000, 0x387F0000, 0x387F2000, 0x387F4000, 0x387F6000, 0x387F8000, 0x387FA000, 0x387FC000, 0x387FE000 };\n__constant static const uint32_t exponent_table[64] = {\n  0x00000000, 0x00800000, 0x01000000, 0x01800000, 0x02000000, 0x02800000, 0x03000000, 0x03800000, 0x04000000, 0x04800000, 0x05000000, 0x05800000, 0x06000000, 0x06800000, 0x07000000, 0x07800000,\n  0x08000000, 0x08800000, 0x09000000, 0x09800000, 0x0A000000, 0x0A800000, 0x0B000000, 0x0B800000, 0x0C000000, 0x0C800000, 0x0D000000, 0x0D800000, 0x0E000000, 0x0E800000, 0x0F000000, 0x47800000,\n  0x80000000, 0x80800000, 0x81000000, 0x81800000, 0x82000000, 0x82800000, 0x83000000, 0x83800000, 0x84000000, 0x84800000, 0x85000000, 0x85800000, 0x86000000, 0x86800000, 0x87000000, 0x87800000,\n  0x88000000, 0x88800000, 0x89000000, 0x89800000, 0x8A000000, 0x8A800000, 0x8B000000, 0x8B800000, 0x8C000000, 0x8C800000, 0x8D000000, 0x8D800000, 0x8E000000, 0x8E800000, 0x8F000000, 0xC7800000 };\n__constant static const unsigned short offset_table[64] = {\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024,",
                                    " 1024, 1024, 1024, 1024, 1024,\n  0, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024 };\n\nSCALAR_FUN_ATTR uint16_t float2halfbits(float value) {\n  union { float x; uint32_t y; } u;\n  u.x = value;\n  uint32_t bits = u.y;\n\n  uint16_t hbits = base_table[bits>>23] + (uint16_t)((bits&0x7FFFFF)>>shift_table[bits>>23]);;\n\n  return hbits;\n}\n\nSCALAR_FUN_ATTR float halfbits2float(uint16_t value) {\n  uint32_t bits = mantissa_table[offset_table[value>>10]+(value&0x3FF)] + exponent_table[value>>10];\n\n  union { uint32_t x; float y; } u;\n  u.x = bits;\n  return u.y;\n}\n\nSCALAR_FUN_ATTR uint16_t halfbitsnextafter(uint16_t from, uint16_t to) {\n  int fabs = from & 0x7FFF, tabs = to & 0x7FFF;\n  if(fabs > 0x7C00 || tabs > 0x7C00) {\n    return ((from&0x7FFF)>0x7C00) ? (from|0x200) : (to|0x200);\n  }\n  if(from == to || !(fabs|tabs)) {\n    return to;\n  }\n  if(!fabs) {\n    return (to&0x8000)+1;\n  }\n  unsigned int out =\n    from +\n    (((from>>15)^(unsigned int)((from^(0x8000|(0x8000-(from>>15))))<(to^(0x8000|(0x8000-(to>>15))))))<<1)\n    - 1;\n  return out;\n}\n\n// End of half.h.\n// Start of scalar.h.\n\n// Implementation of the primitive scalar operations.  Very\n// repetitive.  This code is inserted directly into both CUDA and\n// OpenCL programs, as well as the CPU code, so it has some #ifdefs to\n// work everywhere.  Some operations are defined as macros because\n// this allows us to use them as constant expressions in things like\n// array sizes and static initialisers.\n\n// Some of the #ifdefs are because OpenCL uses type-generic functions\n// for some operations (e.g. sqrt), while C and CUDA sensibly use\n// distinct functions for different precisions (e.g. sqrtf() and\n// sqrt()).  This is quite annoying.  Due to C's unfortunate casting\n// rules, it is also really easy to accidentally implement\n// floating-point functions in the wrong precision, so be careful.\n\n// Do", "uble-precision definitions are only included if the preprocessor\n// macro FUTHARK_F64_ENABLED is set.\n\nSCALAR_FUN_ATTR uint8_t add8(uint8_t x, uint8_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint16_t add16(uint16_t x, uint16_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint32_t add32(uint32_t x, uint32_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint64_t add64(uint64_t x, uint64_t y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR uint8_t sub8(uint8_t x, uint8_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint16_t sub16(uint16_t x, uint16_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint32_t sub32(uint32_t x, uint32_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint64_t sub64(uint64_t x, uint64_t y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR uint8_t mul8(uint8_t x, uint8_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint16_t mul16(uint16_t x, uint16_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint32_t mul32(uint32_t x, uint32_t y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR uint64_t mul64(uint64_t x, uint64_t y) {\n  return x * y;\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  // This strange pattern is used to prevent the ISPC compiler from\n  // causing SIGFPEs and bogus results on divisions where inactive lanes\n  // have 0-valued divisors. It ensures that any inactive lane instead\n  // has a divisor of 1. https://github.com/ispc/ispc/issues/2292\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udi", "v_up16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys =",
                                    " y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : (x + y - 1) / ys;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  uint8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  uint16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  uint32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  uint64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t q = x / ys;\n  int8_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t q = x / ys;\n  int16_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n  int32_t q = x / ys;\n  int32_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t q = x / ys;\n  int64_t r = x % ys;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv6", "4(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int8_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int16_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int32_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  int64_t r = x % ys;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return", " y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return x % ys;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x / ys;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  int8_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  int16_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int3",
                                    "2_t x, int32_t y) {\n  int32_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  int64_t ys = 1;\n  foreach_active(i){\n    ys = y;\n  }\n\n  return y == 0 ? 0 : x % ys;\n}\n\n#else\n\nSCALAR_FUN_ATTR uint8_t udiv8(uint8_t x, uint8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv16(uint16_t x, uint16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv32(uint32_t x, uint32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv64(uint64_t x, uint64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up8(uint8_t x, uint8_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up16(uint16_t x, uint16_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up32(uint32_t x, uint32_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up64(uint64_t x, uint64_t y) {\n  return (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod8(uint8_t x, uint8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod16(uint16_t x, uint16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod32(uint32_t x, uint32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod64(uint64_t x, uint64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR uint8_t udiv_up_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint16_t udiv_up_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint32_t udiv_up_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint64_t udiv_up_safe64(uint64_t x, uint64_t y) {\n  return ", "y == 0 ? 0 : (x + y - 1) / y;\n}\n\nSCALAR_FUN_ATTR uint8_t umod_safe8(uint8_t x, uint8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint16_t umod_safe16(uint16_t x, uint16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint32_t umod_safe32(uint32_t x, uint32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR uint64_t umod_safe64(uint64_t x, uint64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int8_t sdiv8(int8_t x, int8_t y) {\n  int8_t q = x / y;\n  int8_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv16(int16_t x, int16_t y) {\n  int16_t q = x / y;\n  int16_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv32(int32_t x, int32_t y) {\n  int32_t q = x / y;\n  int32_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv64(int64_t x, int64_t y) {\n  int64_t q = x / y;\n  int64_t r = x % y;\n\n  return q - ((r != 0 && r < 0 != y < 0) ? 1 : 0);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up8(int8_t x, int8_t y) {\n  return sdiv8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up16(int16_t x, int16_t y) {\n  return sdiv16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up32(int32_t x, int32_t y) {\n  return sdiv32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up64(int64_t x, int64_t y) {\n  return sdiv64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod8(int8_t x, int8_t y) {\n  int8_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int16_t smod16(int16_t x, int16_t y) {\n  int16_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int32_t smod32(int32_t x, int32_t y) {\n  int32_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int64_t smod64(int64_t x, int64_t y) {\n  int64_t r = x % y;\n\n  return r + (r == 0 || (x > 0 && y > 0) || (x < 0 && y < 0) ? 0 : y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv", "_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : sdiv8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : sdiv16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : sdiv32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : sdiv64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t sdiv_up_safe8(int8_t x, int8_t y) {\n  return sdiv_safe8(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int16_t sdiv_up_safe16(int16_t x, int16_t y) {\n  return sdiv_safe16(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int32_t sdiv_up_safe32(int32_t x, int32_t y) {\n  return sdiv_safe32(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int64_t sdiv_up_safe64(int64_t x, int64_t y) {\n  return sdiv_safe64(x + y - 1, y);\n}\n\nSCALAR_FUN_ATTR int8_t smod_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : smod8(x, y);\n}\n\nSCALAR_FUN_ATTR int16_t smod_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : smod16(x, y);\n}\n\nSCALAR_FUN_ATTR int32_t smod_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : smod32(x, y);\n}\n\nSCALAR_FUN_ATTR int64_t smod_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : smod64(x, y);\n}\n\nSCALAR_FUN_ATTR int8_t squot8(int8_t x, int8_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot16(int16_t x, int16_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot32(int32_t x, int32_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot64(int64_t x, int64_t y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem8(int8_t x, int8_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem16(int16_t x, int16_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem32(int32_t x, int32_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem64(int64_t x, int64_t y) {\n  return x % y;\n}\n\nSCALAR_FUN_ATTR int8_t squot_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int16_t squot_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int32_t squot_safe32(int32_t x, int32_t y) {\n  return y ",
                                    "== 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int64_t squot_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x / y;\n}\n\nSCALAR_FUN_ATTR int8_t srem_safe8(int8_t x, int8_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int16_t srem_safe16(int16_t x, int16_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int32_t srem_safe32(int32_t x, int32_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\nSCALAR_FUN_ATTR int64_t srem_safe64(int64_t x, int64_t y) {\n  return y == 0 ? 0 : x % y;\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t smin8(int8_t x, int8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int16_t smin16(int16_t x, int16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int32_t smin32(int32_t x, int32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int64_t smin64(int64_t x, int64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint8_t umin8(uint8_t x, uint8_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint16_t umin16(uint16_t x, uint16_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint32_t umin32(uint32_t x, uint32_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR uint64_t umin64(uint64_t x, uint64_t y) {\n  return x < y ? x : y;\n}\n\nSCALAR_FUN_ATTR int8_t smax8(int8_t x, int8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int16_t smax16(int16_t x, int16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int32_t smax32(int32_t x, int32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR int64_t smax64(int64_t x, int64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t umax8(uint8_t x, uint8_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint16_t umax16(uint16_t x, uint16_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint32_t umax32(uint32_t x, uint32_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint64_t umax64(uint64_t x, uint64_t y) {\n  return x < y ? y : x;\n}\n\nSCALAR_FUN_ATTR uint8_t shl8(uint8_t x, uint8_t y) {\n  return (uint8_t)(x << y);\n}\n\nSCALAR_FUN_ATTR uint16_t shl16(uint16_t x, uint16_t y) {\n  return (uint16_t)(x << y);\n}\n\nSCALAR_FUN_ATTR uint3", "2_t shl32(uint32_t x, uint32_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint64_t shl64(uint64_t x, uint64_t y) {\n  return x << y;\n}\n\nSCALAR_FUN_ATTR uint8_t lshr8(uint8_t x, uint8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint16_t lshr16(uint16_t x, uint16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint32_t lshr32(uint32_t x, uint32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint64_t lshr64(uint64_t x, uint64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int8_t ashr8(int8_t x, int8_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int16_t ashr16(int16_t x, int16_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int32_t ashr32(int32_t x, int32_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR int64_t ashr64(int64_t x, int64_t y) {\n  return x >> y;\n}\n\nSCALAR_FUN_ATTR uint8_t and8(uint8_t x, uint8_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint16_t and16(uint16_t x, uint16_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint32_t and32(uint32_t x, uint32_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint64_t and64(uint64_t x, uint64_t y) {\n  return x & y;\n}\n\nSCALAR_FUN_ATTR uint8_t or8(uint8_t x, uint8_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint16_t or16(uint16_t x, uint16_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint32_t or32(uint32_t x, uint32_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint64_t or64(uint64_t x, uint64_t y) {\n  return x | y;\n}\n\nSCALAR_FUN_ATTR uint8_t xor8(uint8_t x, uint8_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint16_t xor16(uint16_t x, uint16_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint32_t xor32(uint32_t x, uint32_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR uint64_t xor64(uint64_t x, uint64_t y) {\n  return x ^ y;\n}\n\nSCALAR_FUN_ATTR bool ult8(uint8_t x, uint8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult16(uint16_t x, uint16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult32(uint32_t x, uint32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ult64(uint64_t x, uint64_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool ule8(uint8_t x, uint8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_A", "TTR bool ule16(uint16_t x, uint16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule32(uint32_t x, uint32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool ule64(uint64_t x, uint64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool slt8(int8_t x, int8_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt16(int16_t x, int16_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt32(int32_t x, int32_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool slt64(int64_t x, int64_t y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool sle8(int8_t x, int8_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle16(int16_t x, int16_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle32(int32_t x, int32_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR bool sle64(int64_t x, int64_t y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR uint8_t pow8(uint8_t x, uint8_t y) {\n  uint8_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint16_t pow16(uint16_t x, uint16_t y) {\n  uint16_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint32_t pow32(uint32_t x, uint32_t y) {\n  uint32_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR uint64_t pow64(uint64_t x, uint64_t y) {\n  uint64_t res = 1, rem = y;\n\n  while (rem != 0) {\n    if (rem & 1)\n      res *= x;\n    rem >>= 1;\n    x *= x;\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR bool itob_i8_bool(int8_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i16_bool(int16_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i32_bool(int32_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR bool itob_i64_bool(int64_t x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR int8_t btoi_bool_i8(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int16_t btoi_bool_i16(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int32_t btoi_bool_i32(bool x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR int64_t bto",
                                    "i_bool_i64(bool x) {\n  return x;\n}\n\n#define sext_i8_i8(x) ((int8_t) (int8_t) (x))\n#define sext_i8_i16(x) ((int16_t) (int8_t) (x))\n#define sext_i8_i32(x) ((int32_t) (int8_t) (x))\n#define sext_i8_i64(x) ((int64_t) (int8_t) (x))\n#define sext_i16_i8(x) ((int8_t) (int16_t) (x))\n#define sext_i16_i16(x) ((int16_t) (int16_t) (x))\n#define sext_i16_i32(x) ((int32_t) (int16_t) (x))\n#define sext_i16_i64(x) ((int64_t) (int16_t) (x))\n#define sext_i32_i8(x) ((int8_t) (int32_t) (x))\n#define sext_i32_i16(x) ((int16_t) (int32_t) (x))\n#define sext_i32_i32(x) ((int32_t) (int32_t) (x))\n#define sext_i32_i64(x) ((int64_t) (int32_t) (x))\n#define sext_i64_i8(x) ((int8_t) (int64_t) (x))\n#define sext_i64_i16(x) ((int16_t) (int64_t) (x))\n#define sext_i64_i32(x) ((int32_t) (int64_t) (x))\n#define sext_i64_i64(x) ((int64_t) (int64_t) (x))\n#define zext_i8_i8(x) ((int8_t) (uint8_t) (x))\n#define zext_i8_i16(x) ((int16_t) (uint8_t) (x))\n#define zext_i8_i32(x) ((int32_t) (uint8_t) (x))\n#define zext_i8_i64(x) ((int64_t) (uint8_t) (x))\n#define zext_i16_i8(x) ((int8_t) (uint16_t) (x))\n#define zext_i16_i16(x) ((int16_t) (uint16_t) (x))\n#define zext_i16_i32(x) ((int32_t) (uint16_t) (x))\n#define zext_i16_i64(x) ((int64_t) (uint16_t) (x))\n#define zext_i32_i8(x) ((int8_t) (uint32_t) (x))\n#define zext_i32_i16(x) ((int16_t) (uint32_t) (x))\n#define zext_i32_i32(x) ((int32_t) (uint32_t) (x))\n#define zext_i32_i64(x) ((int64_t) (uint32_t) (x))\n#define zext_i64_i8(x) ((int8_t) (uint64_t) (x))\n#define zext_i64_i16(x) ((int16_t) (uint64_t) (x))\n#define zext_i64_i32(x) ((int32_t) (uint64_t) (x))\n#define zext_i64_i64(x) ((int64_t) (uint64_t) (x))\n\nSCALAR_FUN_ATTR int8_t abs8(int8_t x) {\n  return (int8_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int16_t abs16(int16_t x) {\n  return (int16_t)abs(x);\n}\n\nSCALAR_FUN_ATTR int32_t abs32(int32_t x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR int64_t abs64(int64_t x) {\n#if defined(__OPENCL_VERSION__) || defined(ISPC)\n  return abs(x);\n#else\n  return llabs(x);\n#endif\n}\n\n#if defined(__OPENCL_VERSION__)\n", "SCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return popcount(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return popcount(x);\n}\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(int8_t x) {\n  return __popc(zext_i8_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(int16_t x) {\n  return __popc(zext_i16_i32(x));\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(int32_t x) {\n  return __popc(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(int64_t x) {\n  return __popcll(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_popc8(uint8_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc16(uint16_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc32(uint32_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_popc64(uint64_t x) {\n  int c = 0;\n  for (; x; ++c) { x &= x - 1; }\n  return c;\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR uint8_t  futrts_umul_hi8 ( uint8_t a,  uint8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint8_t  futrts_smul_hi8 ( int8_t a,  int8_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return mul_hi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return mul_hi(a, b); }\n#elif defined(__CUDA_ARCH__)\nSCALAR_FUN_ATTR  uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { ", "return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return __umulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return __umul64hi(a, b); }\nSCALAR_FUN_ATTR  uint8_t futrts_smul_hi8 ( int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_smul_hi32(int32_t a, int32_t b) { return __mulhi(a, b); }\nSCALAR_FUN_ATTR uint64_t futrts_smul_hi64(int64_t a, int64_t b) { return __mul64hi(a, b); }\n#elif ISPC\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 = al * bl;\n  uint64_t p2 = al * bh;\n  uint64_t p3 = ah * bl;\n  uint64_t p4 = ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\nSCALAR_FUN_ATTR  int8_t futrts_smul_hi8 ( int8_t a,  int8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR i",
                                    "nt64_t futrts_smul_hi64(int64_t a, int64_t b) {\n  uint64_t ah = a >> 32;\n  uint64_t al = a & 0xffffffff;\n  uint64_t bh = b >> 32;\n  uint64_t bl = b & 0xffffffff;\n\n  uint64_t p1 =  al * bl;\n  int64_t  p2 = al * bh;\n  int64_t  p3 = ah * bl;\n  uint64_t p4 =  ah * bh;\n\n  uint64_t p1h = p1 >> 32;\n  uint64_t p2h = p2 >> 32;\n  uint64_t p3h = p3 >> 32;\n  uint64_t p2l = p2 & 0xffffffff;\n  uint64_t p3l = p3 & 0xffffffff;\n\n  uint64_t l = p1h + p2l + p3l;\n  uint64_t m = (p2 >> 32) + (p3 >> 32);\n  uint64_t h = (l >> 32) + m + p4;\n\n  return h;\n}\n\n#else // Not OpenCL, ISPC, or CUDA, but plain C.\nSCALAR_FUN_ATTR uint8_t futrts_umul_hi8(uint8_t a, uint8_t b) { return ((uint16_t)a) * ((uint16_t)b) >> 8; }\nSCALAR_FUN_ATTR uint16_t futrts_umul_hi16(uint16_t a, uint16_t b) { return ((uint32_t)a) * ((uint32_t)b) >> 16; }\nSCALAR_FUN_ATTR uint32_t futrts_umul_hi32(uint32_t a, uint32_t b) { return ((uint64_t)a) * ((uint64_t)b) >> 32; }\nSCALAR_FUN_ATTR uint64_t futrts_umul_hi64(uint64_t a, uint64_t b) { return ((__uint128_t)a) * ((__uint128_t)b) >> 64; }\nSCALAR_FUN_ATTR int8_t futrts_smul_hi8(int8_t a, int8_t b) { return ((int16_t)a) * ((int16_t)b) >> 8; }\nSCALAR_FUN_ATTR int16_t futrts_smul_hi16(int16_t a, int16_t b) { return ((int32_t)a) * ((int32_t)b) >> 16; }\nSCALAR_FUN_ATTR int32_t futrts_smul_hi32(int32_t a, int32_t b) { return ((int64_t)a) * ((int64_t)b) >> 32; }\nSCALAR_FUN_ATTR int64_t futrts_smul_hi64(int64_t a, int64_t b) { return ((__int128_t)a) * ((__int128_t)b) >> 64; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8 ( uint8_t a,  uint8_t b,  uint8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8( int8_t a,  i", "nt8_t b,   int8_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return mad_hi(a, b, c); }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return mad_hi(a, b, c); }\n#else // Not OpenCL\n\nSCALAR_FUN_ATTR  uint8_t futrts_umad_hi8( uint8_t a,  uint8_t b,  uint8_t c) { return futrts_umul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_umad_hi16(uint16_t a, uint16_t b, uint16_t c) { return futrts_umul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_umad_hi32(uint32_t a, uint32_t b, uint32_t c) { return futrts_umul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_umad_hi64(uint64_t a, uint64_t b, uint64_t c) { return futrts_umul_hi64(a, b) + c; }\nSCALAR_FUN_ATTR  uint8_t futrts_smad_hi8 ( int8_t a,  int8_t b,  int8_t c) { return futrts_smul_hi8(a, b) + c; }\nSCALAR_FUN_ATTR uint16_t futrts_smad_hi16(int16_t a, int16_t b, int16_t c) { return futrts_smul_hi16(a, b) + c; }\nSCALAR_FUN_ATTR uint32_t futrts_smad_hi32(int32_t a, int32_t b, int32_t c) { return futrts_smul_hi32(a, b) + c; }\nSCALAR_FUN_ATTR uint64_t futrts_smad_hi64(int64_t a, int64_t b, int64_t c) { return futrts_smul_hi64(a, b) + c; }\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return clz(x);\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return __clz(zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return __clz(zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return __clz(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return __clzll(x);\n}\n\n#elif ISPC\n\nSCALAR_", "FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return count_leading_zeros((int32_t)(uint8_t)x)-24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return count_leading_zeros((int32_t)(uint16_t)x)-16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return count_leading_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return count_leading_zeros(x);\n}\n\n#else // Not OpenCL, ISPC or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_clzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_clz((uint32_t)zext_i8_i32(x)) - 24;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_clz((uint32_t)zext_i16_i32(x)) - 16;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_clz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_clzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_clzll((uint64_t)x);\n}\n#endif\n\n#if defined(__OPENCL_VERSION__)\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int i = 0;\n  for (; i < 8 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int i = 0;\n  for (; i < 16 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int i = 0;\n  for (; i < 32 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int i = 0;\n  for (; i < 64 && (x & 1) == 0; i++, x >>= 1)\n    ;\n  return i;\n}\n\n#elif defined(__CUDA_ARCH__)\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 8 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 16 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  int y = __ffs(x);\n  return y == 0 ? 32 : y - 1;\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  int y = __ffsll(x);\n  return y == 0 ? 64 : y - 1;\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : count_trailing_zeros(",
                                    "(int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : count_trailing_zeros((int32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return count_trailing_zeros(x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return count_trailing_zeros(x);\n}\n\n#else // Not OpenCL or CUDA, but plain C.\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz8(int8_t x) {\n  return x == 0 ? 8 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz16(int16_t x) {\n  return x == 0 ? 16 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz32(int32_t x) {\n  return x == 0 ? 32 : __builtin_ctz((uint32_t)x);\n}\n\nSCALAR_FUN_ATTR int32_t futrts_ctzz64(int64_t x) {\n  return x == 0 ? 64 : __builtin_ctzll((uint64_t)x);\n}\n#endif\n\nSCALAR_FUN_ATTR float fdiv32(float x, float y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR float fadd32(float x, float y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR float fsub32(float x, float y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR float fmul32(float x, float y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt32(float x, float y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple32(float x, float y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR float sitofp_i8_f32(int8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i16_f32(int16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i32_f32(int32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float sitofp_i64_f32(int64_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i8_f32(uint8_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i16_f32(uint16_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i32_f32(uint32_t x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR float uitofp_i64_f32(uint64_t x) {\n  return (float) x;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fmin(x, y);\n}\n\nSC", "ALAR_FUN_ATTR float fpow32(float x, float y) {\n  return pow(x, y);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return isnan(x) ? y : isnan(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float a, float b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\n#else // Not OpenCL, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float fabs32(float x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR float fmax32(float x, float y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR float fmin32(float x, float y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR float fpow32(float x, float y) {\n  return powf(x, y);\n}\n#endif\n\nSCALAR_FUN_ATTR bool futrts_isnan32(float x) {\n  return isnan(x);\n}\n\n#if ISPC\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite32(float x) {\n  return !isnan(x) && !futrts_isinf32(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf32(float x) {\n  return isinf(x);\n}\n\n#endif\n\nSCALAR_FUN_ATTR int8_t fptosi_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  };\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f32_i8(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  ", "}\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f32_i16(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f32_i32(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f32_i64(float x) {\n  if (futrts_isnan32(x) || futrts_isinf32(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f32_bool(float x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR float btof_bool_f32(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(flo",
                                    "at x, float y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fma(a, b, c);\n}\n\n#elif ISPC\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return futrts_isfinite32(x) || (futrts_isinf32(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return futrts_log32(x) / log(2.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return futrts_log32(x) / log(10.0f);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  if(x == -1.0f || (futrts_isinf32(x) && x > 0.0f)) return x / 0.0f;\n  float y = 1.0f + x;\n  float z = y - 1.0f;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform float cbrtf(uniform float);\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cos(x);\n}\n\nSCALAR_FUN_AT", "TR float futrts_sin32(float x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return (exp(x)+exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return (exp(x)-exp(-x)) / 2.0f;\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return futrts_sinh32(x)/futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  float f = x+sqrt(x*x-1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  float f = x+sqrt(x*x+1);\n  if(futrts_isfinite32(f)) return log(f);\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  float f = (1+x)/(1-x);\n  if(futrts_isfinite32(f)) return log(f)/2.0f;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return (x == 0.0f && y == 0.0f) ? 0.0f : atan2(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  if (futrts_isfinite32(x) && futrts_isfinite32(y)) {\n    x = abs(x);\n    y = abs(y);\n    float a;\n    float b;\n    if (x >= y){\n        a = x;\n        b = y;\n    } else {\n        a = y;\n        b = x;\n    }\n    if(b == 0){\n      return a;\n    }\n\n    int e;\n    float an;\n    float bn;\n    an = frexp (a, &e);\n    bn = ldexp (b, - e);\n    float cn;\n    cn = sqrt (an * an + bn * bn);\n    return ldexp (cn, e);\n  } else {\n    if (futrts_isinf32(x) || futrts_isinf32(y)) return INFINITY;\n    else return x + y;\n  }\n\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = tgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR float f", "utrts_lgamma32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = lgammaf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erff(uniform float x);\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erff(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float erfcf(uniform float x);\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  float res;\n  foreach_active (i) {\n    uniform float r = erfcf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform float nextafterf(uniform float x, uniform float y);\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  float res;\n  foreach_active (i) {\n    uniform float r = nextafterf(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return a * b + c;\n}\n\n#else // Not OpenCL or ISPC, but CUDA or plain C.\n\nSCALAR_FUN_ATTR float futrts_log32(float x) {\n  return logf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log2_32(float x) {\n  return log2f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log10_32(float x) {\n  return log10f(x);\n}\n\nSCALAR_FUN_ATTR float futrts_log1p_32(float x) {\n  return log1pf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sqrt32(float x) {\n  return sqrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cbrt32(float x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_exp32(float x) {\n  retu",
                                    "rn expf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cos32(float x) {\n  return cosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sin32(float x) {\n  return sinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tan32(float x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acos32(float x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asin32(float x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan32(float x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_cosh32(float x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_sinh32(float x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_tanh32(float x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_acosh32(float x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_asinh32(float x) {\n  return asinhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atanh32(float x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_atan2_32(float x, float y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_hypot32(float x, float y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_gamma32(float x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_lgamma32(float x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erf32(float x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR float futrts_erfc32(float x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR float fmod32(float x, float y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_round32(float x) {\n  return rintf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_floor32(float x) {\n  return floorf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_ceil32(float x) {\n  return ceilf(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter32(float x, float y) {\n  return nextafterf(x, y);\n}\n\nSCALAR_FUN_ATTR float futrts_lerp32(float v0, float v1, float t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR float futrts_mad32(float a, float b, float c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float futrts_fma32(float a, float b, float c) {\n  return fmaf(a, b, c);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(", "float x) {\n  return intbits(x);\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  return floatbits(x);\n}\n#else\nSCALAR_FUN_ATTR int32_t futrts_to_bits32(float x) {\n  union {\n    float f;\n    int32_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR float futrts_from_bits32(int32_t x) {\n  union {\n    int32_t f;\n    float t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\nSCALAR_FUN_ATTR float fsignum32(float x) {\n  return futrts_isnan32(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf64(float x) {\n  return !isnan(x) && isnan(x - x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isfinite64(float x) {\n  return !isnan(x) && !futrts_isinf64(x);\n}\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR double fmin64(double x, double y) {\n  return isnan(x) ? y : isnan(y) ? x : min(", "x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double a, double b) {\n  float ret;\n  foreach_active (i) {\n      uniform float r = __stdlib_powf(extract(a, i), extract(b, i));\n      ret = insert(ret, i, r);\n  }\n  return ret;\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return futrts_isfinite64(x) || (futrts_isinf64(x) && x < 0)? log(x) : x;\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return futrts_log64(x)/log(2.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return futrts_log64(x)/log(10.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  if(x == -1.0d || (futrts_isinf64(x) && x > 0.0d)) return x / 0.0d;\n  double y = 1.0d + x;\n  double z = y - 1.0d;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nextern \"C\" unmasked uniform double cbrt(uniform double);\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = cbrtf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(double x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return (exp(x)+exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return (exp(x)-exp(-x)) / 2.0d;\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return futrts_sinh64(x)/futrts_cosh64(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  double f = x+sqrt(x*x-1.0d);\n  if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  double f = x+sqrt(x*x+1.0d);\n  ",
                                    "if(futrts_isfinite64(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  double f = (1.0d+x)/(1.0d-x);\n  if(futrts_isfinite64(f)) return log(f)/2.0d;\n  return f;\n\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nextern \"C\" unmasked uniform double hypot(uniform double x, uniform double y);\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = hypot(extract(x, i), extract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double tgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = tgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double lgamma(uniform double x);\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = lgamma(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erf(uniform double x);\nSCALAR_FUN_ATTR double futrts_erf64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erf(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform double erfc(uniform double x);\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  double res;\n  foreach_active (i) {\n    uniform double r = erfc(extract(x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return round(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nextern \"C\" unmasked uniform double nextafter(uniform float x, uniform double y);\nSCALAR_FUN_ATTR float futrts_nextafter64(double x, double y) {\n  double res;\n  foreach_active (i) {\n    uniform double r = nextafter(extract(x, i), ext", "ract(y, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0.0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1.0 : 0.0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  int64_t res;\n  foreach_active (i) {\n    uniform double tmp = extract(x, i);\n    uniform int64_t r = *((uniform int64_t* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  double res;\n  foreach_active (i) {\n    uniform int64_t tmp = extract(x, i)", ";\n    uniform double r = *((uniform double* uniform)&tmp);\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return x - y * trunc(x/y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0 ? 1.0d : 0.0d) - (x < 0 ? 1.0d : 0.0d);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#else\n\nSCALAR_FUN_ATTR double fdiv64(double x, double y) {\n  return x / y;\n}\n\nSCALAR_FUN_ATTR double fadd64(double x, double y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR double fsub64(double x, double y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR double fmul64(double x, double y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt64(double x, double y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple64(double x, double y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR double sitofp_i8_f64(int8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i16_f64(int16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i32_f64(int32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double sitofp_i64_f64(int64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i8_f64(uint8_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i16_f64(uint16_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i32_f64(uint32_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double uitofp_i64_f64(uint64_t x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR double fabs64(double x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR double fmax64(double x, double y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR double f",
                                    "min64(double x, double y) {\n  return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR double fpow64(double x, double y) {\n  return pow(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_log64(double x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log2_64(double x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log10_64(double x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR double futrts_log1p_64(double x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sqrt64(double x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cbrt64(double x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR double futrts_exp64(double x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cos64(double x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sin64(double x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tan64(double x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acos64(double x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asin64(double x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan64(double x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR double futrts_cosh64(double x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_sinh64(double x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_tanh64(double x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_acosh64(double x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_asinh64(double x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atanh64(double x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR double futrts_atan2_64(double x, double y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_hypot64(double x, double y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_gamma64(double x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_lgamma64(double x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erf64(double x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR double futrts_erfc64(double x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR double futrts_fma64(double a, double b, double c) {\n  return fma(a, ", "b, c);\n}\n\nSCALAR_FUN_ATTR double futrts_round64(double x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR double futrts_ceil64(double x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR float futrts_nextafter64(float x, float y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR double futrts_floor64(double x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan64(double x) {\n  return isnan(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf64(double x) {\n  return isinf(x);\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f64_i8(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint8_t) (int8_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f64_i16(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint16_t) (int16_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f64_i32(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint32_t) (int32_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f64_i64(double x) {\n  if (futrts_isnan64(x) || futrts_isinf64(x)) {\n    return 0;\n  } else {\n    return (uint64_t) (int64_t) x;\n  }\n}\n\nSCALAR_FUN_ATTR bool ftob_f64_bool(double x) {\n  return x != 0;\n}\n\nSCALAR_FUN_ATTR double btof_bool_f64(bool x) {\n  return x ? 1 : 0;\n}\n\nSCALAR_FUN_ATTR int64_t futrts_to_bits64(double x) {\n  union {\n    double f;\n    int64_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nS", "CALAR_FUN_ATTR double futrts_from_bits64(int64_t x) {\n  union {\n    int64_t f;\n    double t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR double fmod64(double x, double y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR double fsignum64(double x) {\n  return futrts_isnan64(x) ? x : (x > 0) - (x < 0);\n}\n\nSCALAR_FUN_ATTR double futrts_lerp64(double v0, double v1, double t) {\n#ifdef __OPENCL_VERSION__\n  return mix(v0, v1, t);\n#else\n  return v0 + (v1 - v0) * t;\n#endif\n}\n\nSCALAR_FUN_ATTR double futrts_mad64(double a, double b, double c) {\n#ifdef __OPENCL_VERSION__\n  return mad(a, b, c);\n#else\n  return a * b + c;\n#endif\n}\n\nSCALAR_FUN_ATTR float fpconv_f32_f32(float x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f32_f64(float x) {\n  return (double) x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f64_f32(double x) {\n  return (float) x;\n}\n\nSCALAR_FUN_ATTR double fpconv_f64_f64(double x) {\n  return (double) x;\n}\n\n#endif\n\n#endif\n\n// End of scalar.h.\n// Start of scalar_f16.h.\n\n// Half-precision is emulated if needed (e.g. in straight C) with the\n// native type used if possible.  The emulation works by typedef'ing\n// 'float' to 'f16', and then implementing all operations on single\n// precision.  To cut down on duplication, we use the same code for\n// those Futhark functions that require just operators or casts.  The\n// in-memory representation for arrays will still be 16 bits even\n// under emulation, so the compiler will have to be careful when\n// generating reads or writes.\n\n#if !defined(cl_khr_fp16) && !(defined(__CUDA_ARCH__) && __CUDA_ARCH__ >= 600) && !(defined(ISPC))\n#define EMULATE_F16\n#endif\n\n#if !defined(EMULATE_F16) && defined(__OPENCL_VERSION__)\n#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n#endif\n\n#ifdef EMULATE_F16\n\n// Note that the half-precision storage format is still 16 bits - the\n// compiler will have to be real careful!\ntypedef float f16;\n\n#elif ISPC\ntypedef float16 f16;\n\n#else\n\n#ifdef __CUDA_ARCH__\n#include <cuda_fp16.h>\n#endif\n\ntypedef half f16;\n\n#endif\n\n// So",
                                    "me of these functions convert to single precision because half\n// precision versions are not available.\n\nSCALAR_FUN_ATTR f16 fadd16(f16 x, f16 y) {\n  return x + y;\n}\n\nSCALAR_FUN_ATTR f16 fsub16(f16 x, f16 y) {\n  return x - y;\n}\n\nSCALAR_FUN_ATTR f16 fmul16(f16 x, f16 y) {\n  return x * y;\n}\n\nSCALAR_FUN_ATTR bool cmplt16(f16 x, f16 y) {\n  return x < y;\n}\n\nSCALAR_FUN_ATTR bool cmple16(f16 x, f16 y) {\n  return x <= y;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i8_f16(int8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i16_f16(int16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i32_f16(int32_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 sitofp_i64_f16(int64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i8_f16(uint8_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i16_f16(uint16_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i32_f16(uint32_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR f16 uitofp_i64_f16(uint64_t x) {\n  return (f16) x;\n}\n\nSCALAR_FUN_ATTR int8_t fptosi_f16_i8(f16 x) {\n  return (int8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR int16_t fptosi_f16_i16(f16 x) {\n  return (int16_t) x;\n}\n\nSCALAR_FUN_ATTR int32_t fptosi_f16_i32(f16 x) {\n  return (int32_t) x;\n}\n\nSCALAR_FUN_ATTR int64_t fptosi_f16_i64(f16 x) {\n  return (int64_t) x;\n}\n\nSCALAR_FUN_ATTR uint8_t fptoui_f16_i8(f16 x) {\n  return (uint8_t) (float) x;\n}\n\nSCALAR_FUN_ATTR uint16_t fptoui_f16_i16(f16 x) {\n  return (uint16_t) x;\n}\n\nSCALAR_FUN_ATTR uint32_t fptoui_f16_i32(f16 x) {\n  return (uint32_t) x;\n}\n\nSCALAR_FUN_ATTR uint64_t fptoui_f16_i64(f16 x) {\n  return (uint64_t) x;\n}\n\nSCALAR_FUN_ATTR bool ftob_f16_bool(f16 x) {\n  return x != (f16)0;\n}\n\nSCALAR_FUN_ATTR f16 btof_bool_f16(bool x) {\n  return x ? 1 : 0;\n}\n\n#ifndef EMULATE_F16\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return isnan((float)x);\n}\n\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  ", "return fmin(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n\n#elif ISPC\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return abs(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : max(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return futrts_isnan16(x) ? y : futrts_isnan16(y) ? x : min(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return pow(x, y);\n}\n#else // Assuming CUDA.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabsf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmaxf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fminf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return powf(x, y);\n}\n#endif\n\n#if ISPC\nSCALAR_FUN_ATTR bool futrts_isinf16(float x) {\n  return !futrts_isnan16(x) && futrts_isnan16(x - x);\n}\nSCALAR_FUN_ATTR bool futrts_isfinite16(float x) {\n  return !futrts_isnan16(x) && !futrts_isinf16(x);\n}\n\n#else\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return isinf((float)x);\n}\n#endif\n\n#ifdef __OPENCL_VERSION__\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return log(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return log2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return log10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return log1p(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return sqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return cos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return sin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atan(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return cosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f1", "6 x) {\n  return sinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acosh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return asinh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanh(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypot(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return tgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgamma(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return erf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfc(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rint(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return floor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return ceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return nextafter(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return mix(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return mad(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fma(a, b, c);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_isfinite16(x) || (futrts_isinf16(x) && x < 0) ? log(x) : x;\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log16(x) / log(2.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log16(x) / log(10.0f16);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  if(x == -1.0f16 || (futrts_isinf16(x) && x > 0.0f16)) return x / 0.0f16;\n  f16 y = 1.0f16 + x;\n  f16 z = y - 1.0f16;\n  return log(y) - (z-x)/y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return (float16)sqrt((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return exp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return (flo",
                                    "at16)cos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return (float16)sin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return (float16)tan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return (float16)acos((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return (float16)asin((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return (float16)atan((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return (exp(x)+exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return (exp(x)-exp(-x)) / 2.0f16;\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_sinh16(x)/futrts_cosh16(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x-1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  float16 f = x+(float16)sqrt((float)(x*x+1));\n  if(futrts_isfinite16(f)) return log(f);\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  float16 f = (1+x)/(1-x);\n  if(futrts_isfinite16(f)) return log(f)/2.0f16;\n  return f;\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return (float16)atan2((float)x, (float)y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return (float16)futrts_hypot32((float)x, (float)y);\n}\n\nextern \"C\" unmasked uniform float tgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)tgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nextern \"C\" unmasked uniform float lgammaf(uniform float x);\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  f16 res;\n  foreach_active (i) {\n    uniform f16 r = (f16)lgammaf(extract((float)x, i));\n    res = insert(res, i, r);\n  }\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  f16 res = (f16)futrts_cbrt32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  f16 res = (f16)futrts_erf32((float)x);\n  return res;\n", "}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  f16 res = (f16)futrts_erfc32((float)x);\n  return res;\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return x - y * (float16)trunc((float) (x/y));\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return (float16)round((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return (float16)floor((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return (float16)ceil((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return (float16)futrts_nextafter32((float)x, (float) y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\n#else // Assume CUDA.\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return hlog(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return hlog2(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return hlog10(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return (f16)log1pf((float)x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return hsqrt(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return cbrtf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return hexp(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return hcos(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return hsin(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return tanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return acosf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return asinf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return atanf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return coshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return sinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return tanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return acoshf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return", " asinhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return atanhf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return atan2f(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return hypotf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return tgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return lgammaf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return erff(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return erfcf(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmodf(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return rintf(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return hfloor(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return hceil(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return __ushort_as_half(halfbitsnextafter(__half_as_ushort(x), __half_as_ushort(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return v0 + (v1 - v0) * t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return a * b + c;\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return fmaf(a, b, c);\n}\n\n#endif\n\n// The CUDA __half type cannot be put in unions for some reason, so we\n// use bespoke conversion functions instead.\n#ifdef __CUDA_ARCH__\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return __half_as_ushort(x);\n}\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return __ushort_as_half(x);\n}\n#elif ISPC\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  varying int16_t y = *((varying int16_t * uniform)&x);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  varying f16 y = *((varying f16 * uniform)&x);\n  return y;\n}\n#else\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  union {\n    f16 f;\n    int16_t t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  union {\n    int16_t f;\n    f16 t;\n  } p;\n\n  p.f = x;\n  return p.t;\n}\n#endif\n\n#else // No nati",
                                    "ve f16 - emulate.\n\nSCALAR_FUN_ATTR f16 fabs16(f16 x) {\n  return fabs32(x);\n}\n\nSCALAR_FUN_ATTR f16 fmax16(f16 x, f16 y) {\n  return fmax32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fmin16(f16 x, f16 y) {\n  return fmin32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 fpow16(f16 x, f16 y) {\n  return fpow32(x, y);\n}\n\nSCALAR_FUN_ATTR bool futrts_isnan16(f16 x) {\n  return futrts_isnan32(x);\n}\n\nSCALAR_FUN_ATTR bool futrts_isinf16(f16 x) {\n  return futrts_isinf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log16(f16 x) {\n  return futrts_log32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log2_16(f16 x) {\n  return futrts_log2_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log10_16(f16 x) {\n  return futrts_log10_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_log1p_16(f16 x) {\n  return futrts_log1p_32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sqrt16(f16 x) {\n  return futrts_sqrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cbrt16(f16 x) {\n  return futrts_cbrt32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_exp16(f16 x) {\n  return futrts_exp32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cos16(f16 x) {\n  return futrts_cos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sin16(f16 x) {\n  return futrts_sin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tan16(f16 x) {\n  return futrts_tan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acos16(f16 x) {\n  return futrts_acos32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asin16(f16 x) {\n  return futrts_asin32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan16(f16 x) {\n  return futrts_atan32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_cosh16(f16 x) {\n  return futrts_cosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_sinh16(f16 x) {\n  return futrts_sinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_tanh16(f16 x) {\n  return futrts_tanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_acosh16(f16 x) {\n  return futrts_acosh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_asinh16(f16 x) {\n  return futrts_asinh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atanh16(f16 x) {\n  return futrts_atanh32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_atan2_16(f16 x, f16 y) {\n  return futrts_atan2_32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_hypot16(f16 x, f16 y) {\n  return futrts_hypot32(x, y);\n}", "\n\nSCALAR_FUN_ATTR f16 futrts_gamma16(f16 x) {\n  return futrts_gamma32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_lgamma16(f16 x) {\n  return futrts_lgamma32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erf16(f16 x) {\n  return futrts_erf32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_erfc16(f16 x) {\n  return futrts_erfc32(x);\n}\n\nSCALAR_FUN_ATTR f16 fmod16(f16 x, f16 y) {\n  return fmod32(x, y);\n}\n\nSCALAR_FUN_ATTR f16 futrts_round16(f16 x) {\n  return futrts_round32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_floor16(f16 x) {\n  return futrts_floor32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_ceil16(f16 x) {\n  return futrts_ceil32(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_nextafter16(f16 x, f16 y) {\n  return halfbits2float(halfbitsnextafter(float2halfbits(x), float2halfbits(y)));\n}\n\nSCALAR_FUN_ATTR f16 futrts_lerp16(f16 v0, f16 v1, f16 t) {\n  return futrts_lerp32(v0, v1, t);\n}\n\nSCALAR_FUN_ATTR f16 futrts_mad16(f16 a, f16 b, f16 c) {\n  return futrts_mad32(a, b, c);\n}\n\nSCALAR_FUN_ATTR f16 futrts_fma16(f16 a, f16 b, f16 c) {\n  return futrts_fma32(a, b, c);\n}\n\n// Even when we are using an OpenCL that does not support cl_khr_fp16,\n// it must still support vload_half for actually creating a\n// half-precision number, which can then be efficiently converted to a\n// float.  Similarly for vstore_half.\n#ifdef __OPENCL_VERSION__\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  int16_t y;\n  // Violating strict aliasing here.\n  vstore_half((float)x, 0, (half*)&y);\n  return y;\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return (f16)vload_half(0, (half*)&x);\n}\n\n#else\n\nSCALAR_FUN_ATTR int16_t futrts_to_bits16(f16 x) {\n  return (int16_t)float2halfbits(x);\n}\n\nSCALAR_FUN_ATTR f16 futrts_from_bits16(int16_t x) {\n  return halfbits2float((uint16_t)x);\n}\n\nSCALAR_FUN_ATTR f16 fsignum16(f16 x) {\n  return futrts_isnan16(x) ? x : (x > 0 ? 1 : 0) - (x < 0 ? 1 : 0);\n}\n\n#endif\n\n#endif\n\nSCALAR_FUN_ATTR float fpconv_f16_f16(f16 x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR float fpconv_f16_f32(f16 x) {\n  return x;\n}\n\nSCALAR_FUN_ATTR f16 fpconv_f32_f16(fl", "oat x) {\n  return (f16) x;\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double fpconv_f16_f64(f16 x) {\n  return (double) x;\n}\n\n#if ISPC\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) ((float)x);\n}\n#else\nSCALAR_FUN_ATTR f16 fpconv_f64_f16(double x) {\n  return (f16) x;\n}\n#endif\n#endif\n\n\n// End of scalar_f16.h.\n// Start of atomics.h\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_local(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_local(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_add_i32_local(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x);\nSCALAR_FUN_ATTR float atomic_fadd_f32_local(volatile __local float *p, float x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_local(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_local(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_local(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_local(volatile __local uint32_t *p, uint32_t x);\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_",
                                    "FUN_ATTR int32_t atomic_and_i32_local(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_or_i32_local(volatile __local int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x);\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_local(volatile __local int32_t *p, int32_t x);\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xchg_i32_local(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_global(volatile __global int32_t *p,\n                                                         int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_cmpxchg_i32_local(volatile __local int32_t *p,\n                                                        int32_t cmp, int32_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((int32_t*)p, cmp, val);\n#else\n  return atomic_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_add_i32_local(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((int32_t*)p, x);\n#else\n  return atomic_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_global(volatile __global float *p, float x)", " {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_global((volatile __global int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR float atomic_fadd_f32_local(volatile __local float *p, float x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((float*)p, x);\n#else\n  union { int32_t i; float f; } old;\n  union { int32_t i; float f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i32_local((volatile __local int32_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smax_i32_local(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((int32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_smin_i32_local(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((int32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umax_i32_local(volatile __lo", "cal uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint32_t*)p, x);\n#else\n  return atomic_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_global(volatile __global uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint32_t atomic_umin_i32_local(volatile __local uint32_t *p, uint32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint32_t*)p, x);\n#else\n  return atomic_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_and_i32_local(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((int32_t*)p, x);\n#else\n  return atomic_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_or_i32_local(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((int32_t*)p, x);\n#else\n  return atomic_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_global(volatile __global int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int32_t atomic_xor_i32_local(volatile __local int32_t *p, int32_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((int32_t*)p, x);\n#else\n  return atomic_xor(p, x);\n#endif\n}\n\n// Start of 64 bit atomics\n\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int",
                                    "64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_local(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_local(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_add_i64_local(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_local(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_local(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_local(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_local(volatile __local uint64_t *p, uint64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_and_i64_local(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_or_i64_local(volatile __local int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x);\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_local(volatile __local int64_t *p, int64_t x);\n\n#ifdef FUTHARK_F64_ENABLED\nS", "CALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x);\nSCALAR_FUN_ATTR double atomic_fadd_f64_local(volatile __local double *p, double x);\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xchg_i64_local(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicExch((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_global(volatile __global int64_t *p,\n                                                         int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_cmpxchg_i64_local(volatile __local int64_t *p,\n                                                        int64_t cmp, int64_t val) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicCAS((uint64_t*)p, cmp, val);\n#else\n  return atom_cmpxchg(p, cmp, val);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_add_i64_local(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAdd((uint64_t*)p, x);\n#else\n  return atom_add(p, x);\n#endif\n}\n\n#ifdef FUTHARK_F64_ENABLED\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_global(volatile __global double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  union { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    a", "ssumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\nSCALAR_FUN_ATTR double atomic_fadd_f64_local(volatile __local double *p, double x) {\n#if defined(FUTHARK_CUDA) && __CUDA_ARCH__ >= 600 || defined(FUTHARK_HIP)\n  return atomicAdd((double*)p, x);\n#else\n  union { int64_t i; double f; } old;\n  union { int64_t i; double f; } assumed;\n  old.f = *p;\n  do {\n    assumed.f = old.f;\n    old.f = old.f + x;\n    old.i = atomic_cmpxchg_i64_local((volatile __local int64_t*)p, assumed.i, old.i);\n  } while (assumed.i != old.i);\n  return old.f;\n#endif\n}\n\n#endif\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smax_i64_local(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMax((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smax64(old, x);\n    old = atomic_cmpxchg_i64_local((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic",
                                    "_cmpxchg_i64_global((volatile __global int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_smin_i64_local(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA)\n  return atomicMin((int64_t*)p, x);\n#elif defined(FUTHARK_HIP)\n  // Currentely missing in HIP; probably a temporary oversight.\n  int64_t old = *p, assumed;\n  do {\n    assumed = old;\n    old = smin64(old, x);\n    old = atomic_cmpxchg_i64_local((volatile __local int64_t*)p, assumed, old);\n  } while (assumed != old);\n  return old;\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umax_i64_local(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMax((uint64_t*)p, x);\n#else\n  return atom_max(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_global(volatile __global uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR uint64_t atomic_umin_i64_local(volatile __local uint64_t *p, uint64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicMin((uint64_t*)p, x);\n#else\n  return atom_min(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_and_i64_local(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicAnd((uint64_t*)p, x);\n#else\n  return atom_and(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_global(volatile ", "__global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_or_i64_local(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicOr((uint64_t*)p, x);\n#else\n  return atom_or(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_global(volatile __global int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\nSCALAR_FUN_ATTR int64_t atomic_xor_i64_local(volatile __local int64_t *p, int64_t x) {\n#if defined(FUTHARK_CUDA) || defined(FUTHARK_HIP)\n  return atomicXor((uint64_t*)p, x);\n#else\n  return atom_xor(p, x);\n#endif\n}\n\n#endif // defined(FUTHARK_CUDA) || defined(FUTHARK_HIP) || defined(cl_khr_int64_base_atomics) && defined(cl_khr_int64_extended_atomics)\n\n// End of atomics.h\n// Start of transpose.cl\n\n#define GEN_TRANSPOSE_KERNELS(NAME, ELEM_TYPE)                          \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME(LOCAL_MEM_PARAM                               \\\n                          __global ELEM_TYPE *dst_mem,                  \\\n                          int64_t dst_offset,                           \\\n                          __global ELEM_TYPE *src_mem,                  \\\n                          int64_t src_offset,                           \\\n                          int32_t num_arrays,                           \\\n                          int32_t x_elems,                              \\\n                          int32_t y_elems,                              \\\n                          int32_t mulx,                                 \\\n                          int32_t muly,                                 \\\n                          int32_t repeat_1,                             \\\n                          int32_t repeat_2) {      ", "                     \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)local_mem;             \\\n  int group_id_0 = get_group_id(0);                                     \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int group_id_1 = get_group_id(1);                                     \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int group_id_2 = get_group_id(2);                                   \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = group_id_2 * x_elems * y_elems;        \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = global_id_0;                                    \\\n      int32_t y_index = group_id_1 * TR_TILE_DIM + get_local_id(1);     \\\n      if (x_index < x_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\",
                                    "\n      x_index = group_id_1 * TR_TILE_DIM + get_local_id(0);             \\\n      y_index = group_id_0 * TR_TILE_DIM + get_local_id(1);             \\\n      if (x_index < y_elems) {                                          \\\n        for (int32_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int32_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      group_id_2 += get_num_groups(2);                                  \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    group_id_1 += get_num_groups(1);                                    \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_height(LOCAL_MEM_PARAM                  \\\n                                                __global ELEM_TYPE *dst_mem, \\\n                                                int64_t dst_offset,     \\\n                                                __global ELEM_TYPE *src_mem, \\\n                                                int64_t src_offset,     \\\n                           ", "                     int32_t num_arrays,     \\\n                                                int32_t x_elems,        \\\n                                                int32_t y_elems,        \\\n                                                int32_t mulx,           \\\n                                                int32_t muly,           \\\n                                                int32_t repeat_1,       \\\n                                                int32_t repeat_2) {     \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)local_mem; \\\n  int group_id_0 = get_group_id(0);                                     \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int group_id_1 = get_group_id(1);                                     \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int group_id_2 = get_group_id(2);                                   \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = group_id_2 * x_elems * y_elems;        \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index =                                                 \\\n        group_id_0 * TR_BLOCK_DIM * mulx +                              \\\n        get_local_id(0) +                                               \\\n        get_local_id(1)%mulx * TR_BLOCK_DIM;                            \\\n      int32_t y_index = group_id_1 * TR_BLOCK_DIM + get_local_id(1)/mulx; \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_", "in];                             \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = group_id_1 * TR_BLOCK_DIM + get_local_id(0)/mulx;       \\\n      y_index =                                                         \\\n        group_id_0 * TR_BLOCK_DIM * mulx +                              \\\n        get_local_id(1) +                                               \\\n        (get_local_id(0)%mulx) * TR_BLOCK_DIM;                          \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      group_id_2 += get_num_groups(2);                                  \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    group_id_1 += get_num_groups(1);                                    \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM, TR_BLOCK_DIM, 1)                     \\\nvoid map_transpose_##NAME##_low_width(LOCAL_MEM_PARAM                   \\\n                                      __global ELEM_TYPE *dst_mem,      \\\n                                      int64_t dst_offset,               \\\n                                      __global ELEM_TYPE *src_mem,      \\\n                                      int64_t src_offset,               \\\n                                      int",
                                    "32_t num_arrays,               \\\n                                      int32_t x_elems,                  \\\n                                      int32_t y_elems,                  \\\n                                      int32_t mulx,                     \\\n                                      int32_t muly,                     \\\n                                      int32_t repeat_1,                 \\\n                                      int32_t repeat_2) {               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)local_mem;             \\\n  int group_id_0 = get_group_id(0);                                     \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int group_id_1 = get_group_id(1);                                     \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int group_id_2 = get_group_id(2);                                   \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = group_id_2 * x_elems * y_elems;        \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t x_index = group_id_0 * TR_BLOCK_DIM + get_local_id(0)/muly; \\\n      int32_t y_index =                                                 \\\n        group_id_1 * TR_BLOCK_DIM * muly +                              \\\n        get_local_id(1) + (get_local_id(0)%muly) * TR_BLOCK_DIM;        \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      if (x_index < x_elems && y_index < y_elems) {                     \\\n        block[get_local_id(1) * (TR_BLOCK_DIM+1) + get_local_id(0)] =   \\\n          src_mem[idata_offset + index_in];                             \\\n      }                                  ", "                               \\\n      barrier_local();                                                  \\\n      x_index = group_id_1 * TR_BLOCK_DIM * muly +                      \\\n        get_local_id(0) + (get_local_id(1)%muly) * TR_BLOCK_DIM;        \\\n      y_index = group_id_0 * TR_BLOCK_DIM + get_local_id(1)/muly;       \\\n      int32_t index_out = y_index * y_elems + x_index;                  \\\n      if (x_index < y_elems && y_index < x_elems) {                     \\\n        dst_mem[odata_offset + index_out] =                             \\\n          block[get_local_id(0) * (TR_BLOCK_DIM+1) + get_local_id(1)];  \\\n      }                                                                 \\\n      group_id_2 += get_num_groups(2);                                  \\\n      global_id_2 += get_num_groups(2) * get_local_size(2);             \\\n    }                                                                   \\\n    group_id_1 += get_num_groups(1);                                    \\\n    global_id_1 += get_num_groups(1) * get_local_size(1);               \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*TR_BLOCK_DIM, 1, 1)                   \\\nvoid map_transpose_##NAME##_small(LOCAL_MEM_PARAM                       \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int32_t num_arrays,                   \\\n                                  int32_t x_elems,                      \\\n                                  int32_t y_elems,                      \\\n                                  int32_t m", "ulx,                         \\\n                                  int32_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)local_mem;             \\\n  int group_id_0 = get_group_id(0);                                     \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int group_id_1 = get_group_id(1);                                     \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int group_id_2 = get_group_id(2);                                   \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= repeat_2; i2++) {                            \\\n      int32_t our_array_offset = global_id_0/(y_elems * x_elems) * y_elems * x_elems; \\\n      int32_t x_index = (global_id_0 % (y_elems * x_elems))/y_elems;    \\\n      int32_t y_index = global_id_0%y_elems;                            \\\n      int32_t odata_offset = dst_offset + our_array_offset;             \\\n      int32_t idata_offset = src_offset + our_array_offset;             \\\n      int32_t index_in = y_index * x_elems + x_index;                   \\\n      int32_t index_out = x_index * y_elems + y_index;                  \\\n      if (global_id_0 < x_elems * y_elems * num_arrays) {               \\\n        dst_mem[odata_offset + index_out] = src_mem[idata_offset + index_in]; \\\n      }                                                                 \\\n      group_id_2 += get_num_groups(2);                                  \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    group_id_1 += get_num",
                                    "_groups(1);                                    \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n                                                                        \\\nFUTHARK_KERNEL_SIZED(TR_BLOCK_DIM*2, TR_TILE_DIM/TR_ELEMS_PER_THREAD, 1)\\\nvoid map_transpose_##NAME##_large(LOCAL_MEM_PARAM                       \\\n                                  __global ELEM_TYPE *dst_mem,          \\\n                                  int64_t dst_offset,                   \\\n                                  __global ELEM_TYPE *src_mem,          \\\n                                  int64_t src_offset,                   \\\n                                  int64_t num_arrays,                   \\\n                                  int64_t x_elems,                      \\\n                                  int64_t y_elems,                      \\\n                                  int64_t mulx,                         \\\n                                  int64_t muly,                         \\\n                                  int32_t repeat_1,                     \\\n                                  int32_t repeat_2) {                   \\\n  (void)mulx; (void)muly;                                               \\\n  __local ELEM_TYPE* block = (__local ELEM_TYPE*)local_mem;             \\\n  int group_id_0 = get_group_id(0);                                     \\\n  int global_id_0 = get_global_id(0);                                   \\\n  int group_id_1 = get_group_id(1);                                     \\\n  int global_id_1 = get_global_id(1);                                   \\\n  for (int i1 = 0; i1 <= repeat_1; i1++) {                              \\\n    int group_id_2 = get_group_id(2);                                   \\\n    int global_id_2 = get_global_id(2);                                 \\\n    for (int i2 = 0; i2 <= ", "repeat_2; i2++) {                            \\\n      int64_t our_array_offset = group_id_2 * x_elems * y_elems;        \\\n      int64_t odata_offset = dst_offset + our_array_offset;             \\\n      int64_t idata_offset = src_offset + our_array_offset;             \\\n      int64_t x_index = global_id_0;                                    \\\n      int64_t y_index = group_id_1 * TR_TILE_DIM + get_local_id(1);     \\\n      if (x_index < x_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_i = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * x_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < y_elems) { \\\n            block[(get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * (TR_TILE_DIM+1) + \\\n                  get_local_id(0)] =                                    \\\n              src_mem[idata_offset + index_i];                          \\\n          }                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      barrier_local();                                                  \\\n      x_index = group_id_1 * TR_TILE_DIM + get_local_id(0);             \\\n      y_index = group_id_0 * TR_TILE_DIM + get_local_id(1);             \\\n      if (x_index < y_elems) {                                          \\\n        for (int64_t j = 0; j < TR_ELEMS_PER_THREAD; j++) {             \\\n          int64_t index_out = (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)) * y_elems + x_index; \\\n          if (y_index + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD) < x_elems) { \\\n            dst_mem[(odata_offset + index_out)] =                       \\\n              block[get_local_id(0) * (TR_TILE_DIM+1) +                 \\\n                    get_local_id(1) + j * (TR_TILE_DIM/TR_ELEMS_PER_THREAD)]; \\\n          }", "                                                             \\\n        }                                                               \\\n      }                                                                 \\\n      group_id_2 += get_num_groups(2);                                  \\\n      global_id_2 += get_global_size(2);                                \\\n    }                                                                   \\\n    group_id_1 += get_num_groups(1);                                    \\\n    global_id_1 += get_global_size(1);                                  \\\n  }                                                                     \\\n}                                                                       \\\n\nGEN_TRANSPOSE_KERNELS(1b, uint8_t)\nGEN_TRANSPOSE_KERNELS(2b, uint16_t)\nGEN_TRANSPOSE_KERNELS(4b, uint32_t)\nGEN_TRANSPOSE_KERNELS(8b, uint64_t)\n\n// End of transpose.cl\n// Start of copy.cl\n\n#define GEN_COPY_KERNEL(NAME, ELEM_TYPE) \\\nFUTHARK_KERNEL void lmad_copy_##NAME(LOCAL_MEM_PARAM                    \\\n                               __global ELEM_TYPE *dst_mem,             \\\n                               int64_t dst_offset,                      \\\n                               __global ELEM_TYPE *src_mem,             \\\n                               int64_t src_offset,                      \\\n                               int64_t n,                               \\\n                               int r,                                   \\\n                               int64_t shape0, int64_t dst_stride0, int64_t src_stride0, \\\n                               int64_t shape1, int64_t dst_stride1, int64_t src_stride1, \\\n                               int64_t shape2, int64_t dst_stride2, int64_t src_stride2, \\\n                               int64_t shape3, int64_t dst_stride3, int64_t src_stride3, \\\n                               int64_t shape4, int64_t dst_stride4, int64_t src_stride4, \\\n                               int64_t shape5, int64_t dst_stride5",
                                    ", int64_t src_stride5, \\\n                               int64_t shape6, int64_t dst_stride6, int64_t src_stride6, \\\n                               int64_t shape7, int64_t dst_stride7, int64_t src_stride7) { \\\n  int64_t gtid = get_global_id(0);                                      \\\n  int64_t remainder = gtid;                                             \\\n                                                                        \\\n  if (gtid >= n) {                                                      \\\n    return;                                                             \\\n  }                                                                     \\\n                                                                        \\\n  if (r > 0) {                                                          \\\n    int64_t i = remainder % shape0;                                     \\\n    dst_offset += i * dst_stride0;                                      \\\n    src_offset += i * src_stride0;                                      \\\n    remainder /= shape0;                                                \\\n  }                                                                     \\\n  if (r > 1) {                                                          \\\n    int64_t i = remainder % shape1;                                     \\\n    dst_offset += i * dst_stride1;                                      \\\n    src_offset += i * src_stride1;                                      \\\n    remainder /= shape1;                                                \\\n  }                                                                     \\\n  if (r > 2) {                                                          \\\n    int64_t i = remainder % shape2;                                     \\\n    dst_offset += i * dst_stride2;                                      \\\n    src_offset += i * src_stride2;                                      \\\n    remainder /= shape2;                                                \\\n  }            ", "                                                         \\\n  if (r > 3) {                                                          \\\n    int64_t i = remainder % shape3;                                     \\\n    dst_offset += i * dst_stride3;                                      \\\n    src_offset += i * src_stride3;                                      \\\n    remainder /= shape3;                                                \\\n  }                                                                     \\\n  if (r > 4) {                                                          \\\n    int64_t i = remainder % shape4;                                     \\\n    dst_offset += i * dst_stride4;                                      \\\n    src_offset += i * src_stride4;                                      \\\n    remainder /= shape4;                                                \\\n  }                                                                     \\\n  if (r > 5) {                                                          \\\n    int64_t i = remainder % shape5;                                     \\\n    dst_offset += i * dst_stride5;                                      \\\n    src_offset += i * src_stride5;                                      \\\n    remainder /= shape5;                                                \\\n  }                                                                     \\\n  if (r > 6) {                                                          \\\n    int64_t i = remainder % shape6;                                     \\\n    dst_offset += i * dst_stride6;                                      \\\n    src_offset += i * src_stride6;                                      \\\n    remainder /= shape6;                                                \\\n  }                                                                     \\\n  if (r > 7) {                                                          \\\n    int64_t i = remainder % shape7;                                     \\\n    dst_offset +=", " i * dst_stride7;                                      \\\n    src_offset += i * src_stride7;                                      \\\n    remainder /= shape7;                                                \\\n  }                                                                     \\\n                                                                        \\\n  dst_mem[dst_offset] = src_mem[src_offset];                            \\\n}\n\nGEN_COPY_KERNEL(1b, uint8_t)\nGEN_COPY_KERNEL(2b, uint16_t)\nGEN_COPY_KERNEL(4b, uint32_t)\nGEN_COPY_KERNEL(8b, uint64_t)\n\n// End of copy.cl\n\n\n\nFUTHARK_KERNEL_SIZED(big_add_debugzisegmap_group_sizze_12302, 1, 1)\nvoid big_add_debugzisegmap_12352(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t n_10772, int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, int32_t i64_res_11190, int32_t zp_lhs_11191, int32_t zp_lhs_11192, __global unsigned char *as_mem_12913, __global unsigned char *bs_mem_12914, __global unsigned char *mem_12919, __global unsigned char *mem_12922, __global unsigned char *mem_12925, __global unsigned char *mem_12928, __global unsigned char *mem_12931, __global unsigned char *mem_12934, __global unsigned char *mem_12937, __global unsigned char *mem_12940)\n{\n    #define segmap_group_sizze_12341 (big_add_debugzisegmap_group_sizze_12302)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13007;\n    int64_t group_sizze_13010;\n    int32_t wave_sizze_13009;\n    int32_t group_tid_13008;\n    int32_t global_tid_13006;\n    int32_t phys_tid_12352;\n    int64_t global_tid_13011;\n    int64_t slice_13012;\n    int64_t gtid_12351;\n    int64_t remnant_13013;\n    \n    local_tid_13007 = get_local_id(0);\n    group_sizze_13010 = get_local_size(0);\n    wave_sizze_13009 = LOCKSTEP_WIDTH;\n    group_tid_13008 = get_group_id(0);\n    global_tid_13006 = group_tid_13008 * group_sizze_13010 + local_tid_13007;\n    phys_tid_12352 = global_tid_13006;\n    global_tid_13011 = sext_i32_i64(group_tid_13008",
                                    ") * segmap_group_sizze_12341 + sext_i32_i64(local_tid_13007);\n    slice_13012 = n_10772;\n    gtid_12351 = global_tid_13011;\n    remnant_13013 = global_tid_13011 - gtid_12351;\n    if (slt64(gtid_12351, n_10772)) {\n        int32_t i64_res_12354;\n        int64_t i_12355;\n        bool x_12356;\n        bool y_12357;\n        bool bounds_check_12358;\n        bool index_certs_12359;\n        int32_t tmp_12361;\n        int64_t tmp_12362;\n        bool x_12363;\n        bool y_12364;\n        bool bounds_check_12365;\n        bool index_certs_12366;\n        int32_t tmp_12368;\n        int64_t tmp_12369;\n        bool x_12370;\n        bool y_12371;\n        bool bounds_check_12372;\n        bool index_certs_12373;\n        int32_t tmp_12375;\n        int64_t tmp_12376;\n        bool x_12377;\n        bool y_12378;\n        bool bounds_check_12379;\n        bool index_certs_12380;\n        int64_t tmp_12360;\n        int64_t tmp_12367;\n        int64_t tmp_12374;\n        int64_t tmp_12381;\n        int64_t tmp_12382;\n        int64_t tmp_12383;\n        int64_t tmp_12384;\n        int64_t tmp_12385;\n        \n        i64_res_12354 = sext_i64_i32(gtid_12351);\n        i_12355 = sext_i32_i64(i64_res_12354);\n        x_12356 = sle64((int64_t) 0, i_12355);\n        y_12357 = slt64(i_12355, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n        bounds_check_12358 = x_12356 && y_12357;\n        if (!bounds_check_12358) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 0) == -1) {\n                    global_failure_args[0] = (int64_t) i_12355;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n                    ;\n                }\n                return;\n            }\n        }\n        tmp_12361 = add32(i64_res_11190, i64_res_12354);\n        tmp_12362 = sext_i32_i64(tmp_12361);\n        x_12363 = sle64((int64_t) 0, tmp_12362);\n        y_12364 = slt64(tmp_12362, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n        bounds_check_12365 = x_12363 && y_12364;\n", "        if (!bounds_check_12365) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 1) == -1) {\n                    global_failure_args[0] = (int64_t) tmp_12362;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n                    ;\n                }\n                return;\n            }\n        }\n        tmp_12368 = add32(zp_lhs_11191, i64_res_12354);\n        tmp_12369 = sext_i32_i64(tmp_12368);\n        x_12370 = sle64((int64_t) 0, tmp_12369);\n        y_12371 = slt64(tmp_12369, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n        bounds_check_12372 = x_12370 && y_12371;\n        if (!bounds_check_12372) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 2) == -1) {\n                    global_failure_args[0] = (int64_t) tmp_12369;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n                    ;\n                }\n                return;\n            }\n        }\n        tmp_12375 = add32(zp_lhs_11192, i64_res_12354);\n        tmp_12376 = sext_i32_i64(tmp_12375);\n        x_12377 = sle64((int64_t) 0, tmp_12376);\n        y_12378 = slt64(tmp_12376, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n        bounds_check_12379 = x_12377 && y_12378;\n        if (!bounds_check_12379) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 3) == -1) {\n                    global_failure_args[0] = (int64_t) tmp_12376;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n                    ;\n                }\n                return;\n            }\n        }\n        tmp_12360 = ((__global int64_t *) as_mem_12913)[i_12355];\n        tmp_12367 = ((__global int64_t *) as_mem_12913)[tmp_12362];\n        tmp_12374 = ((__global int64_t *) as_mem_12913)[tmp_12369];\n        tmp_12381 = ((__global int64_t *) as_mem_12913)[tmp_12376];\n        tmp_12382 = ((__global int64_t *) bs_mem_12914)[i_12355];\n ", "       tmp_12383 = ((__global int64_t *) bs_mem_12914)[tmp_12362];\n        tmp_12384 = ((__global int64_t *) bs_mem_12914)[tmp_12369];\n        tmp_12385 = ((__global int64_t *) bs_mem_12914)[tmp_12376];\n        ((__global int64_t *) mem_12919)[gtid_12351] = tmp_12360;\n        ((__global int64_t *) mem_12922)[gtid_12351] = tmp_12367;\n        ((__global int64_t *) mem_12925)[gtid_12351] = tmp_12374;\n        ((__global int64_t *) mem_12928)[gtid_12351] = tmp_12381;\n        ((__global int64_t *) mem_12931)[gtid_12351] = tmp_12382;\n        ((__global int64_t *) mem_12934)[gtid_12351] = tmp_12383;\n        ((__global int64_t *) mem_12937)[gtid_12351] = tmp_12384;\n        ((__global int64_t *) mem_12940)[gtid_12351] = tmp_12385;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_12341\n}\nFUTHARK_KERNEL_SIZED(big_add_debugzisegmap_group_sizze_12397, 1, 1)\nvoid big_add_debugzisegmap_12421(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t conc_tmp_11253, __global unsigned char *mem_12944, __global unsigned char *mem_12947, __global unsigned char *mem_12951)\n{\n    #define segmap_group_sizze_12417 (big_add_debugzisegmap_group_sizze_12397)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13192;\n    int64_t group_sizze_13195;\n    int32_t wave_sizze_13194;\n    int32_t group_tid_13193;\n    int32_t global_tid_13191;\n    int32_t phys_tid_12421;\n    int64_t global_tid_13196;\n    int64_t slice_13197;\n    int64_t gtid_12420;\n    int64_t remnant_13198;\n    \n    local_tid_13192 = get_local_id(0);\n    group_sizze_13195 = get_local_size(0);\n    wave_sizze_13194 = LOCKSTEP_WIDTH;\n    group_tid_13193 = get_group_id(0);\n    global_tid_13191 = group_tid_13193 * group_sizze_13195 + local_tid_13192;\n    phys_tid_12421 = global_tid_13191;\n    global_tid_13196 = sext_i32_i64(group_tid_13193) * segmap_group_sizze_12417 + sext_i32_i64(local_tid_13192);\n    slice_13197 = conc_tmp_11253;\n    gtid_12420 = global_tid_",
                                    "13196;\n    remnant_13198 = global_tid_13196 - gtid_12420;\n    if (slt64(gtid_12420, conc_tmp_11253)) {\n        int64_t eta_p_12422;\n        bool cond_12424;\n        bool bool_arg0_12425;\n        int64_t unsign_arg0_12434;\n        int64_t lifted_lambda_res_12435;\n        \n        eta_p_12422 = ((__global int64_t *) mem_12947)[gtid_12420];\n        cond_12424 = slt64((int64_t) 0, gtid_12420);\n        if (cond_12424 == 1) {\n            int64_t za_lhs_12426;\n            bool x_12427;\n            bool y_12428;\n            bool bounds_check_12429;\n            bool index_certs_12430;\n            int32_t za_lhs_12431;\n            int32_t zeze_lhs_12432;\n            bool bool_arg0_t_res_12433;\n            \n            za_lhs_12426 = sub64(gtid_12420, (int64_t) 1);\n            x_12427 = sle64((int64_t) 0, za_lhs_12426);\n            y_12428 = slt64(za_lhs_12426, conc_tmp_11253);\n            bounds_check_12429 = x_12427 && y_12428;\n            if (!bounds_check_12429) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 4) == -1) {\n                        global_failure_args[0] = (int64_t) za_lhs_12426;\n                        global_failure_args[1] = (int64_t) conc_tmp_11253;\n                        ;\n                    }\n                    return;\n                }\n            }\n            za_lhs_12431 = ((__global int32_t *) mem_12944)[za_lhs_12426];\n            zeze_lhs_12432 = 1 & za_lhs_12431;\n            bool_arg0_t_res_12433 = zeze_lhs_12432 == 1;\n            bool_arg0_12425 = bool_arg0_t_res_12433;\n        } else {\n            bool_arg0_12425 = 0;\n        }\n        unsign_arg0_12434 = btoi_bool_i64(bool_arg0_12425);\n        lifted_lambda_res_12435 = add64(eta_p_12422, unsign_arg0_12434);\n        ((__global int64_t *) mem_12951)[gtid_12420] = lifted_lambda_res_12435;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_12417\n}\nFUTHARK_KERNEL_SIZED(big_add_debugzisegmap_group_sizze_12447, 1, 1)\nvoid big_add_debugzisegmap_", "12445(__global int *global_failure, int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, __global unsigned char *exp_res_mem_12915, __global unsigned char *mem_12951, __global unsigned char *mem_12955, __global unsigned char *mem_12958, __global unsigned char *mem_12961, __global unsigned char *mem_12964, __global unsigned char *mem_12967)\n{\n    #define segmap_group_sizze_12448 (big_add_debugzisegmap_group_sizze_12447)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13295;\n    int64_t group_sizze_13298;\n    int32_t wave_sizze_13297;\n    int32_t group_tid_13296;\n    int32_t global_tid_13294;\n    int32_t phys_tid_12445;\n    int64_t global_tid_13299;\n    int64_t slice_13300;\n    int64_t write_i_12444;\n    int64_t remnant_13301;\n    \n    local_tid_13295 = get_local_id(0);\n    group_sizze_13298 = get_local_size(0);\n    wave_sizze_13297 = LOCKSTEP_WIDTH;\n    group_tid_13296 = get_group_id(0);\n    global_tid_13294 = group_tid_13296 * group_sizze_13298 + local_tid_13295;\n    phys_tid_12445 = global_tid_13294;\n    global_tid_13299 = sext_i32_i64(group_tid_13296) * segmap_group_sizze_12448 + sext_i32_i64(local_tid_13295);\n    slice_13300 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n    write_i_12444 = global_tid_13299;\n    remnant_13301 = global_tid_13299 - write_i_12444;\n    if (slt64(write_i_12444, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {\n        int64_t c_10811;\n        int64_t offset_10812;\n        int64_t v_10813;\n        int64_t v_10814;\n        bool is_this_one_10816;\n        int64_t this_offset_10817;\n        int64_t total_res_10818;\n        \n        c_10811 = ((__global int64_t *) mem_12958)[write_i_12444];\n        offset_10812 = ((__global int64_t *) mem_12955)[write_i_12444];\n        v_10813 = ((__global int64_t *) exp_res_mem_12915)[write_i_12444];\n        v_10814 = ((__global int64_t *) mem_12951)[write_i_12444];\n        is_this_one_10816 = c_10811 == (int64_t) 0;\n        this_offset_10817 = (int64_t) -1 + offset_10812;\n        if (is_this_one_10816 == ", "1) {\n            total_res_10818 = this_offset_10817;\n        } else {\n            total_res_10818 = (int64_t) -1;\n        }\n        if (sle64((int64_t) 0, total_res_10818) && slt64(total_res_10818, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {\n            ((__global int64_t *) mem_12961)[total_res_10818] = v_10813;\n        }\n        if (sle64((int64_t) 0, total_res_10818) && slt64(total_res_10818, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {\n            ((__global int64_t *) mem_12964)[total_res_10818] = v_10814;\n        }\n        if (sle64((int64_t) 0, total_res_10818) && slt64(total_res_10818, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {\n            ((__global int64_t *) mem_12967)[total_res_10818] = write_i_12444;\n        }\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_12448\n}\nFUTHARK_KERNEL_SIZED(big_add_debugzisegscan_group_sizze_12387, 1, 1)\nvoid big_add_debugzisegscan_12393(__global int *global_failure, int64_t local_mem_13072_backing_offset_0, int64_t n_10772, int64_t conc_tmp_11249, int64_t conc_tmp_11251, int64_t conc_tmp_11253, int64_t num_groups_13015, __global unsigned char *mem_12919, __global unsigned char *mem_12922, __global unsigned char *mem_12925, __global unsigned char *mem_12928, __global unsigned char *mem_12931, __global unsigned char *mem_12934, __global unsigned char *mem_12937, __global unsigned char *mem_12940, __global unsigned char *mem_12944, __global unsigned char *mem_12947, __global unsigned char *id_counter_mem_13017, __global unsigned char *status_flags_mem_13039, __global unsigned char *aggregates_mem_13041, __global unsigned char *incprefixes_mem_13043)\n{\n    #define segscan_group_sizze_12388 (big_add_debugzisegscan_group_sizze_12387)\n    \n    volatile __local unsigned char *local_mem_13072_backing_0 = &local_mem[local_mem_13072_backing_offset_0];\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13066;\n    int64_t group_sizze_13069;\n    int32_t wave_sizze_13068;\n    int32_t group_tid_13067;\n    in",
                                    "t32_t global_tid_13065;\n    int32_t phys_tid_12393;\n    int64_t byte_offsets_13070;\n    int64_t warp_byte_offset_13071;\n    __local unsigned char *local_mem_13072;\n    int64_t trans_arr_len_13073;\n    int32_t dynamic_id_13079;\n    int64_t blockOff_13080;\n    int64_t sgm_idx_13081;\n    int32_t boundary_13082;\n    int32_t segsizze_compact_13083;\n    int32_t private_mem_13084[(int64_t) 23];\n    int32_t acc_13108;\n    int32_t prefix_13124;\n    bool block_new_sgm_13125;\n    \n    local_tid_13066 = get_local_id(0);\n    group_sizze_13069 = get_local_size(0);\n    wave_sizze_13068 = LOCKSTEP_WIDTH;\n    group_tid_13067 = get_group_id(0);\n    global_tid_13065 = group_tid_13067 * group_sizze_13069 + local_tid_13066;\n    phys_tid_12393 = global_tid_13065;\n    byte_offsets_13070 = segscan_group_sizze_12388 * (int64_t) 4;\n    warp_byte_offset_13071 = (int64_t) 160;\n    // Allocate reused shared memeory\n    { }\n    local_mem_13072 = (__local unsigned char *) local_mem_13072_backing_0;\n    trans_arr_len_13073 = (int64_t) 23 * segscan_group_sizze_12388;\n    if (local_tid_13066 == 0) {\n        dynamic_id_13079 = atomic_add_i32_global(&((volatile __global int *) id_counter_mem_13017)[(int64_t) 0], (int) 1);\n        ((__local int32_t *) local_mem_13072)[(int64_t) 0] = dynamic_id_13079;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dynamic_id_13079 = ((__local int32_t *) local_mem_13072)[(int64_t) 0];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    blockOff_13080 = sext_i32_i64(dynamic_id_13079) * (int64_t) 23 * segscan_group_sizze_12388;\n    sgm_idx_13081 = smod64(blockOff_13080, conc_tmp_11253);\n    boundary_13082 = sext_i64_i32(smin64((int64_t) 23 * segscan_group_sizze_12388, conc_tmp_11253 - sgm_idx_13081));\n    segsizze_compact_13083 = sext_i64_i32(smin64((int64_t) 23 * segscan_group_sizze_12388, conc_tmp_11253));\n    // Load and map\n    {\n        for (int64_t i_13086 = 0; i_13086 < (int64_t) 23; i_13086++) {\n            int64_t phys_tid_13087 = blockOff_13080 + sext_i32_i64(local_tid_13066) + i", "_13086 * segscan_group_sizze_12388;\n            int64_t slice_13088 = conc_tmp_11253;\n            int64_t gtid_12392 = phys_tid_13087;\n            int64_t remnant_13089 = phys_tid_13087 - gtid_12392;\n            \n            if (slt64(phys_tid_13087, conc_tmp_11253)) {\n                bool index_concat_cmp_12888 = sle64(conc_tmp_11251, gtid_12392);\n                int64_t index_concat_branch_12900;\n                \n                if (index_concat_cmp_12888 == 1) {\n                    int64_t index_concat_i_12889 = sub64(gtid_12392, conc_tmp_11251);\n                    int64_t index_concat_12890 = ((__global int64_t *) mem_12928)[index_concat_i_12889];\n                    \n                    index_concat_branch_12900 = index_concat_12890;\n                } else {\n                    bool index_concat_cmp_12891 = sle64(conc_tmp_11249, gtid_12392);\n                    int64_t index_concat_branch_12899;\n                    \n                    if (index_concat_cmp_12891 == 1) {\n                        int64_t index_concat_i_12892 = sub64(gtid_12392, conc_tmp_11249);\n                        int64_t index_concat_12893 = ((__global int64_t *) mem_12925)[index_concat_i_12892];\n                        \n                        index_concat_branch_12899 = index_concat_12893;\n                    } else {\n                        bool index_concat_cmp_12894 = sle64(n_10772, gtid_12392);\n                        int64_t index_concat_branch_12898;\n                        \n                        if (index_concat_cmp_12894 == 1) {\n                            int64_t index_concat_i_12895 = sub64(gtid_12392, n_10772);\n                            int64_t index_concat_12896 = ((__global int64_t *) mem_12922)[index_concat_i_12895];\n                            \n                            index_concat_branch_12898 = index_concat_12896;\n                        } else {\n                            int64_t index_concat_12897 = ((__global int64_t *) mem_12919)[gtid_12392];\n                  ", "          \n                            index_concat_branch_12898 = index_concat_12897;\n                        }\n                        index_concat_branch_12899 = index_concat_branch_12898;\n                    }\n                    index_concat_branch_12900 = index_concat_branch_12899;\n                }\n                \n                int64_t index_concat_branch_12884;\n                \n                if (index_concat_cmp_12888 == 1) {\n                    int64_t index_concat_i_12873 = sub64(gtid_12392, conc_tmp_11251);\n                    int64_t index_concat_12874 = ((__global int64_t *) mem_12940)[index_concat_i_12873];\n                    \n                    index_concat_branch_12884 = index_concat_12874;\n                } else {\n                    bool index_concat_cmp_12875 = sle64(conc_tmp_11249, gtid_12392);\n                    int64_t index_concat_branch_12883;\n                    \n                    if (index_concat_cmp_12875 == 1) {\n                        int64_t index_concat_i_12876 = sub64(gtid_12392, conc_tmp_11249);\n                        int64_t index_concat_12877 = ((__global int64_t *) mem_12937)[index_concat_i_12876];\n                        \n                        index_concat_branch_12883 = index_concat_12877;\n                    } else {\n                        bool index_concat_cmp_12878 = sle64(n_10772, gtid_12392);\n                        int64_t index_concat_branch_12882;\n                        \n                        if (index_concat_cmp_12878 == 1) {\n                            int64_t index_concat_i_12879 = sub64(gtid_12392, n_10772);\n                            int64_t index_concat_12880 = ((__global int64_t *) mem_12934)[index_concat_i_12879];\n                            \n                            index_concat_branch_12882 = index_concat_12880;\n                        } else {\n                            int64_t index_concat_12881 = ((__global int64_t *) mem_12931)[gtid_12392];\n                            \n                ",
                                    "            index_concat_branch_12882 = index_concat_12881;\n                        }\n                        index_concat_branch_12883 = index_concat_branch_12882;\n                    }\n                    index_concat_branch_12884 = index_concat_branch_12883;\n                }\n                \n                int64_t s_11565 = add64(index_concat_branch_12884, index_concat_branch_12900);\n                bool bool_arg0_11566 = ult64(s_11565, index_concat_branch_12900);\n                int32_t unsign_arg0_11567 = btoi_bool_i32(bool_arg0_11566);\n                bool bool_arg0_11568 = s_11565 == (int64_t) -1;\n                int32_t unsign_arg0_11569 = btoi_bool_i32(bool_arg0_11568);\n                int32_t zb_rhs_11570 = shl32(unsign_arg0_11569, 1);\n                int32_t c_11571 = unsign_arg0_11567 | zb_rhs_11570;\n                \n                ((__global int64_t *) mem_12947)[gtid_12392] = s_11565;\n                private_mem_13084[i_13086] = c_11571;\n            } else {\n                private_mem_13084[i_13086] = 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Transpose scan inputs\n    {\n        for (int64_t i_13090 = 0; i_13090 < (int64_t) 23; i_13090++) {\n            int64_t sharedIdx_13091 = sext_i32_i64(local_tid_13066) + i_13090 * segscan_group_sizze_12388;\n            int32_t tmp_13092 = private_mem_13084[i_13090];\n            \n            ((__local int32_t *) local_mem_13072)[sharedIdx_13091] = tmp_13092;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_13093 = 0; i_13093 < 23; i_13093++) {\n            int32_t sharedIdx_13094 = local_tid_13066 * 23 + i_13093;\n            int32_t tmp_13095 = ((__local int32_t *) local_mem_13072)[sext_i32_i64(sharedIdx_13094)];\n            \n            private_mem_13084[sext_i32_i64(i_13093)] = tmp_13095;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // Per thread scan\n    {\n        int32_t gidx_13096 = local_tid_13066 * 23 + 1;\n        \n        for (int64_t i_13", "097 = 0; i_13097 < (int64_t) 22; i_13097++) {\n            int32_t eta_p_11276;\n            int32_t eta_p_11277;\n            \n            eta_p_11276 = private_mem_13084[i_13097];\n            eta_p_11277 = private_mem_13084[i_13097 + (int64_t) 1];\n            \n            int32_t za_lhs_11278 = eta_p_11276 & eta_p_11277;\n            int32_t zb_lhs_11279 = 2 & za_lhs_11278;\n            int32_t za_rhs_11280 = lshr32(eta_p_11277, 1);\n            int32_t zb_lhs_11281 = eta_p_11276 & za_rhs_11280;\n            int32_t za_lhs_11282 = eta_p_11277 | zb_lhs_11281;\n            int32_t zb_rhs_11283 = 1 & za_lhs_11282;\n            int32_t carry_prop_res_11284 = zb_lhs_11279 | zb_rhs_11283;\n            \n            private_mem_13084[i_13097 + (int64_t) 1] = carry_prop_res_11284;\n        }\n    }\n    // Publish results in shared memory\n    {\n        int32_t tmp_13098 = private_mem_13084[(int64_t) 22];\n        \n        ((__local int32_t *) local_mem_13072)[sext_i32_i64(local_tid_13066)] = tmp_13098;\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // Scan results (with warp scan)\n    {\n        int32_t eta_p_13099;\n        int32_t eta_p_13100;\n        int32_t eta_p_13109;\n        int32_t eta_p_13110;\n        bool ltid_in_bounds_13118 = slt64(sext_i32_i64(local_tid_13066), segscan_group_sizze_12388);\n        int32_t skip_threads_13119;\n        \n        // read input for in-block scan\n        {\n            if (ltid_in_bounds_13118) {\n                eta_p_13100 = ((volatile __local int32_t *) local_mem_13072)[sext_i32_i64(local_tid_13066)];\n                if ((local_tid_13066 - squot32(local_tid_13066, 32) * 32) == 0) {\n                    eta_p_13099 = eta_p_13100;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_13119 = 1;\n            while (slt32(skip_threads_13119, 32)) {\n                bool thread_active_13120 = sle32(skip_threads_13119, local_tid_13066 - squot32(local_tid_13066, 32) * 32) && ltid_", "in_bounds_13118;\n                \n                if (thread_active_13120) {\n                    // read operands\n                    {\n                        eta_p_13099 = ((volatile __local int32_t *) local_mem_13072)[sext_i32_i64(local_tid_13066) - sext_i32_i64(skip_threads_13119)];\n                    }\n                }\n                // perform operation\n                {\n                    if (thread_active_13120) {\n                        int32_t za_lhs_13101 = eta_p_13099 & eta_p_13100;\n                        int32_t zb_lhs_13102 = 2 & za_lhs_13101;\n                        int32_t za_rhs_13103 = lshr32(eta_p_13100, 1);\n                        int32_t zb_lhs_13104 = eta_p_13099 & za_rhs_13103;\n                        int32_t za_lhs_13105 = eta_p_13100 | zb_lhs_13104;\n                        int32_t zb_rhs_13106 = 1 & za_lhs_13105;\n                        int32_t carry_prop_res_13107 = zb_lhs_13102 | zb_rhs_13106;\n                        \n                        eta_p_13099 = carry_prop_res_13107;\n                    }\n                }\n                if (sle32(wave_sizze_13068, skip_threads_13119)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_13120) {\n                    // write result\n                    {\n                        ((volatile __local int32_t *) local_mem_13072)[sext_i32_i64(local_tid_13066)] = eta_p_13099;\n                        eta_p_13100 = eta_p_13099;\n                    }\n                }\n                if (sle32(wave_sizze_13068, skip_threads_13119)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_13119 *= 2;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // last thread of block 'i' writes its result to offset 'i'\n        {\n            if ((local_tid_13066 - squot32(local_tid_13066, 32) * 32) == 31 && ltid_in_bounds_13118) {\n                ((volatile __local int32_t *) local_mem_13072)[sext_i32_i",
                                    "64(squot32(local_tid_13066, 32))] = eta_p_13099;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n        {\n            int32_t skip_threads_13121;\n            \n            // read input for in-block scan\n            {\n                if (squot32(local_tid_13066, 32) == 0 && ltid_in_bounds_13118) {\n                    eta_p_13110 = ((volatile __local int32_t *) local_mem_13072)[sext_i32_i64(local_tid_13066)];\n                    if ((local_tid_13066 - squot32(local_tid_13066, 32) * 32) == 0) {\n                        eta_p_13109 = eta_p_13110;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_13121 = 1;\n                while (slt32(skip_threads_13121, 32)) {\n                    bool thread_active_13122 = sle32(skip_threads_13121, local_tid_13066 - squot32(local_tid_13066, 32) * 32) && (squot32(local_tid_13066, 32) == 0 && ltid_in_bounds_13118);\n                    \n                    if (thread_active_13122) {\n                        // read operands\n                        {\n                            eta_p_13109 = ((volatile __local int32_t *) local_mem_13072)[sext_i32_i64(local_tid_13066) - sext_i32_i64(skip_threads_13121)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_13122) {\n                            int32_t za_lhs_13111 = eta_p_13109 & eta_p_13110;\n                            int32_t zb_lhs_13112 = 2 & za_lhs_13111;\n                            int32_t za_rhs_13113 = lshr32(eta_p_13110, 1);\n                            int32_t zb_lhs_13114 = eta_p_13109 & za_rhs_13113;\n                            int32_t za_lhs_13115 = eta_p_13110 | zb_lhs_13114;\n                            int32_t zb_rhs_13116 = 1 & za_lhs_13115;\n                            int", "32_t carry_prop_res_13117 = zb_lhs_13112 | zb_rhs_13116;\n                            \n                            eta_p_13109 = carry_prop_res_13117;\n                        }\n                    }\n                    if (sle32(wave_sizze_13068, skip_threads_13121)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_13122) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_13072)[sext_i32_i64(local_tid_13066)] = eta_p_13109;\n                            eta_p_13110 = eta_p_13109;\n                        }\n                    }\n                    if (sle32(wave_sizze_13068, skip_threads_13121)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_13121 *= 2;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        \n        bool no_carry_in_13123 = squot32(local_tid_13066, 32) == 0 || !ltid_in_bounds_13118;\n        \n        // carry-in for every block except the first\n        {\n            // read operands\n            {\n                if (!no_carry_in_13123) {\n                    eta_p_13100 = eta_p_13099;\n                    eta_p_13099 = ((__local int32_t *) local_mem_13072)[sext_i32_i64(squot32(local_tid_13066, 32)) - (int64_t) 1];\n                }\n            }\n            // perform operation\n            {\n                if (!no_carry_in_13123) {\n                    int32_t za_lhs_13101 = eta_p_13099 & eta_p_13100;\n                    int32_t zb_lhs_13102 = 2 & za_lhs_13101;\n                    int32_t za_rhs_13103 = lshr32(eta_p_13100, 1);\n                    int32_t zb_lhs_13104 = eta_p_13099 & za_rhs_13103;\n                    int32_t za_lhs_13105 = eta_p_13100 | zb_lhs_13104;\n                    int32_t zb_rhs_13106 = 1 & za_lhs_13105;\n                    int32_t carry_prop_res_13107 = zb_lhs_13102 | zb_rhs_13106;\n       ", "             \n                    eta_p_13099 = carry_prop_res_13107;\n                }\n            }\n            // write final result\n            {\n                if (!no_carry_in_13123) {\n                    ((__local int32_t *) local_mem_13072)[sext_i32_i64(local_tid_13066)] = eta_p_13099;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // restore correct values for first block\n        {\n            if (squot32(local_tid_13066, 32) == 0 && ltid_in_bounds_13118) {\n                ((__local int32_t *) local_mem_13072)[sext_i32_i64(local_tid_13066)] = eta_p_13100;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_tid_13066 == 0) {\n            acc_13108 = ((__local int32_t *) local_mem_13072)[segscan_group_sizze_12388 - (int64_t) 1];\n        } else {\n            acc_13108 = ((__local int32_t *) local_mem_13072)[sext_i32_i64(local_tid_13066) - (int64_t) 1];\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    prefix_13124 = 2;\n    block_new_sgm_13125 = sgm_idx_13081 == (int64_t) 0;\n    // Perform lookback\n    {\n        if (block_new_sgm_13125 && local_tid_13066 == 0) {\n            ((volatile __global int32_t *) incprefixes_mem_13043)[dynamic_id_13079] = acc_13108;\n            mem_fence_global();\n            ((volatile __global int8_t *) status_flags_mem_13039)[dynamic_id_13079] = (int8_t) 2;\n            acc_13108 = 2;\n        }\n        if (!block_new_sgm_13125 && slt32(local_tid_13066, wave_sizze_13068)) {\n            if (local_tid_13066 == 0) {\n                ((volatile __global int32_t *) aggregates_mem_13041)[dynamic_id_13079] = acc_13108;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_13039)[dynamic_id_13079] = (int8_t) 1;\n                \n                int8_t tmp_13126 = ((volatile __global int8_t *) status_flags_mem_13039)[dynamic_id_13079 - (int64_t) 1];\n                \n                ((volat",
                                    "ile __local int8_t *) local_mem_13072)[(int64_t) 0] = tmp_13126;\n            }\n            mem_fence_local();\n            \n            int8_t status_13127 = ((__local int8_t *) local_mem_13072)[(int64_t) 0];\n            \n            if (status_13127 == (int8_t) 2) {\n                if (local_tid_13066 == 0) {\n                    prefix_13124 = ((volatile __global int32_t *) incprefixes_mem_13043)[dynamic_id_13079 - (int64_t) 1];\n                }\n            } else {\n                int32_t readOffset_13128 = dynamic_id_13079 - sext_i32_i64(wave_sizze_13068);\n                \n                while (slt32(wave_sizze_13068 * -1, readOffset_13128)) {\n                    int32_t read_i_13129 = readOffset_13128 + local_tid_13066;\n                    int32_t aggr_13130 = 2;\n                    int8_t flag_13131 = (int8_t) 0;\n                    \n                    if (sle32(0, read_i_13129)) {\n                        flag_13131 = ((volatile __global int8_t *) status_flags_mem_13039)[sext_i32_i64(read_i_13129)];\n                        if (flag_13131 == (int8_t) 2) {\n                            aggr_13130 = ((volatile __global int32_t *) incprefixes_mem_13043)[sext_i32_i64(read_i_13129)];\n                        } else if (flag_13131 == (int8_t) 1) {\n                            aggr_13130 = ((volatile __global int32_t *) aggregates_mem_13041)[sext_i32_i64(read_i_13129)];\n                        }\n                    }\n                    ((__local int32_t *) local_mem_13072)[(int64_t) 8 + sext_i32_i64(local_tid_13066)] = aggr_13130;\n                    ((__local int8_t *) local_mem_13072)[sext_i32_i64(local_tid_13066)] = flag_13131;\n                    flag_13131 = ((__local int8_t *) local_mem_13072)[sext_i32_i64(wave_sizze_13068) - (int64_t) 1];\n                    if (slt8(flag_13131, (int8_t) 2)) {\n                        int8_t flg_x_13141;\n                        int8_t flg_y_13142;\n                        int32_t eta_p_13132;\n                        int32_t eta_p_1", "3133;\n                        int32_t skip_threads_13143;\n                        \n                        // read input for in-block scan\n                        {\n                            flg_y_13142 = ((volatile __local int8_t *) local_mem_13072)[sext_i32_i64(local_tid_13066)];\n                            eta_p_13133 = ((volatile __local int32_t *) local_mem_13072)[(int64_t) 8 + sext_i32_i64(local_tid_13066)];\n                            if ((local_tid_13066 - squot32(local_tid_13066, 32) * 32) == 0) {\n                                eta_p_13132 = eta_p_13133;\n                                flg_x_13141 = flg_y_13142;\n                            }\n                        }\n                        // in-block scan (hopefully no barriers needed)\n                        {\n                            skip_threads_13143 = 1;\n                            while (slt32(skip_threads_13143, 32)) {\n                                if (sle32(skip_threads_13143, local_tid_13066 - squot32(local_tid_13066, 32) * 32)) {\n                                    // read operands\n                                    {\n                                        flg_x_13141 = ((volatile __local int8_t *) local_mem_13072)[sext_i32_i64(local_tid_13066) - sext_i32_i64(skip_threads_13143)];\n                                        eta_p_13132 = ((volatile __local int32_t *) local_mem_13072)[(int64_t) 8 + (sext_i32_i64(local_tid_13066) - sext_i32_i64(skip_threads_13143))];\n                                    }\n                                    // perform operation\n                                    {\n                                        if (flg_y_13142 == (int8_t) 2 || flg_y_13142 == (int8_t) 0) {\n                                            flg_x_13141 = flg_y_13142;\n                                            eta_p_13132 = eta_p_13133;\n                                        } else {\n                                            int32_t za_lhs_13134 = eta_p_13132 & eta_p_13133;\n              ", "                              int32_t zb_lhs_13135 = 2 & za_lhs_13134;\n                                            int32_t za_rhs_13136 = lshr32(eta_p_13133, 1);\n                                            int32_t zb_lhs_13137 = eta_p_13132 & za_rhs_13136;\n                                            int32_t za_lhs_13138 = eta_p_13133 | zb_lhs_13137;\n                                            int32_t zb_rhs_13139 = 1 & za_lhs_13138;\n                                            int32_t carry_prop_res_13140 = zb_lhs_13135 | zb_rhs_13139;\n                                            \n                                            eta_p_13132 = carry_prop_res_13140;\n                                        }\n                                    }\n                                    // write result\n                                    {\n                                        ((volatile __local int8_t *) local_mem_13072)[sext_i32_i64(local_tid_13066)] = flg_x_13141;\n                                        flg_y_13142 = flg_x_13141;\n                                        ((volatile __local int32_t *) local_mem_13072)[(int64_t) 8 + sext_i32_i64(local_tid_13066)] = eta_p_13132;\n                                        eta_p_13133 = eta_p_13132;\n                                    }\n                                }\n                                skip_threads_13143 *= 2;\n                            }\n                        }\n                    }\n                    flag_13131 = ((__local int8_t *) local_mem_13072)[sext_i32_i64(wave_sizze_13068) - (int64_t) 1];\n                    aggr_13130 = ((__local int32_t *) local_mem_13072)[(int64_t) 8 + (sext_i32_i64(wave_sizze_13068) - (int64_t) 1)];\n                    if (flag_13131 == (int8_t) 2) {\n                        readOffset_13128 = wave_sizze_13068 * -1;\n                    } else if (flag_13131 == (int8_t) 1) {\n                        readOffset_13128 -= wave_sizze_13068;\n                    }\n                    if (slt8((in",
                                    "t8_t) 0, flag_13131)) {\n                        int32_t eta_p_13144 = aggr_13130;\n                        int32_t eta_p_13145 = prefix_13124;\n                        int32_t za_lhs_13146 = eta_p_13144 & eta_p_13145;\n                        int32_t zb_lhs_13147 = 2 & za_lhs_13146;\n                        int32_t za_rhs_13148 = lshr32(eta_p_13145, 1);\n                        int32_t zb_lhs_13149 = eta_p_13144 & za_rhs_13148;\n                        int32_t za_lhs_13150 = eta_p_13145 | zb_lhs_13149;\n                        int32_t zb_rhs_13151 = 1 & za_lhs_13150;\n                        int32_t carry_prop_res_13152 = zb_lhs_13147 | zb_rhs_13151;\n                        \n                        prefix_13124 = carry_prop_res_13152;\n                    }\n                    mem_fence_local();\n                }\n            }\n            if (local_tid_13066 == 0) {\n                if (boundary_13082 == sext_i64_i32(segscan_group_sizze_12388 * (int64_t) 23)) {\n                    int32_t eta_p_13153 = prefix_13124;\n                    int32_t eta_p_13154 = acc_13108;\n                    int32_t za_lhs_13155 = eta_p_13153 & eta_p_13154;\n                    int32_t zb_lhs_13156 = 2 & za_lhs_13155;\n                    int32_t za_rhs_13157 = lshr32(eta_p_13154, 1);\n                    int32_t zb_lhs_13158 = eta_p_13153 & za_rhs_13157;\n                    int32_t za_lhs_13159 = eta_p_13154 | zb_lhs_13158;\n                    int32_t zb_rhs_13160 = 1 & za_lhs_13159;\n                    int32_t carry_prop_res_13161 = zb_lhs_13156 | zb_rhs_13160;\n                    \n                    ((volatile __global int32_t *) incprefixes_mem_13043)[dynamic_id_13079] = carry_prop_res_13161;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_13039)[dynamic_id_13079] = (int8_t) 2;\n                }\n                ((__local int32_t *) local_mem_13072)[(int64_t) 8] = prefix_13124;\n                acc_13108 = 2;\n            }\n        }\n     ", "   if (!(dynamic_id_13079 == (int64_t) 0)) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            prefix_13124 = ((__local int32_t *) local_mem_13072)[(int64_t) 8];\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    // Distribute results\n    {\n        int32_t eta_p_13162;\n        int32_t eta_p_13163;\n        int32_t eta_p_13171 = prefix_13124;\n        int32_t eta_p_13172 = acc_13108;\n        \n        if (slt32(local_tid_13066 * 23, boundary_13082) && !block_new_sgm_13125) {\n            int32_t za_lhs_13173 = eta_p_13171 & eta_p_13172;\n            int32_t zb_lhs_13174 = 2 & za_lhs_13173;\n            int32_t za_rhs_13175 = lshr32(eta_p_13172, 1);\n            int32_t zb_lhs_13176 = eta_p_13171 & za_rhs_13175;\n            int32_t za_lhs_13177 = eta_p_13172 | zb_lhs_13176;\n            int32_t zb_rhs_13178 = 1 & za_lhs_13177;\n            int32_t carry_prop_res_13179 = zb_lhs_13174 | zb_rhs_13178;\n            \n            eta_p_13162 = carry_prop_res_13179;\n        } else {\n            eta_p_13162 = acc_13108;\n        }\n        \n        int32_t stopping_point_13180 = segsizze_compact_13083 - srem32(local_tid_13066 * 23 - 1 + segsizze_compact_13083 - boundary_13082, segsizze_compact_13083);\n        \n        for (int64_t i_13181 = 0; i_13181 < (int64_t) 23; i_13181++) {\n            if (slt32(sext_i64_i32(i_13181), stopping_point_13180 - 1)) {\n                eta_p_13163 = private_mem_13084[i_13181];\n                \n                int32_t za_lhs_13164 = eta_p_13162 & eta_p_13163;\n                int32_t zb_lhs_13165 = 2 & za_lhs_13164;\n                int32_t za_rhs_13166 = lshr32(eta_p_13163, 1);\n                int32_t zb_lhs_13167 = eta_p_13162 & za_rhs_13166;\n                int32_t za_lhs_13168 = eta_p_13163 | zb_lhs_13167;\n                int32_t zb_rhs_13169 = 1 & za_lhs_13168;\n                int32_t carry_prop_res_13170 = zb_lhs_13165 | zb_rhs_13169;\n                \n                private_mem_13084[i_13181] = carry_prop_res_13170;\n            }\n      ", "  }\n    }\n    // Transpose scan output and Write it to global memory in coalesced fashion\n    {\n        for (int64_t i_13182 = 0; i_13182 < (int64_t) 23; i_13182++) {\n            int64_t sharedIdx_13183 = sext_i32_i64(local_tid_13066 * 23) + i_13182;\n            int32_t tmp_13184 = private_mem_13084[i_13182];\n            \n            ((__local int32_t *) local_mem_13072)[sharedIdx_13183] = tmp_13184;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int64_t i_13185 = 0; i_13185 < (int64_t) 23; i_13185++) {\n            int64_t flat_idx_13186 = blockOff_13080 + segscan_group_sizze_12388 * i_13185 + sext_i32_i64(local_tid_13066);\n            int64_t slice_13187 = conc_tmp_11253;\n            int64_t gtid_12392 = flat_idx_13186;\n            int64_t remnant_13188 = flat_idx_13186 - gtid_12392;\n            \n            if (slt64(flat_idx_13186, conc_tmp_11253)) {\n                int32_t tmp_13189 = ((__local int32_t *) local_mem_13072)[flat_idx_13186 - blockOff_13080];\n                \n                ((__global int32_t *) mem_12944)[gtid_12392] = tmp_13189;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // If this is the last block, reset the dynamicId\n    {\n        if (dynamic_id_13079 == num_groups_13015 - (int64_t) 1) {\n            ((__global int32_t *) id_counter_mem_13017)[(int64_t) 0] = 0;\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_group_sizze_12388\n}\nFUTHARK_KERNEL_SIZED(big_add_debugzisegscan_group_sizze_12437, 1, 1)\nvoid big_add_debugzisegscan_12443(__global int *global_failure, int64_t local_mem_13217_backing_offset_0, int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, int64_t num_groups_13200, __global unsigned char *exp_res_mem_12915, __global unsigned char *mem_12951, __global unsigned char *mem_12955, __global unsigned char *mem_12958, __global unsigned char *id_counter_mem_13202, __global unsigned char *status_flags_mem_13204, __global unsigned char *aggregates_mem_13206, __global unsigned char *incprefixes_",
                                    "mem_13208)\n{\n    #define segscan_group_sizze_12438 (big_add_debugzisegscan_group_sizze_12437)\n    \n    volatile __local unsigned char *local_mem_13217_backing_0 = &local_mem[local_mem_13217_backing_offset_0];\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13211;\n    int64_t group_sizze_13214;\n    int32_t wave_sizze_13213;\n    int32_t group_tid_13212;\n    int32_t global_tid_13210;\n    int32_t phys_tid_12443;\n    int64_t byte_offsets_13215;\n    int64_t warp_byte_offset_13216;\n    __local unsigned char *local_mem_13217;\n    int64_t trans_arr_len_13218;\n    int32_t dynamic_id_13224;\n    int64_t blockOff_13225;\n    int64_t sgm_idx_13226;\n    int32_t boundary_13227;\n    int32_t segsizze_compact_13228;\n    int64_t private_mem_13229[(int64_t) 11];\n    int64_t acc_13247;\n    int64_t prefix_13257;\n    bool block_new_sgm_13258;\n    \n    local_tid_13211 = get_local_id(0);\n    group_sizze_13214 = get_local_size(0);\n    wave_sizze_13213 = LOCKSTEP_WIDTH;\n    group_tid_13212 = get_group_id(0);\n    global_tid_13210 = group_tid_13212 * group_sizze_13214 + local_tid_13211;\n    phys_tid_12443 = global_tid_13210;\n    byte_offsets_13215 = segscan_group_sizze_12438 * (int64_t) 8;\n    warp_byte_offset_13216 = (int64_t) 288;\n    // Allocate reused shared memeory\n    { }\n    local_mem_13217 = (__local unsigned char *) local_mem_13217_backing_0;\n    trans_arr_len_13218 = (int64_t) 11 * segscan_group_sizze_12438;\n    if (local_tid_13211 == 0) {\n        dynamic_id_13224 = atomic_add_i32_global(&((volatile __global int *) id_counter_mem_13202)[(int64_t) 0], (int) 1);\n        ((__local int32_t *) local_mem_13217)[(int64_t) 0] = dynamic_id_13224;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dynamic_id_13224 = ((__local int32_t *) local_mem_13217)[(int64_t) 0];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    blockOff_13225 = sext_i32_i64(dynamic_id_13224) * (int64_t) 11 * segscan_group_sizze_12438;\n    sgm_idx_13226 = smod64(blockOff_13225, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);", "\n    boundary_13227 = sext_i64_i32(smin64((int64_t) 11 * segscan_group_sizze_12438, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773 - sgm_idx_13226));\n    segsizze_compact_13228 = sext_i64_i32(smin64((int64_t) 11 * segscan_group_sizze_12438, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773));\n    // Load and map\n    {\n        for (int64_t i_13231 = 0; i_13231 < (int64_t) 11; i_13231++) {\n            int64_t phys_tid_13232 = blockOff_13225 + sext_i32_i64(local_tid_13211) + i_13231 * segscan_group_sizze_12438;\n            int64_t slice_13233 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n            int64_t gtid_12442 = phys_tid_13232;\n            int64_t remnant_13234 = phys_tid_13232 - gtid_12442;\n            \n            if (slt64(phys_tid_13232, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {\n                int64_t x_11551 = ((__global int64_t *) exp_res_mem_12915)[gtid_12442];\n                int64_t x_11552 = ((__global int64_t *) mem_12951)[gtid_12442];\n                bool lifted_lambda_res_11553 = x_11552 == x_11551;\n                int64_t defunc_0_partition_arg1_res_11554 = btoi_bool_i64(lifted_lambda_res_11553);\n                bool is_i_11555 = defunc_0_partition_arg1_res_11554 == (int64_t) 0;\n                bool cond_neg_11556 = !is_i_11555;\n                int64_t part_res_11557 = btoi_bool_i64(cond_neg_11556);\n                int64_t part_res_11558 = btoi_bool_i64(is_i_11555);\n                \n                ((__global int64_t *) mem_12958)[gtid_12442] = part_res_11557;\n                private_mem_13229[i_13231] = part_res_11558;\n            } else {\n                private_mem_13229[i_13231] = (int64_t) 0;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Transpose scan inputs\n    {\n        for (int64_t i_13235 = 0; i_13235 < (int64_t) 11; i_13235++) {\n            int64_t sharedIdx_13236 = sext_i32_i64(local_tid_13211) + i_13235 * segscan_group_sizze_12438;\n            int64_t tmp_13237 = private_mem_13229[i_13235];\n            \n            ((__local int64_t *) local_", "mem_13217)[sharedIdx_13236] = tmp_13237;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_13238 = 0; i_13238 < 11; i_13238++) {\n            int32_t sharedIdx_13239 = local_tid_13211 * 11 + i_13238;\n            int64_t tmp_13240 = ((__local int64_t *) local_mem_13217)[sext_i32_i64(sharedIdx_13239)];\n            \n            private_mem_13229[sext_i32_i64(i_13238)] = tmp_13240;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // Per thread scan\n    {\n        int32_t gidx_13241 = local_tid_13211 * 11 + 1;\n        \n        for (int64_t i_13242 = 0; i_13242 < (int64_t) 10; i_13242++) {\n            int64_t x_10795;\n            int64_t y_10796;\n            \n            x_10795 = private_mem_13229[i_13242];\n            y_10796 = private_mem_13229[i_13242 + (int64_t) 1];\n            \n            int64_t zz_10797 = x_10795 + y_10796;\n            \n            private_mem_13229[i_13242 + (int64_t) 1] = zz_10797;\n        }\n    }\n    // Publish results in shared memory\n    {\n        int64_t tmp_13243 = private_mem_13229[(int64_t) 10];\n        \n        ((__local int64_t *) local_mem_13217)[sext_i32_i64(local_tid_13211)] = tmp_13243;\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // Scan results (with warp scan)\n    {\n        int64_t x_13244;\n        int64_t y_13245;\n        int64_t x_13248;\n        int64_t y_13249;\n        bool ltid_in_bounds_13251 = slt64(sext_i32_i64(local_tid_13211), segscan_group_sizze_12438);\n        int32_t skip_threads_13252;\n        \n        // read input for in-block scan\n        {\n            if (ltid_in_bounds_13251) {\n                y_13245 = ((volatile __local int64_t *) local_mem_13217)[sext_i32_i64(local_tid_13211)];\n                if ((local_tid_13211 - squot32(local_tid_13211, 32) * 32) == 0) {\n                    x_13244 = y_13245;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_13252 = 1;\n            while (slt32(skip_threads_13",
                                    "252, 32)) {\n                bool thread_active_13253 = sle32(skip_threads_13252, local_tid_13211 - squot32(local_tid_13211, 32) * 32) && ltid_in_bounds_13251;\n                \n                if (thread_active_13253) {\n                    // read operands\n                    {\n                        x_13244 = ((volatile __local int64_t *) local_mem_13217)[sext_i32_i64(local_tid_13211) - sext_i32_i64(skip_threads_13252)];\n                    }\n                }\n                // perform operation\n                {\n                    if (thread_active_13253) {\n                        int64_t zz_13246 = x_13244 + y_13245;\n                        \n                        x_13244 = zz_13246;\n                    }\n                }\n                if (sle32(wave_sizze_13213, skip_threads_13252)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_13253) {\n                    // write result\n                    {\n                        ((volatile __local int64_t *) local_mem_13217)[sext_i32_i64(local_tid_13211)] = x_13244;\n                        y_13245 = x_13244;\n                    }\n                }\n                if (sle32(wave_sizze_13213, skip_threads_13252)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_13252 *= 2;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // last thread of block 'i' writes its result to offset 'i'\n        {\n            if ((local_tid_13211 - squot32(local_tid_13211, 32) * 32) == 31 && ltid_in_bounds_13251) {\n                ((volatile __local int64_t *) local_mem_13217)[sext_i32_i64(squot32(local_tid_13211, 32))] = x_13244;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n        {\n            int32_t skip_threads_13254;\n            \n            // read input for in-block scan\n            {\n                if ", "(squot32(local_tid_13211, 32) == 0 && ltid_in_bounds_13251) {\n                    y_13249 = ((volatile __local int64_t *) local_mem_13217)[sext_i32_i64(local_tid_13211)];\n                    if ((local_tid_13211 - squot32(local_tid_13211, 32) * 32) == 0) {\n                        x_13248 = y_13249;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_13254 = 1;\n                while (slt32(skip_threads_13254, 32)) {\n                    bool thread_active_13255 = sle32(skip_threads_13254, local_tid_13211 - squot32(local_tid_13211, 32) * 32) && (squot32(local_tid_13211, 32) == 0 && ltid_in_bounds_13251);\n                    \n                    if (thread_active_13255) {\n                        // read operands\n                        {\n                            x_13248 = ((volatile __local int64_t *) local_mem_13217)[sext_i32_i64(local_tid_13211) - sext_i32_i64(skip_threads_13254)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_13255) {\n                            int64_t zz_13250 = x_13248 + y_13249;\n                            \n                            x_13248 = zz_13250;\n                        }\n                    }\n                    if (sle32(wave_sizze_13213, skip_threads_13254)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_13255) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_13217)[sext_i32_i64(local_tid_13211)] = x_13248;\n                            y_13249 = x_13248;\n                        }\n                    }\n                    if (sle32(wave_sizze_13213, skip_threads_13254)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_th", "reads_13254 *= 2;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        \n        bool no_carry_in_13256 = squot32(local_tid_13211, 32) == 0 || !ltid_in_bounds_13251;\n        \n        // carry-in for every block except the first\n        {\n            // read operands\n            {\n                if (!no_carry_in_13256) {\n                    y_13245 = x_13244;\n                    x_13244 = ((__local int64_t *) local_mem_13217)[sext_i32_i64(squot32(local_tid_13211, 32)) - (int64_t) 1];\n                }\n            }\n            // perform operation\n            {\n                if (!no_carry_in_13256) {\n                    int64_t zz_13246 = x_13244 + y_13245;\n                    \n                    x_13244 = zz_13246;\n                }\n            }\n            // write final result\n            {\n                if (!no_carry_in_13256) {\n                    ((__local int64_t *) local_mem_13217)[sext_i32_i64(local_tid_13211)] = x_13244;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // restore correct values for first block\n        {\n            if (squot32(local_tid_13211, 32) == 0 && ltid_in_bounds_13251) {\n                ((__local int64_t *) local_mem_13217)[sext_i32_i64(local_tid_13211)] = y_13245;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_tid_13211 == 0) {\n            acc_13247 = ((__local int64_t *) local_mem_13217)[segscan_group_sizze_12438 - (int64_t) 1];\n        } else {\n            acc_13247 = ((__local int64_t *) local_mem_13217)[sext_i32_i64(local_tid_13211) - (int64_t) 1];\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    prefix_13257 = (int64_t) 0;\n    block_new_sgm_13258 = sgm_idx_13226 == (int64_t) 0;\n    // Perform lookback\n    {\n        if (block_new_sgm_13258 && local_tid_13211 == 0) {\n            ((volatile __global int64_t *) incprefixes_mem_13208)[dynamic_id_13224] = acc_13247;\n         ",
                                    "   mem_fence_global();\n            ((volatile __global int8_t *) status_flags_mem_13204)[dynamic_id_13224] = (int8_t) 2;\n            acc_13247 = (int64_t) 0;\n        }\n        if (!block_new_sgm_13258 && slt32(local_tid_13211, wave_sizze_13213)) {\n            if (local_tid_13211 == 0) {\n                ((volatile __global int64_t *) aggregates_mem_13206)[dynamic_id_13224] = acc_13247;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_13204)[dynamic_id_13224] = (int8_t) 1;\n                \n                int8_t tmp_13259 = ((volatile __global int8_t *) status_flags_mem_13204)[dynamic_id_13224 - (int64_t) 1];\n                \n                ((volatile __local int8_t *) local_mem_13217)[(int64_t) 0] = tmp_13259;\n            }\n            mem_fence_local();\n            \n            int8_t status_13260 = ((__local int8_t *) local_mem_13217)[(int64_t) 0];\n            \n            if (status_13260 == (int8_t) 2) {\n                if (local_tid_13211 == 0) {\n                    prefix_13257 = ((volatile __global int64_t *) incprefixes_mem_13208)[dynamic_id_13224 - (int64_t) 1];\n                }\n            } else {\n                int32_t readOffset_13261 = dynamic_id_13224 - sext_i32_i64(wave_sizze_13213);\n                \n                while (slt32(wave_sizze_13213 * -1, readOffset_13261)) {\n                    int32_t read_i_13262 = readOffset_13261 + local_tid_13211;\n                    int64_t aggr_13263 = (int64_t) 0;\n                    int8_t flag_13264 = (int8_t) 0;\n                    \n                    if (sle32(0, read_i_13262)) {\n                        flag_13264 = ((volatile __global int8_t *) status_flags_mem_13204)[sext_i32_i64(read_i_13262)];\n                        if (flag_13264 == (int8_t) 2) {\n                            aggr_13263 = ((volatile __global int64_t *) incprefixes_mem_13208)[sext_i32_i64(read_i_13262)];\n                        } else if (flag_13264 == (int8_t) 1) {\n                    ", "        aggr_13263 = ((volatile __global int64_t *) aggregates_mem_13206)[sext_i32_i64(read_i_13262)];\n                        }\n                    }\n                    ((__local int64_t *) local_mem_13217)[(int64_t) 4 + sext_i32_i64(local_tid_13211)] = aggr_13263;\n                    ((__local int8_t *) local_mem_13217)[sext_i32_i64(local_tid_13211)] = flag_13264;\n                    flag_13264 = ((__local int8_t *) local_mem_13217)[sext_i32_i64(wave_sizze_13213) - (int64_t) 1];\n                    if (slt8(flag_13264, (int8_t) 2)) {\n                        int8_t flg_x_13268;\n                        int8_t flg_y_13269;\n                        int64_t x_13265;\n                        int64_t y_13266;\n                        int32_t skip_threads_13270;\n                        \n                        // read input for in-block scan\n                        {\n                            flg_y_13269 = ((volatile __local int8_t *) local_mem_13217)[sext_i32_i64(local_tid_13211)];\n                            y_13266 = ((volatile __local int64_t *) local_mem_13217)[(int64_t) 4 + sext_i32_i64(local_tid_13211)];\n                            if ((local_tid_13211 - squot32(local_tid_13211, 32) * 32) == 0) {\n                                x_13265 = y_13266;\n                                flg_x_13268 = flg_y_13269;\n                            }\n                        }\n                        // in-block scan (hopefully no barriers needed)\n                        {\n                            skip_threads_13270 = 1;\n                            while (slt32(skip_threads_13270, 32)) {\n                                if (sle32(skip_threads_13270, local_tid_13211 - squot32(local_tid_13211, 32) * 32)) {\n                                    // read operands\n                                    {\n                                        flg_x_13268 = ((volatile __local int8_t *) local_mem_13217)[sext_i32_i64(local_tid_13211) - sext_i32_i64(skip_threads_13270)];\n                       ", "                 x_13265 = ((volatile __local int64_t *) local_mem_13217)[(int64_t) 4 + (sext_i32_i64(local_tid_13211) - sext_i32_i64(skip_threads_13270))];\n                                    }\n                                    // perform operation\n                                    {\n                                        if (flg_y_13269 == (int8_t) 2 || flg_y_13269 == (int8_t) 0) {\n                                            flg_x_13268 = flg_y_13269;\n                                            x_13265 = y_13266;\n                                        } else {\n                                            int64_t zz_13267 = x_13265 + y_13266;\n                                            \n                                            x_13265 = zz_13267;\n                                        }\n                                    }\n                                    // write result\n                                    {\n                                        ((volatile __local int8_t *) local_mem_13217)[sext_i32_i64(local_tid_13211)] = flg_x_13268;\n                                        flg_y_13269 = flg_x_13268;\n                                        ((volatile __local int64_t *) local_mem_13217)[(int64_t) 4 + sext_i32_i64(local_tid_13211)] = x_13265;\n                                        y_13266 = x_13265;\n                                    }\n                                }\n                                skip_threads_13270 *= 2;\n                            }\n                        }\n                    }\n                    flag_13264 = ((__local int8_t *) local_mem_13217)[sext_i32_i64(wave_sizze_13213) - (int64_t) 1];\n                    aggr_13263 = ((__local int64_t *) local_mem_13217)[(int64_t) 4 + (sext_i32_i64(wave_sizze_13213) - (int64_t) 1)];\n                    if (flag_13264 == (int8_t) 2) {\n                        readOffset_13261 = wave_sizze_13213 * -1;\n                    } else if (flag_13264 == (int8_t) 1) {\n                        read",
                                    "Offset_13261 -= wave_sizze_13213;\n                    }\n                    if (slt8((int8_t) 0, flag_13264)) {\n                        int64_t x_13271 = aggr_13263;\n                        int64_t y_13272 = prefix_13257;\n                        int64_t zz_13273 = x_13271 + y_13272;\n                        \n                        prefix_13257 = zz_13273;\n                    }\n                    mem_fence_local();\n                }\n            }\n            if (local_tid_13211 == 0) {\n                if (boundary_13227 == sext_i64_i32(segscan_group_sizze_12438 * (int64_t) 11)) {\n                    int64_t x_13274 = prefix_13257;\n                    int64_t y_13275 = acc_13247;\n                    int64_t zz_13276 = x_13274 + y_13275;\n                    \n                    ((volatile __global int64_t *) incprefixes_mem_13208)[dynamic_id_13224] = zz_13276;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_13204)[dynamic_id_13224] = (int8_t) 2;\n                }\n                ((__local int64_t *) local_mem_13217)[(int64_t) 4] = prefix_13257;\n                acc_13247 = (int64_t) 0;\n            }\n        }\n        if (!(dynamic_id_13224 == (int64_t) 0)) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            prefix_13257 = ((__local int64_t *) local_mem_13217)[(int64_t) 4];\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    // Distribute results\n    {\n        int64_t x_13277;\n        int64_t y_13278;\n        int64_t x_13280 = prefix_13257;\n        int64_t y_13281 = acc_13247;\n        \n        if (slt32(local_tid_13211 * 11, boundary_13227) && !block_new_sgm_13258) {\n            int64_t zz_13282 = x_13280 + y_13281;\n            \n            x_13277 = zz_13282;\n        } else {\n            x_13277 = acc_13247;\n        }\n        \n        int32_t stopping_point_13283 = segsizze_compact_13228 - srem32(local_tid_13211 * 11 - 1 + segsizze_compact_13228 - boundary_13227, segsizze_compact_13228);\n        \n", "        for (int64_t i_13284 = 0; i_13284 < (int64_t) 11; i_13284++) {\n            if (slt32(sext_i64_i32(i_13284), stopping_point_13283 - 1)) {\n                y_13278 = private_mem_13229[i_13284];\n                \n                int64_t zz_13279 = x_13277 + y_13278;\n                \n                private_mem_13229[i_13284] = zz_13279;\n            }\n        }\n    }\n    // Transpose scan output and Write it to global memory in coalesced fashion\n    {\n        for (int64_t i_13285 = 0; i_13285 < (int64_t) 11; i_13285++) {\n            int64_t sharedIdx_13286 = sext_i32_i64(local_tid_13211 * 11) + i_13285;\n            int64_t tmp_13287 = private_mem_13229[i_13285];\n            \n            ((__local int64_t *) local_mem_13217)[sharedIdx_13286] = tmp_13287;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int64_t i_13288 = 0; i_13288 < (int64_t) 11; i_13288++) {\n            int64_t flat_idx_13289 = blockOff_13225 + segscan_group_sizze_12438 * i_13288 + sext_i32_i64(local_tid_13211);\n            int64_t slice_13290 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n            int64_t gtid_12442 = flat_idx_13289;\n            int64_t remnant_13291 = flat_idx_13289 - gtid_12442;\n            \n            if (slt64(flat_idx_13289, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {\n                int64_t tmp_13292 = ((__local int64_t *) local_mem_13217)[flat_idx_13289 - blockOff_13225];\n                \n                ((__global int64_t *) mem_12955)[gtid_12442] = tmp_13292;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // If this is the last block, reset the dynamicId\n    {\n        if (dynamic_id_13224 == num_groups_13200 - (int64_t) 1) {\n            ((__global int32_t *) id_counter_mem_13202)[(int64_t) 0] = 0;\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_group_sizze_12438\n}\nFUTHARK_KERNEL_SIZED(big_add_validationzisegmap_group_sizze_11786, 1, 1)\nvoid big_add_validationzisegmap_11836(__global int *global_failure, int failure_is_an_option,", " __global int64_t *global_failure_args, int64_t n_10211, int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, int32_t i64_res_11190, int32_t zp_lhs_11191, int32_t zp_lhs_11192, __global unsigned char *as_mem_12913, __global unsigned char *bs_mem_12914, __global unsigned char *mem_12919, __global unsigned char *mem_12922, __global unsigned char *mem_12925, __global unsigned char *mem_12928, __global unsigned char *mem_12931, __global unsigned char *mem_12934, __global unsigned char *mem_12937, __global unsigned char *mem_12940)\n{\n    #define segmap_group_sizze_11825 (big_add_validationzisegmap_group_sizze_11786)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13004;\n    int64_t group_sizze_13007;\n    int32_t wave_sizze_13006;\n    int32_t group_tid_13005;\n    int32_t global_tid_13003;\n    int32_t phys_tid_11836;\n    int64_t global_tid_13008;\n    int64_t slice_13009;\n    int64_t gtid_11835;\n    int64_t remnant_13010;\n    \n    local_tid_13004 = get_local_id(0);\n    group_sizze_13007 = get_local_size(0);\n    wave_sizze_13006 = LOCKSTEP_WIDTH;\n    group_tid_13005 = get_group_id(0);\n    global_tid_13003 = group_tid_13005 * group_sizze_13007 + local_tid_13004;\n    phys_tid_11836 = global_tid_13003;\n    global_tid_13008 = sext_i32_i64(group_tid_13005) * segmap_group_sizze_11825 + sext_i32_i64(local_tid_13004);\n    slice_13009 = n_10211;\n    gtid_11835 = global_tid_13008;\n    remnant_13010 = global_tid_13008 - gtid_11835;\n    if (slt64(gtid_11835, n_10211)) {\n        int32_t i64_res_11838;\n        int64_t i_11839;\n        bool x_11840;\n        bool y_11841;\n        bool bounds_check_11842;\n        bool index_certs_11843;\n        int32_t tmp_11845;\n        int64_t tmp_11846;\n        bool x_11847;\n        bool y_11848;\n        bool bounds_check_11849;\n        bool index_certs_11850;\n        int32_t tmp_11852;\n        int64_t tmp_11853;\n        bool x_11854;\n        bool y_11855;\n        bool bounds_check_11856;\n        bool index_certs_11857;\n        int32_t tm",
                                    "p_11859;\n        int64_t tmp_11860;\n        bool x_11861;\n        bool y_11862;\n        bool bounds_check_11863;\n        bool index_certs_11864;\n        int64_t tmp_11844;\n        int64_t tmp_11851;\n        int64_t tmp_11858;\n        int64_t tmp_11865;\n        int64_t tmp_11866;\n        int64_t tmp_11867;\n        int64_t tmp_11868;\n        int64_t tmp_11869;\n        \n        i64_res_11838 = sext_i64_i32(gtid_11835);\n        i_11839 = sext_i32_i64(i64_res_11838);\n        x_11840 = sle64((int64_t) 0, i_11839);\n        y_11841 = slt64(i_11839, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);\n        bounds_check_11842 = x_11840 && y_11841;\n        if (!bounds_check_11842) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 5) == -1) {\n                    global_failure_args[0] = (int64_t) i_11839;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n                    ;\n                }\n                return;\n            }\n        }\n        tmp_11845 = add32(i64_res_11190, i64_res_11838);\n        tmp_11846 = sext_i32_i64(tmp_11845);\n        x_11847 = sle64((int64_t) 0, tmp_11846);\n        y_11848 = slt64(tmp_11846, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);\n        bounds_check_11849 = x_11847 && y_11848;\n        if (!bounds_check_11849) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 6) == -1) {\n                    global_failure_args[0] = (int64_t) tmp_11846;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n                    ;\n                }\n                return;\n            }\n        }\n        tmp_11852 = add32(zp_lhs_11191, i64_res_11838);\n        tmp_11853 = sext_i32_i64(tmp_11852);\n        x_11854 = sle64((int64_t) 0, tmp_11853);\n        y_11855 = slt64(tmp_11853, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);\n        bounds_check_11856 = x_11854 && y_11855;\n        if (!bounds_check_11856) {\n            {\n                if (atomic_c", "mpxchg_i32_global(global_failure, -1, 7) == -1) {\n                    global_failure_args[0] = (int64_t) tmp_11853;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n                    ;\n                }\n                return;\n            }\n        }\n        tmp_11859 = add32(zp_lhs_11192, i64_res_11838);\n        tmp_11860 = sext_i32_i64(tmp_11859);\n        x_11861 = sle64((int64_t) 0, tmp_11860);\n        y_11862 = slt64(tmp_11860, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);\n        bounds_check_11863 = x_11861 && y_11862;\n        if (!bounds_check_11863) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 8) == -1) {\n                    global_failure_args[0] = (int64_t) tmp_11860;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n                    ;\n                }\n                return;\n            }\n        }\n        tmp_11844 = ((__global int64_t *) as_mem_12913)[i_11839];\n        tmp_11851 = ((__global int64_t *) as_mem_12913)[tmp_11846];\n        tmp_11858 = ((__global int64_t *) as_mem_12913)[tmp_11853];\n        tmp_11865 = ((__global int64_t *) as_mem_12913)[tmp_11860];\n        tmp_11866 = ((__global int64_t *) bs_mem_12914)[i_11839];\n        tmp_11867 = ((__global int64_t *) bs_mem_12914)[tmp_11846];\n        tmp_11868 = ((__global int64_t *) bs_mem_12914)[tmp_11853];\n        tmp_11869 = ((__global int64_t *) bs_mem_12914)[tmp_11860];\n        ((__global int64_t *) mem_12919)[gtid_11835] = tmp_11844;\n        ((__global int64_t *) mem_12922)[gtid_11835] = tmp_11851;\n        ((__global int64_t *) mem_12925)[gtid_11835] = tmp_11858;\n        ((__global int64_t *) mem_12928)[gtid_11835] = tmp_11865;\n        ((__global int64_t *) mem_12931)[gtid_11835] = tmp_11866;\n        ((__global int64_t *) mem_12934)[gtid_11835] = tmp_11867;\n        ((__global int64_t *) mem_12937)[gtid_11835] = tmp_11868;\n        ((__global int64_t *) mem_12940)[gtid_11835] = tm", "p_11869;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_11825\n}\nFUTHARK_KERNEL_SIZED(big_add_validationzisegred_group_sizze_11879, 1, 1)\nvoid big_add_validationzisegred_nonseg_11887(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t red_arr_mem_13200_backing_offset_0, int64_t sync_arr_mem_13198_backing_offset_1, int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, int64_t conc_tmp_11253, int64_t num_groups_11882, int64_t num_threads_13192, __global unsigned char *exp_res_mem_12915, __global unsigned char *mem_12944, __global unsigned char *mem_12947, __global unsigned char *mem_12950, __global unsigned char *counters_mem_13188, __global unsigned char *segred_tmp_mem_13190)\n{\n    #define segred_group_sizze_11880 (big_add_validationzisegred_group_sizze_11879)\n    \n    volatile __local unsigned char *red_arr_mem_13200_backing_1 = &local_mem[red_arr_mem_13200_backing_offset_0];\n    volatile __local unsigned char *sync_arr_mem_13198_backing_0 = &local_mem[sync_arr_mem_13198_backing_offset_1];\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_13194;\n    int64_t group_sizze_13197;\n    int32_t wave_sizze_13196;\n    int32_t group_tid_13195;\n    int32_t global_tid_13193;\n    int32_t phys_tid_11887;\n    __local unsigned char *sync_arr_mem_13198;\n    __local unsigned char *red_arr_mem_13200;\n    int64_t dummy_11885;\n    int64_t gtid_11886;\n    bool x_acc_13202;\n    int64_t chunk_sizze_13203;\n    bool x_10230;\n    bool y_10231;\n    int32_t offset_13208;\n    int32_t skip_waves_13209;\n    bool x_13204;\n    bool y_13205;\n    int32_t old_counter_13210;\n    bool is_last_group_13211;\n    \n    local_tid_13194 = get_local_id(0);\n    group_sizze_13197 = get_local_size(0);\n    wave_sizze_13196 = LOCKSTEP_WIDTH;\n    group_ti",
                                    "d_13195 = get_group_id(0);\n    global_tid_13193 = group_tid_13195 * group_sizze_13197 + local_tid_13194;\n    phys_tid_11887 = global_tid_13193;\n    sync_arr_mem_13198 = (__local unsigned char *) sync_arr_mem_13198_backing_0;\n    red_arr_mem_13200 = (__local unsigned char *) red_arr_mem_13200_backing_1;\n    dummy_11885 = (int64_t) 0;\n    gtid_11886 = (int64_t) 0;\n    chunk_sizze_13203 = smin64(sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, sext_i32_i64(sext_i64_i32(segred_group_sizze_11880 * num_groups_11882))), sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10212 - phys_tid_11887, num_threads_13192));\n    // neutral-initialise the accumulators\n    {\n        x_acc_13202 = 1;\n    }\n    for (int64_t i_13207 = 0; i_13207 < chunk_sizze_13203; i_13207++) {\n        gtid_11886 = phys_tid_11887 + num_threads_13192 * i_13207;\n        // apply map function\n        {\n            int64_t eta_p_11555 = ((__global int64_t *) mem_12947)[gtid_11886];\n            int64_t y_11557 = ((__global int64_t *) exp_res_mem_12915)[gtid_11886];\n            bool cond_11558 = slt64((int64_t) 0, gtid_11886);\n            bool bool_arg0_11559;\n            \n            if (cond_11558 == 1) {\n                int64_t za_lhs_11629 = sub64(gtid_11886, (int64_t) 1);\n                bool x_11630 = sle64((int64_t) 0, za_lhs_11629);\n                bool y_11631 = slt64(za_lhs_11629, conc_tmp_11253);\n                bool bounds_check_11632 = x_11630 && y_11631;\n                bool index_certs_11633;\n                \n                if (!bounds_check_11632) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 9) == -1) {\n                            global_failure_args[0] = (int64_t) za_lhs_11629;\n                            global_failure_args[1] = (int64_t) conc_tmp_11253;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                \n       ", "         int32_t za_lhs_11634 = ((__global int32_t *) mem_12944)[za_lhs_11629];\n                int32_t zeze_lhs_11635 = 1 & za_lhs_11634;\n                bool bool_arg0_t_res_11636 = zeze_lhs_11635 == 1;\n                \n                bool_arg0_11559 = bool_arg0_t_res_11636;\n            } else {\n                bool_arg0_11559 = 0;\n            }\n            \n            int64_t unsign_arg0_11568 = btoi_bool_i64(bool_arg0_11559);\n            int64_t lifted_lambda_res_11569 = add64(eta_p_11555, unsign_arg0_11568);\n            bool binlam_res_11571 = lifted_lambda_res_11569 == y_11557;\n            \n            // save map-out results\n            { }\n            // load accumulator\n            {\n                x_10230 = x_acc_13202;\n            }\n            // load new values\n            {\n                y_10231 = binlam_res_11571;\n            }\n            // apply reduction operator\n            {\n                bool binlam_res_10232 = x_10230 && y_10231;\n                \n                // store in accumulator\n                {\n                    x_acc_13202 = binlam_res_10232;\n                }\n            }\n        }\n    }\n    \n  error_0:\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_failure)\n        return;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // to reduce current chunk, first store our result in memory\n    {\n        x_10230 = x_acc_13202;\n        ((__local bool *) red_arr_mem_13200)[sext_i32_i64(local_tid_13194)] = x_10230;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_13209 = 1;\n    offset_13208 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_13194, sext_i64_i32(segred_group_sizze_11880))) {\n            x_13204 = ((__local bool *) red_arr_mem_13200)[sext_i32_i64(local_tid_13194 + offset_13208)];\n        }\n    }\n    offset_13208 = 1;\n    while (slt32(offset_13208, wave_sizze_13196)) {\n        if (slt32(local_tid_13194 + offset_13208, sext_i64_i32(segred_group_sizze_11880)) && ((local_tid_13194 - squo", "t32(local_tid_13194, wave_sizze_13196) * wave_sizze_13196) & (2 * offset_13208 - 1)) == 0) {\n            // read array element\n            {\n                y_13205 = ((volatile __local bool *) red_arr_mem_13200)[sext_i32_i64(local_tid_13194 + offset_13208)];\n            }\n            // apply reduction operation\n            {\n                bool binlam_res_13206 = x_13204 && y_13205;\n                \n                x_13204 = binlam_res_13206;\n            }\n            // write result of operation\n            {\n                ((volatile __local bool *) red_arr_mem_13200)[sext_i32_i64(local_tid_13194)] = x_13204;\n            }\n        }\n        offset_13208 *= 2;\n    }\n    while (slt32(skip_waves_13209, squot32(sext_i64_i32(segred_group_sizze_11880) + wave_sizze_13196 - 1, wave_sizze_13196))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_13208 = skip_waves_13209 * wave_sizze_13196;\n        if (slt32(local_tid_13194 + offset_13208, sext_i64_i32(segred_group_sizze_11880)) && ((local_tid_13194 - squot32(local_tid_13194, wave_sizze_13196) * wave_sizze_13196) == 0 && (squot32(local_tid_13194, wave_sizze_13196) & (2 * skip_waves_13209 - 1)) == 0)) {\n            // read array element\n            {\n                y_13205 = ((__local bool *) red_arr_mem_13200)[sext_i32_i64(local_tid_13194 + offset_13208)];\n            }\n            // apply reduction operation\n            {\n                bool binlam_res_13206 = x_13204 && y_13205;\n                \n                x_13204 = binlam_res_13206;\n            }\n            // write result of operation\n            {\n                ((__local bool *) red_arr_mem_13200)[sext_i32_i64(local_tid_13194)] = x_13204;\n            }\n        }\n        skip_waves_13209 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Copy array-typed operands to result array\n    {\n        if (local_tid_13194 == 0) { }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // first thread saves the result in accumulator\n    {\n        if (sext_i32_i64(loca",
                                    "l_tid_13194) == (int64_t) 0) {\n            x_acc_13202 = x_13204;\n        }\n    }\n    // first thread in group saves group result to global memory\n    {\n        if (local_tid_13194 == 0) {\n            ((__global bool *) segred_tmp_mem_13190)[sext_i32_i64(group_tid_13195)] = x_acc_13202;\n            mem_fence_global();\n            old_counter_13210 = atomic_add_i32_global(&((volatile __global int *) counters_mem_13188)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_13198)[(int64_t) 0] = old_counter_13210 == num_groups_11882 - (int64_t) 1;\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_group_13211 = ((__local bool *) sync_arr_mem_13198)[(int64_t) 0];\n    if (is_last_group_13211) {\n        if (local_tid_13194 == 0) {\n            old_counter_13210 = atomic_add_i32_global(&((volatile __global int *) counters_mem_13188)[(int64_t) 0], (int) ((int64_t) 0 - num_groups_11882));\n        }\n        // read in the per-group-results\n        {\n            int64_t read_per_thread_13212 = sdiv_up64(num_groups_11882, segred_group_sizze_11880);\n            \n            x_10230 = 1;\n            for (int64_t i_13213 = 0; i_13213 < read_per_thread_13212; i_13213++) {\n                int64_t group_res_id_13214 = sext_i32_i64(local_tid_13194) * read_per_thread_13212 + i_13213;\n                int64_t index_of_group_res_13215 = group_res_id_13214;\n                \n                if (slt64(group_res_id_13214, num_groups_11882)) {\n                    y_10231 = ((__global bool *) segred_tmp_mem_13190)[index_of_group_res_13215];\n                    \n                    bool binlam_res_10232 = x_10230 && y_10231;\n                    \n                    x_10230 = binlam_res_10232;\n                }\n            }\n        }\n        ((__local bool *) red_arr_mem_13200)[sext_i32_i64(local_tid_13194)] = x_10230;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-group results\n        {\n            int32_t offset_13216;\n           ", " int32_t skip_waves_13217 = 1;\n            bool x_13204;\n            bool y_13205;\n            \n            offset_13216 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_13194, sext_i64_i32(segred_group_sizze_11880))) {\n                    x_13204 = ((__local bool *) red_arr_mem_13200)[sext_i32_i64(local_tid_13194 + offset_13216)];\n                }\n            }\n            offset_13216 = 1;\n            while (slt32(offset_13216, wave_sizze_13196)) {\n                if (slt32(local_tid_13194 + offset_13216, sext_i64_i32(segred_group_sizze_11880)) && ((local_tid_13194 - squot32(local_tid_13194, wave_sizze_13196) * wave_sizze_13196) & (2 * offset_13216 - 1)) == 0) {\n                    // read array element\n                    {\n                        y_13205 = ((volatile __local bool *) red_arr_mem_13200)[sext_i32_i64(local_tid_13194 + offset_13216)];\n                    }\n                    // apply reduction operation\n                    {\n                        bool binlam_res_13206 = x_13204 && y_13205;\n                        \n                        x_13204 = binlam_res_13206;\n                    }\n                    // write result of operation\n                    {\n                        ((volatile __local bool *) red_arr_mem_13200)[sext_i32_i64(local_tid_13194)] = x_13204;\n                    }\n                }\n                offset_13216 *= 2;\n            }\n            while (slt32(skip_waves_13217, squot32(sext_i64_i32(segred_group_sizze_11880) + wave_sizze_13196 - 1, wave_sizze_13196))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_13216 = skip_waves_13217 * wave_sizze_13196;\n                if (slt32(local_tid_13194 + offset_13216, sext_i64_i32(segred_group_sizze_11880)) && ((local_tid_13194 - squot32(local_tid_13194, wave_sizze_13196) * wave_sizze_13196) == 0 && (squot32(local_tid_13194, wave_sizze_13196) & (2 * skip_waves_13217 - 1)) == 0)) {\n          ", "          // read array element\n                    {\n                        y_13205 = ((__local bool *) red_arr_mem_13200)[sext_i32_i64(local_tid_13194 + offset_13216)];\n                    }\n                    // apply reduction operation\n                    {\n                        bool binlam_res_13206 = x_13204 && y_13205;\n                        \n                        x_13204 = binlam_res_13206;\n                    }\n                    // write result of operation\n                    {\n                        ((__local bool *) red_arr_mem_13200)[sext_i32_i64(local_tid_13194)] = x_13204;\n                    }\n                }\n                skip_waves_13217 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // Copy array-typed operands to result array\n            {\n                if (local_tid_13194 == 0) { }\n            }\n            // and back to memory with the final result\n            {\n                if (local_tid_13194 == 0) {\n                    ((__global bool *) mem_12950)[(int64_t) 0] = x_13204;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_group_sizze_11880\n}\nFUTHARK_KERNEL_SIZED(big_add_validationzisegscan_group_sizze_11871, 1, 1)\nvoid big_add_validationzisegscan_11877(__global int *global_failure, int64_t local_mem_13069_backing_offset_0, int64_t n_10211, int64_t conc_tmp_11249, int64_t conc_tmp_11251, int64_t conc_tmp_11253, int64_t num_groups_13012, __global unsigned char *mem_12919, __global unsigned char *mem_12922, __global unsigned char *mem_12925, __global unsigned char *mem_12928, __global unsigned char *mem_12931, __global unsigned char *mem_12934, __global unsigned char *mem_12937, __global unsigned char *mem_12940, __global unsigned char *mem_12944, __global unsigned char *mem_12947, __global unsigned char *id_counter_mem_13014, __global unsigned char *status_flags_mem_13036, __global unsigned char *aggregates_mem_13038, __global unsigned char *incprefixes_",
                                    "mem_13040)\n{\n    #define segscan_group_sizze_11872 (big_add_validationzisegscan_group_sizze_11871)\n    \n    volatile __local unsigned char *local_mem_13069_backing_0 = &local_mem[local_mem_13069_backing_offset_0];\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13063;\n    int64_t group_sizze_13066;\n    int32_t wave_sizze_13065;\n    int32_t group_tid_13064;\n    int32_t global_tid_13062;\n    int32_t phys_tid_11877;\n    int64_t byte_offsets_13067;\n    int64_t warp_byte_offset_13068;\n    __local unsigned char *local_mem_13069;\n    int64_t trans_arr_len_13070;\n    int32_t dynamic_id_13076;\n    int64_t blockOff_13077;\n    int64_t sgm_idx_13078;\n    int32_t boundary_13079;\n    int32_t segsizze_compact_13080;\n    int32_t private_mem_13081[(int64_t) 23];\n    int32_t acc_13105;\n    int32_t prefix_13121;\n    bool block_new_sgm_13122;\n    \n    local_tid_13063 = get_local_id(0);\n    group_sizze_13066 = get_local_size(0);\n    wave_sizze_13065 = LOCKSTEP_WIDTH;\n    group_tid_13064 = get_group_id(0);\n    global_tid_13062 = group_tid_13064 * group_sizze_13066 + local_tid_13063;\n    phys_tid_11877 = global_tid_13062;\n    byte_offsets_13067 = segscan_group_sizze_11872 * (int64_t) 4;\n    warp_byte_offset_13068 = (int64_t) 160;\n    // Allocate reused shared memeory\n    { }\n    local_mem_13069 = (__local unsigned char *) local_mem_13069_backing_0;\n    trans_arr_len_13070 = (int64_t) 23 * segscan_group_sizze_11872;\n    if (local_tid_13063 == 0) {\n        dynamic_id_13076 = atomic_add_i32_global(&((volatile __global int *) id_counter_mem_13014)[(int64_t) 0], (int) 1);\n        ((__local int32_t *) local_mem_13069)[(int64_t) 0] = dynamic_id_13076;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dynamic_id_13076 = ((__local int32_t *) local_mem_13069)[(int64_t) 0];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    blockOff_13077 = sext_i32_i64(dynamic_id_13076) * (int64_t) 23 * segscan_group_sizze_11872;\n    sgm_idx_13078 = smod64(blockOff_13077, conc_tmp_11253);\n    boundary_13", "079 = sext_i64_i32(smin64((int64_t) 23 * segscan_group_sizze_11872, conc_tmp_11253 - sgm_idx_13078));\n    segsizze_compact_13080 = sext_i64_i32(smin64((int64_t) 23 * segscan_group_sizze_11872, conc_tmp_11253));\n    // Load and map\n    {\n        for (int64_t i_13083 = 0; i_13083 < (int64_t) 23; i_13083++) {\n            int64_t phys_tid_13084 = blockOff_13077 + sext_i32_i64(local_tid_13063) + i_13083 * segscan_group_sizze_11872;\n            int64_t slice_13085 = conc_tmp_11253;\n            int64_t gtid_11876 = phys_tid_13084;\n            int64_t remnant_13086 = phys_tid_13084 - gtid_11876;\n            \n            if (slt64(phys_tid_13084, conc_tmp_11253)) {\n                bool index_concat_cmp_12886 = sle64(conc_tmp_11251, gtid_11876);\n                int64_t index_concat_branch_12898;\n                \n                if (index_concat_cmp_12886 == 1) {\n                    int64_t index_concat_i_12887 = sub64(gtid_11876, conc_tmp_11251);\n                    int64_t index_concat_12888 = ((__global int64_t *) mem_12928)[index_concat_i_12887];\n                    \n                    index_concat_branch_12898 = index_concat_12888;\n                } else {\n                    bool index_concat_cmp_12889 = sle64(conc_tmp_11249, gtid_11876);\n                    int64_t index_concat_branch_12897;\n                    \n                    if (index_concat_cmp_12889 == 1) {\n                        int64_t index_concat_i_12890 = sub64(gtid_11876, conc_tmp_11249);\n                        int64_t index_concat_12891 = ((__global int64_t *) mem_12925)[index_concat_i_12890];\n                        \n                        index_concat_branch_12897 = index_concat_12891;\n                    } else {\n                        bool index_concat_cmp_12892 = sle64(n_10211, gtid_11876);\n                        int64_t index_concat_branch_12896;\n                        \n                        if (index_concat_cmp_12892 == 1) {\n                            int64_t index_concat_i_12893 = sub64", "(gtid_11876, n_10211);\n                            int64_t index_concat_12894 = ((__global int64_t *) mem_12922)[index_concat_i_12893];\n                            \n                            index_concat_branch_12896 = index_concat_12894;\n                        } else {\n                            int64_t index_concat_12895 = ((__global int64_t *) mem_12919)[gtid_11876];\n                            \n                            index_concat_branch_12896 = index_concat_12895;\n                        }\n                        index_concat_branch_12897 = index_concat_branch_12896;\n                    }\n                    index_concat_branch_12898 = index_concat_branch_12897;\n                }\n                \n                int64_t index_concat_branch_12882;\n                \n                if (index_concat_cmp_12886 == 1) {\n                    int64_t index_concat_i_12871 = sub64(gtid_11876, conc_tmp_11251);\n                    int64_t index_concat_12872 = ((__global int64_t *) mem_12940)[index_concat_i_12871];\n                    \n                    index_concat_branch_12882 = index_concat_12872;\n                } else {\n                    bool index_concat_cmp_12873 = sle64(conc_tmp_11249, gtid_11876);\n                    int64_t index_concat_branch_12881;\n                    \n                    if (index_concat_cmp_12873 == 1) {\n                        int64_t index_concat_i_12874 = sub64(gtid_11876, conc_tmp_11249);\n                        int64_t index_concat_12875 = ((__global int64_t *) mem_12937)[index_concat_i_12874];\n                        \n                        index_concat_branch_12881 = index_concat_12875;\n                    } else {\n                        bool index_concat_cmp_12876 = sle64(n_10211, gtid_11876);\n                        int64_t index_concat_branch_12880;\n                        \n                        if (index_concat_cmp_12876 == 1) {\n                            int64_t index_concat_i_12877 = sub64(gtid_11876, n_10211);\n    ",
                                    "                        int64_t index_concat_12878 = ((__global int64_t *) mem_12934)[index_concat_i_12877];\n                            \n                            index_concat_branch_12880 = index_concat_12878;\n                        } else {\n                            int64_t index_concat_12879 = ((__global int64_t *) mem_12931)[gtid_11876];\n                            \n                            index_concat_branch_12880 = index_concat_12879;\n                        }\n                        index_concat_branch_12881 = index_concat_branch_12880;\n                    }\n                    index_concat_branch_12882 = index_concat_branch_12881;\n                }\n                \n                int64_t s_11577 = add64(index_concat_branch_12882, index_concat_branch_12898);\n                bool bool_arg0_11578 = ult64(s_11577, index_concat_branch_12898);\n                int32_t unsign_arg0_11579 = btoi_bool_i32(bool_arg0_11578);\n                bool bool_arg0_11580 = s_11577 == (int64_t) -1;\n                int32_t unsign_arg0_11581 = btoi_bool_i32(bool_arg0_11580);\n                int32_t zb_rhs_11582 = shl32(unsign_arg0_11581, 1);\n                int32_t c_11583 = unsign_arg0_11579 | zb_rhs_11582;\n                \n                ((__global int64_t *) mem_12947)[gtid_11876] = s_11577;\n                private_mem_13081[i_13083] = c_11583;\n            } else {\n                private_mem_13081[i_13083] = 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Transpose scan inputs\n    {\n        for (int64_t i_13087 = 0; i_13087 < (int64_t) 23; i_13087++) {\n            int64_t sharedIdx_13088 = sext_i32_i64(local_tid_13063) + i_13087 * segscan_group_sizze_11872;\n            int32_t tmp_13089 = private_mem_13081[i_13087];\n            \n            ((__local int32_t *) local_mem_13069)[sharedIdx_13088] = tmp_13089;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_13090 = 0; i_13090 < 23; i_13090++) {\n            int32_t sharedId", "x_13091 = local_tid_13063 * 23 + i_13090;\n            int32_t tmp_13092 = ((__local int32_t *) local_mem_13069)[sext_i32_i64(sharedIdx_13091)];\n            \n            private_mem_13081[sext_i32_i64(i_13090)] = tmp_13092;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // Per thread scan\n    {\n        int32_t gidx_13093 = local_tid_13063 * 23 + 1;\n        \n        for (int64_t i_13094 = 0; i_13094 < (int64_t) 22; i_13094++) {\n            int32_t eta_p_11276;\n            int32_t eta_p_11277;\n            \n            eta_p_11276 = private_mem_13081[i_13094];\n            eta_p_11277 = private_mem_13081[i_13094 + (int64_t) 1];\n            \n            int32_t za_lhs_11278 = eta_p_11276 & eta_p_11277;\n            int32_t zb_lhs_11279 = 2 & za_lhs_11278;\n            int32_t za_rhs_11280 = lshr32(eta_p_11277, 1);\n            int32_t zb_lhs_11281 = eta_p_11276 & za_rhs_11280;\n            int32_t za_lhs_11282 = eta_p_11277 | zb_lhs_11281;\n            int32_t zb_rhs_11283 = 1 & za_lhs_11282;\n            int32_t carry_prop_res_11284 = zb_lhs_11279 | zb_rhs_11283;\n            \n            private_mem_13081[i_13094 + (int64_t) 1] = carry_prop_res_11284;\n        }\n    }\n    // Publish results in shared memory\n    {\n        int32_t tmp_13095 = private_mem_13081[(int64_t) 22];\n        \n        ((__local int32_t *) local_mem_13069)[sext_i32_i64(local_tid_13063)] = tmp_13095;\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // Scan results (with warp scan)\n    {\n        int32_t eta_p_13096;\n        int32_t eta_p_13097;\n        int32_t eta_p_13106;\n        int32_t eta_p_13107;\n        bool ltid_in_bounds_13115 = slt64(sext_i32_i64(local_tid_13063), segscan_group_sizze_11872);\n        int32_t skip_threads_13116;\n        \n        // read input for in-block scan\n        {\n            if (ltid_in_bounds_13115) {\n                eta_p_13097 = ((volatile __local int32_t *) local_mem_13069)[sext_i32_i64(local_tid_13063)];\n                if ((local_tid_13063 - squot32(local_tid_130", "63, 32) * 32) == 0) {\n                    eta_p_13096 = eta_p_13097;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_13116 = 1;\n            while (slt32(skip_threads_13116, 32)) {\n                bool thread_active_13117 = sle32(skip_threads_13116, local_tid_13063 - squot32(local_tid_13063, 32) * 32) && ltid_in_bounds_13115;\n                \n                if (thread_active_13117) {\n                    // read operands\n                    {\n                        eta_p_13096 = ((volatile __local int32_t *) local_mem_13069)[sext_i32_i64(local_tid_13063) - sext_i32_i64(skip_threads_13116)];\n                    }\n                }\n                // perform operation\n                {\n                    if (thread_active_13117) {\n                        int32_t za_lhs_13098 = eta_p_13096 & eta_p_13097;\n                        int32_t zb_lhs_13099 = 2 & za_lhs_13098;\n                        int32_t za_rhs_13100 = lshr32(eta_p_13097, 1);\n                        int32_t zb_lhs_13101 = eta_p_13096 & za_rhs_13100;\n                        int32_t za_lhs_13102 = eta_p_13097 | zb_lhs_13101;\n                        int32_t zb_rhs_13103 = 1 & za_lhs_13102;\n                        int32_t carry_prop_res_13104 = zb_lhs_13099 | zb_rhs_13103;\n                        \n                        eta_p_13096 = carry_prop_res_13104;\n                    }\n                }\n                if (sle32(wave_sizze_13065, skip_threads_13116)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_13117) {\n                    // write result\n                    {\n                        ((volatile __local int32_t *) local_mem_13069)[sext_i32_i64(local_tid_13063)] = eta_p_13096;\n                        eta_p_13097 = eta_p_13096;\n                    }\n                }\n                if (sle32(wave_sizze_13065, skip_threads_13116)) {\n                    barrier(CL",
                                    "K_LOCAL_MEM_FENCE);\n                }\n                skip_threads_13116 *= 2;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // last thread of block 'i' writes its result to offset 'i'\n        {\n            if ((local_tid_13063 - squot32(local_tid_13063, 32) * 32) == 31 && ltid_in_bounds_13115) {\n                ((volatile __local int32_t *) local_mem_13069)[sext_i32_i64(squot32(local_tid_13063, 32))] = eta_p_13096;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n        {\n            int32_t skip_threads_13118;\n            \n            // read input for in-block scan\n            {\n                if (squot32(local_tid_13063, 32) == 0 && ltid_in_bounds_13115) {\n                    eta_p_13107 = ((volatile __local int32_t *) local_mem_13069)[sext_i32_i64(local_tid_13063)];\n                    if ((local_tid_13063 - squot32(local_tid_13063, 32) * 32) == 0) {\n                        eta_p_13106 = eta_p_13107;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_13118 = 1;\n                while (slt32(skip_threads_13118, 32)) {\n                    bool thread_active_13119 = sle32(skip_threads_13118, local_tid_13063 - squot32(local_tid_13063, 32) * 32) && (squot32(local_tid_13063, 32) == 0 && ltid_in_bounds_13115);\n                    \n                    if (thread_active_13119) {\n                        // read operands\n                        {\n                            eta_p_13106 = ((volatile __local int32_t *) local_mem_13069)[sext_i32_i64(local_tid_13063) - sext_i32_i64(skip_threads_13118)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_13119) {\n                            int32_t za_lhs_13108 = eta_p_13106 & eta_p_13107;\n       ", "                     int32_t zb_lhs_13109 = 2 & za_lhs_13108;\n                            int32_t za_rhs_13110 = lshr32(eta_p_13107, 1);\n                            int32_t zb_lhs_13111 = eta_p_13106 & za_rhs_13110;\n                            int32_t za_lhs_13112 = eta_p_13107 | zb_lhs_13111;\n                            int32_t zb_rhs_13113 = 1 & za_lhs_13112;\n                            int32_t carry_prop_res_13114 = zb_lhs_13109 | zb_rhs_13113;\n                            \n                            eta_p_13106 = carry_prop_res_13114;\n                        }\n                    }\n                    if (sle32(wave_sizze_13065, skip_threads_13118)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_13119) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_13069)[sext_i32_i64(local_tid_13063)] = eta_p_13106;\n                            eta_p_13107 = eta_p_13106;\n                        }\n                    }\n                    if (sle32(wave_sizze_13065, skip_threads_13118)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_13118 *= 2;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        \n        bool no_carry_in_13120 = squot32(local_tid_13063, 32) == 0 || !ltid_in_bounds_13115;\n        \n        // carry-in for every block except the first\n        {\n            // read operands\n            {\n                if (!no_carry_in_13120) {\n                    eta_p_13097 = eta_p_13096;\n                    eta_p_13096 = ((__local int32_t *) local_mem_13069)[sext_i32_i64(squot32(local_tid_13063, 32)) - (int64_t) 1];\n                }\n            }\n            // perform operation\n            {\n                if (!no_carry_in_13120) {\n                    int32_t za_lhs_13098 = eta_p_13096 & eta_p_13097;\n                    int", "32_t zb_lhs_13099 = 2 & za_lhs_13098;\n                    int32_t za_rhs_13100 = lshr32(eta_p_13097, 1);\n                    int32_t zb_lhs_13101 = eta_p_13096 & za_rhs_13100;\n                    int32_t za_lhs_13102 = eta_p_13097 | zb_lhs_13101;\n                    int32_t zb_rhs_13103 = 1 & za_lhs_13102;\n                    int32_t carry_prop_res_13104 = zb_lhs_13099 | zb_rhs_13103;\n                    \n                    eta_p_13096 = carry_prop_res_13104;\n                }\n            }\n            // write final result\n            {\n                if (!no_carry_in_13120) {\n                    ((__local int32_t *) local_mem_13069)[sext_i32_i64(local_tid_13063)] = eta_p_13096;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // restore correct values for first block\n        {\n            if (squot32(local_tid_13063, 32) == 0 && ltid_in_bounds_13115) {\n                ((__local int32_t *) local_mem_13069)[sext_i32_i64(local_tid_13063)] = eta_p_13097;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_tid_13063 == 0) {\n            acc_13105 = ((__local int32_t *) local_mem_13069)[segscan_group_sizze_11872 - (int64_t) 1];\n        } else {\n            acc_13105 = ((__local int32_t *) local_mem_13069)[sext_i32_i64(local_tid_13063) - (int64_t) 1];\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    prefix_13121 = 2;\n    block_new_sgm_13122 = sgm_idx_13078 == (int64_t) 0;\n    // Perform lookback\n    {\n        if (block_new_sgm_13122 && local_tid_13063 == 0) {\n            ((volatile __global int32_t *) incprefixes_mem_13040)[dynamic_id_13076] = acc_13105;\n            mem_fence_global();\n            ((volatile __global int8_t *) status_flags_mem_13036)[dynamic_id_13076] = (int8_t) 2;\n            acc_13105 = 2;\n        }\n        if (!block_new_sgm_13122 && slt32(local_tid_13063, wave_sizze_13065)) {\n            if (local_tid_13063 == 0) {\n                ((vola",
                                    "tile __global int32_t *) aggregates_mem_13038)[dynamic_id_13076] = acc_13105;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_13036)[dynamic_id_13076] = (int8_t) 1;\n                \n                int8_t tmp_13123 = ((volatile __global int8_t *) status_flags_mem_13036)[dynamic_id_13076 - (int64_t) 1];\n                \n                ((volatile __local int8_t *) local_mem_13069)[(int64_t) 0] = tmp_13123;\n            }\n            mem_fence_local();\n            \n            int8_t status_13124 = ((__local int8_t *) local_mem_13069)[(int64_t) 0];\n            \n            if (status_13124 == (int8_t) 2) {\n                if (local_tid_13063 == 0) {\n                    prefix_13121 = ((volatile __global int32_t *) incprefixes_mem_13040)[dynamic_id_13076 - (int64_t) 1];\n                }\n            } else {\n                int32_t readOffset_13125 = dynamic_id_13076 - sext_i32_i64(wave_sizze_13065);\n                \n                while (slt32(wave_sizze_13065 * -1, readOffset_13125)) {\n                    int32_t read_i_13126 = readOffset_13125 + local_tid_13063;\n                    int32_t aggr_13127 = 2;\n                    int8_t flag_13128 = (int8_t) 0;\n                    \n                    if (sle32(0, read_i_13126)) {\n                        flag_13128 = ((volatile __global int8_t *) status_flags_mem_13036)[sext_i32_i64(read_i_13126)];\n                        if (flag_13128 == (int8_t) 2) {\n                            aggr_13127 = ((volatile __global int32_t *) incprefixes_mem_13040)[sext_i32_i64(read_i_13126)];\n                        } else if (flag_13128 == (int8_t) 1) {\n                            aggr_13127 = ((volatile __global int32_t *) aggregates_mem_13038)[sext_i32_i64(read_i_13126)];\n                        }\n                    }\n                    ((__local int32_t *) local_mem_13069)[(int64_t) 8 + sext_i32_i64(local_tid_13063)] = aggr_13127;\n                    ((__local int8_t *) local_mem_13", "069)[sext_i32_i64(local_tid_13063)] = flag_13128;\n                    flag_13128 = ((__local int8_t *) local_mem_13069)[sext_i32_i64(wave_sizze_13065) - (int64_t) 1];\n                    if (slt8(flag_13128, (int8_t) 2)) {\n                        int8_t flg_x_13138;\n                        int8_t flg_y_13139;\n                        int32_t eta_p_13129;\n                        int32_t eta_p_13130;\n                        int32_t skip_threads_13140;\n                        \n                        // read input for in-block scan\n                        {\n                            flg_y_13139 = ((volatile __local int8_t *) local_mem_13069)[sext_i32_i64(local_tid_13063)];\n                            eta_p_13130 = ((volatile __local int32_t *) local_mem_13069)[(int64_t) 8 + sext_i32_i64(local_tid_13063)];\n                            if ((local_tid_13063 - squot32(local_tid_13063, 32) * 32) == 0) {\n                                eta_p_13129 = eta_p_13130;\n                                flg_x_13138 = flg_y_13139;\n                            }\n                        }\n                        // in-block scan (hopefully no barriers needed)\n                        {\n                            skip_threads_13140 = 1;\n                            while (slt32(skip_threads_13140, 32)) {\n                                if (sle32(skip_threads_13140, local_tid_13063 - squot32(local_tid_13063, 32) * 32)) {\n                                    // read operands\n                                    {\n                                        flg_x_13138 = ((volatile __local int8_t *) local_mem_13069)[sext_i32_i64(local_tid_13063) - sext_i32_i64(skip_threads_13140)];\n                                        eta_p_13129 = ((volatile __local int32_t *) local_mem_13069)[(int64_t) 8 + (sext_i32_i64(local_tid_13063) - sext_i32_i64(skip_threads_13140))];\n                                    }\n                                    // perform operation\n                                    {\n      ", "                                  if (flg_y_13139 == (int8_t) 2 || flg_y_13139 == (int8_t) 0) {\n                                            flg_x_13138 = flg_y_13139;\n                                            eta_p_13129 = eta_p_13130;\n                                        } else {\n                                            int32_t za_lhs_13131 = eta_p_13129 & eta_p_13130;\n                                            int32_t zb_lhs_13132 = 2 & za_lhs_13131;\n                                            int32_t za_rhs_13133 = lshr32(eta_p_13130, 1);\n                                            int32_t zb_lhs_13134 = eta_p_13129 & za_rhs_13133;\n                                            int32_t za_lhs_13135 = eta_p_13130 | zb_lhs_13134;\n                                            int32_t zb_rhs_13136 = 1 & za_lhs_13135;\n                                            int32_t carry_prop_res_13137 = zb_lhs_13132 | zb_rhs_13136;\n                                            \n                                            eta_p_13129 = carry_prop_res_13137;\n                                        }\n                                    }\n                                    // write result\n                                    {\n                                        ((volatile __local int8_t *) local_mem_13069)[sext_i32_i64(local_tid_13063)] = flg_x_13138;\n                                        flg_y_13139 = flg_x_13138;\n                                        ((volatile __local int32_t *) local_mem_13069)[(int64_t) 8 + sext_i32_i64(local_tid_13063)] = eta_p_13129;\n                                        eta_p_13130 = eta_p_13129;\n                                    }\n                                }\n                                skip_threads_13140 *= 2;\n                            }\n                        }\n                    }\n                    flag_13128 = ((__local int8_t *) local_mem_13069)[sext_i32_i64(wave_sizze_13065) - (int64_t) 1];\n                    aggr_13127 =",
                                    " ((__local int32_t *) local_mem_13069)[(int64_t) 8 + (sext_i32_i64(wave_sizze_13065) - (int64_t) 1)];\n                    if (flag_13128 == (int8_t) 2) {\n                        readOffset_13125 = wave_sizze_13065 * -1;\n                    } else if (flag_13128 == (int8_t) 1) {\n                        readOffset_13125 -= wave_sizze_13065;\n                    }\n                    if (slt8((int8_t) 0, flag_13128)) {\n                        int32_t eta_p_13141 = aggr_13127;\n                        int32_t eta_p_13142 = prefix_13121;\n                        int32_t za_lhs_13143 = eta_p_13141 & eta_p_13142;\n                        int32_t zb_lhs_13144 = 2 & za_lhs_13143;\n                        int32_t za_rhs_13145 = lshr32(eta_p_13142, 1);\n                        int32_t zb_lhs_13146 = eta_p_13141 & za_rhs_13145;\n                        int32_t za_lhs_13147 = eta_p_13142 | zb_lhs_13146;\n                        int32_t zb_rhs_13148 = 1 & za_lhs_13147;\n                        int32_t carry_prop_res_13149 = zb_lhs_13144 | zb_rhs_13148;\n                        \n                        prefix_13121 = carry_prop_res_13149;\n                    }\n                    mem_fence_local();\n                }\n            }\n            if (local_tid_13063 == 0) {\n                if (boundary_13079 == sext_i64_i32(segscan_group_sizze_11872 * (int64_t) 23)) {\n                    int32_t eta_p_13150 = prefix_13121;\n                    int32_t eta_p_13151 = acc_13105;\n                    int32_t za_lhs_13152 = eta_p_13150 & eta_p_13151;\n                    int32_t zb_lhs_13153 = 2 & za_lhs_13152;\n                    int32_t za_rhs_13154 = lshr32(eta_p_13151, 1);\n                    int32_t zb_lhs_13155 = eta_p_13150 & za_rhs_13154;\n                    int32_t za_lhs_13156 = eta_p_13151 | zb_lhs_13155;\n                    int32_t zb_rhs_13157 = 1 & za_lhs_13156;\n                    int32_t carry_prop_res_13158 = zb_lhs_13153 | zb_rhs_13157;\n                    \n                    ((volati", "le __global int32_t *) incprefixes_mem_13040)[dynamic_id_13076] = carry_prop_res_13158;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_13036)[dynamic_id_13076] = (int8_t) 2;\n                }\n                ((__local int32_t *) local_mem_13069)[(int64_t) 8] = prefix_13121;\n                acc_13105 = 2;\n            }\n        }\n        if (!(dynamic_id_13076 == (int64_t) 0)) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            prefix_13121 = ((__local int32_t *) local_mem_13069)[(int64_t) 8];\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    // Distribute results\n    {\n        int32_t eta_p_13159;\n        int32_t eta_p_13160;\n        int32_t eta_p_13168 = prefix_13121;\n        int32_t eta_p_13169 = acc_13105;\n        \n        if (slt32(local_tid_13063 * 23, boundary_13079) && !block_new_sgm_13122) {\n            int32_t za_lhs_13170 = eta_p_13168 & eta_p_13169;\n            int32_t zb_lhs_13171 = 2 & za_lhs_13170;\n            int32_t za_rhs_13172 = lshr32(eta_p_13169, 1);\n            int32_t zb_lhs_13173 = eta_p_13168 & za_rhs_13172;\n            int32_t za_lhs_13174 = eta_p_13169 | zb_lhs_13173;\n            int32_t zb_rhs_13175 = 1 & za_lhs_13174;\n            int32_t carry_prop_res_13176 = zb_lhs_13171 | zb_rhs_13175;\n            \n            eta_p_13159 = carry_prop_res_13176;\n        } else {\n            eta_p_13159 = acc_13105;\n        }\n        \n        int32_t stopping_point_13177 = segsizze_compact_13080 - srem32(local_tid_13063 * 23 - 1 + segsizze_compact_13080 - boundary_13079, segsizze_compact_13080);\n        \n        for (int64_t i_13178 = 0; i_13178 < (int64_t) 23; i_13178++) {\n            if (slt32(sext_i64_i32(i_13178), stopping_point_13177 - 1)) {\n                eta_p_13160 = private_mem_13081[i_13178];\n                \n                int32_t za_lhs_13161 = eta_p_13159 & eta_p_13160;\n                int32_t zb_lhs_13162 = 2 & za_lhs_13161;\n                int32_t za_rhs_13163 = ", "lshr32(eta_p_13160, 1);\n                int32_t zb_lhs_13164 = eta_p_13159 & za_rhs_13163;\n                int32_t za_lhs_13165 = eta_p_13160 | zb_lhs_13164;\n                int32_t zb_rhs_13166 = 1 & za_lhs_13165;\n                int32_t carry_prop_res_13167 = zb_lhs_13162 | zb_rhs_13166;\n                \n                private_mem_13081[i_13178] = carry_prop_res_13167;\n            }\n        }\n    }\n    // Transpose scan output and Write it to global memory in coalesced fashion\n    {\n        for (int64_t i_13179 = 0; i_13179 < (int64_t) 23; i_13179++) {\n            int64_t sharedIdx_13180 = sext_i32_i64(local_tid_13063 * 23) + i_13179;\n            int32_t tmp_13181 = private_mem_13081[i_13179];\n            \n            ((__local int32_t *) local_mem_13069)[sharedIdx_13180] = tmp_13181;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int64_t i_13182 = 0; i_13182 < (int64_t) 23; i_13182++) {\n            int64_t flat_idx_13183 = blockOff_13077 + segscan_group_sizze_11872 * i_13182 + sext_i32_i64(local_tid_13063);\n            int64_t slice_13184 = conc_tmp_11253;\n            int64_t gtid_11876 = flat_idx_13183;\n            int64_t remnant_13185 = flat_idx_13183 - gtid_11876;\n            \n            if (slt64(flat_idx_13183, conc_tmp_11253)) {\n                int32_t tmp_13186 = ((__local int32_t *) local_mem_13069)[flat_idx_13183 - blockOff_13077];\n                \n                ((__global int32_t *) mem_12944)[gtid_11876] = tmp_13186;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // If this is the last block, reset the dynamicId\n    {\n        if (dynamic_id_13076 == num_groups_13012 - (int64_t) 1) {\n            ((__global int32_t *) id_counter_mem_13014)[(int64_t) 0] = 0;\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_group_sizze_11872\n}\nFUTHARK_KERNEL_SIZED(1, 1, 1)\nvoid big_mul_debugzigpuseq_13027(__global int *global_failure, __global unsigned char *bs_mem_12914, __global unsigned char *mem_12938)\n{\n    if ",
                                    "(*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13029;\n    int64_t group_sizze_13032;\n    int32_t wave_sizze_13031;\n    int32_t group_tid_13030;\n    int32_t global_tid_13028;\n    int32_t tid_13027;\n    int64_t computeIter64_arg1_12910;\n    \n    local_tid_13029 = get_local_id(0);\n    group_sizze_13032 = get_local_size(0);\n    wave_sizze_13031 = LOCKSTEP_WIDTH;\n    group_tid_13030 = get_group_id(0);\n    global_tid_13028 = group_tid_13030 * group_sizze_13032 + local_tid_13029;\n    tid_13027 = global_tid_13028;\n    computeIter64_arg1_12910 = ((__global int64_t *) bs_mem_12914)[(int64_t) 0];\n    ((__global int64_t *) mem_12938)[(int64_t) 0] = computeIter64_arg1_12910;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(big_mul_debugzisegmap_group_sizze_12453, 1, 1)\nvoid big_mul_debugzisegmap_12635(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t n_10772, int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, int32_t zm_lhs_11194, __global unsigned char *as_mem_12913, __global unsigned char *bs_mem_12914, __global unsigned char *mem_12938, __global unsigned char *mem_12942, __global unsigned char *mem_12945, __global unsigned char *mem_12948, __global unsigned char *mem_12951, __global unsigned char *mem_12954, __global unsigned char *mem_12957, __global unsigned char *mem_12960, __global unsigned char *mem_12963)\n{\n    #define segmap_group_sizze_12624 (big_mul_debugzisegmap_group_sizze_12453)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13035;\n    int64_t group_sizze_13038;\n    int32_t wave_sizze_13037;\n    int32_t group_tid_13036;\n    int32_t global_tid_13034;\n    int32_t phys_tid_12635;\n    int64_t global_tid_13039;\n    int64_t slice_13040;\n    int64_t gtid_12634;\n    int64_t remnant_13041;\n    \n    local_tid_13035 = get_local_id(0);\n    group_sizze_13038 = get_local_size(0);\n    wave_sizze_13037 = LOCKSTEP_WIDTH;\n    group_tid_13036 = get_group_id(0);\n    global_tid_13034 = group_", "tid_13036 * group_sizze_13038 + local_tid_13035;\n    phys_tid_12635 = global_tid_13034;\n    global_tid_13039 = sext_i32_i64(group_tid_13036) * segmap_group_sizze_12624 + sext_i32_i64(local_tid_13035);\n    slice_13040 = n_10772;\n    gtid_12634 = global_tid_13039;\n    remnant_13041 = global_tid_13039 - gtid_12634;\n    if (slt64(gtid_12634, n_10772)) {\n        int32_t i64_res_12637;\n        int32_t k1_12638;\n        int32_t upper_bound_12639;\n        int64_t computeIter64_arg0_12693;\n        bool x_12694;\n        bool y_12695;\n        bool bounds_check_12696;\n        bool index_certs_12697;\n        int32_t zm_lhs_12719;\n        int32_t k2_12720;\n        int32_t upper_bound_12721;\n        int64_t computeIter64_arg0_12775;\n        bool x_12776;\n        bool y_12777;\n        bool bounds_check_12778;\n        bool index_certs_12779;\n        int64_t computeIter64_arg1_12912;\n        int64_t convulution4_res_12640;\n        int64_t convulution4_res_12641;\n        int32_t convulution4_res_12642;\n        int64_t convulution4_res_12643;\n        int64_t convulution4_res_12644;\n        int32_t convulution4_res_12645;\n        int64_t lhc0_12647;\n        int64_t lhc0_12648;\n        int32_t lhc0_12649;\n        int64_t lhc1_12650;\n        int64_t lhc1_12651;\n        int32_t lhc1_12652;\n        int64_t computeIter64_arg0_12698;\n        int64_t ck_l_12699;\n        int64_t n_l_12700;\n        bool zbzg_lhs_12701;\n        int64_t unsign_arg0_12702;\n        int64_t n_h_12703;\n        int64_t unsign_arg0_12704;\n        int64_t n_h_12705;\n        bool zbzg_lhs_12706;\n        int32_t unsign_arg0_12707;\n        int32_t n_c_12708;\n        int64_t n_l_12709;\n        bool zbzg_lhs_12710;\n        int64_t unsign_arg0_12711;\n        int64_t u32_res_12712;\n        int64_t zp_lhs_12713;\n        int64_t n_h_12714;\n        bool zbzg_lhs_12715;\n        int64_t unsign_arg0_12716;\n        int64_t u32_res_12717;\n        int64_t n_c_12718;\n        int64_t convulution4_res_12722;\n        int64_t convulution4_re", "s_12723;\n        int32_t convulution4_res_12724;\n        int64_t convulution4_res_12725;\n        int64_t convulution4_res_12726;\n        int32_t convulution4_res_12727;\n        int64_t lhc2_12729;\n        int64_t lhc2_12730;\n        int32_t lhc2_12731;\n        int64_t lhc3_12732;\n        int64_t lhc3_12733;\n        int32_t lhc3_12734;\n        int64_t computeIter64_arg0_12780;\n        int64_t ck_l_12781;\n        int64_t n_l_12782;\n        bool zbzg_lhs_12783;\n        int64_t unsign_arg0_12784;\n        int64_t n_h_12785;\n        int64_t unsign_arg0_12786;\n        int64_t n_h_12787;\n        bool zbzg_lhs_12788;\n        int32_t unsign_arg0_12789;\n        int32_t n_c_12790;\n        int64_t n_l_12791;\n        bool zbzg_lhs_12792;\n        int64_t unsign_arg0_12793;\n        int64_t u32_res_12794;\n        int64_t zp_lhs_12795;\n        int64_t n_h_12796;\n        bool zbzg_lhs_12797;\n        int64_t unsign_arg0_12798;\n        int64_t u32_res_12799;\n        int64_t n_c_12800;\n        \n        i64_res_12637 = sext_i64_i32(gtid_12634);\n        k1_12638 = mul32(2, i64_res_12637);\n        upper_bound_12639 = add32(1, k1_12638);\n        computeIter64_arg0_12693 = sext_i32_i64(upper_bound_12639);\n        x_12694 = sle64((int64_t) 0, computeIter64_arg0_12693);\n        y_12695 = slt64(computeIter64_arg0_12693, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n        bounds_check_12696 = x_12694 && y_12695;\n        if (!bounds_check_12696) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 10) == -1) {\n                    global_failure_args[0] = (int64_t) computeIter64_arg0_12693;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n                    ;\n                }\n                return;\n            }\n        }\n        zm_lhs_12719 = sub32(zm_lhs_11194, k1_12638);\n        k2_12720 = sub32(zm_lhs_12719, 2);\n        upper_bound_12721 = add32(1, k2_12720);\n        computeIter64_arg0_12775 = sext_i32_i64(upper_bound_12721);",
                                    "\n        x_12776 = sle64((int64_t) 0, computeIter64_arg0_12775);\n        y_12777 = slt64(computeIter64_arg0_12775, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n        bounds_check_12778 = x_12776 && y_12777;\n        if (!bounds_check_12778) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 11) == -1) {\n                    global_failure_args[0] = (int64_t) computeIter64_arg0_12775;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n                    ;\n                }\n                return;\n            }\n        }\n        computeIter64_arg1_12912 = ((__global int64_t *) mem_12938)[(int64_t) 0];\n        lhc0_12647 = (int64_t) 0;\n        lhc0_12648 = (int64_t) 0;\n        lhc0_12649 = 0;\n        lhc1_12650 = (int64_t) 0;\n        lhc1_12651 = (int64_t) 0;\n        lhc1_12652 = 0;\n        for (int32_t kk_12646 = 0; kk_12646 < upper_bound_12639; kk_12646++) {\n            int32_t j_12653;\n            int64_t j_12654;\n            bool x_12655;\n            bool y_12656;\n            bool bounds_check_12657;\n            bool index_certs_12658;\n            int64_t i_12660;\n            bool x_12661;\n            bool y_12662;\n            bool bounds_check_12663;\n            bool index_certs_12664;\n            int32_t computeIter64_arg1_12676;\n            int64_t computeIter64_arg1_12677;\n            bool x_12678;\n            bool y_12679;\n            bool bounds_check_12680;\n            bool index_certs_12681;\n            int64_t computeIter64_arg1_12659;\n            int64_t computeIter64_arg0_12665;\n            int64_t ck_l_12666;\n            int64_t n_l_12667;\n            bool zbzg_lhs_12668;\n            int64_t unsign_arg0_12669;\n            int64_t n_h_12670;\n            int64_t unsign_arg0_12671;\n            int64_t n_h_12672;\n            bool zbzg_lhs_12673;\n            int32_t unsign_arg0_12674;\n            int32_t n_c_12675;\n            int64_t computeIter64_arg1_12682;\n            int64_t ck_l_12683;\n ", "           int64_t n_l_12684;\n            bool zbzg_lhs_12685;\n            int64_t unsign_arg0_12686;\n            int64_t n_h_12687;\n            int64_t unsign_arg0_12688;\n            int64_t n_h_12689;\n            bool zbzg_lhs_12690;\n            int32_t unsign_arg0_12691;\n            int32_t n_c_12692;\n            int64_t lhc0_tmp_13042;\n            int64_t lhc0_tmp_13043;\n            int32_t lhc0_tmp_13044;\n            int64_t lhc1_tmp_13045;\n            int64_t lhc1_tmp_13046;\n            int32_t lhc1_tmp_13047;\n            \n            j_12653 = sub32(k1_12638, kk_12646);\n            j_12654 = sext_i32_i64(j_12653);\n            x_12655 = sle64((int64_t) 0, j_12654);\n            y_12656 = slt64(j_12654, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n            bounds_check_12657 = x_12655 && y_12656;\n            if (!bounds_check_12657) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 12) == -1) {\n                        global_failure_args[0] = (int64_t) j_12654;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n                        ;\n                    }\n                    return;\n                }\n            }\n            i_12660 = sext_i32_i64(kk_12646);\n            x_12661 = sle64((int64_t) 0, i_12660);\n            y_12662 = slt64(i_12660, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n            bounds_check_12663 = x_12661 && y_12662;\n            if (!bounds_check_12663) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 13) == -1) {\n                        global_failure_args[0] = (int64_t) i_12660;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n                        ;\n                    }\n                    return;\n                }\n            }\n            computeIter64_arg1_12676 = add32(1, j_12653);\n            computeIter64_arg1_12677 = sext_i32_i64(computeIter64_arg1_12676);\n      ", "      x_12678 = sle64((int64_t) 0, computeIter64_arg1_12677);\n            y_12679 = slt64(computeIter64_arg1_12677, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n            bounds_check_12680 = x_12678 && y_12679;\n            if (!bounds_check_12680) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 14) == -1) {\n                        global_failure_args[0] = (int64_t) computeIter64_arg1_12677;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n                        ;\n                    }\n                    return;\n                }\n            }\n            computeIter64_arg1_12659 = ((__global int64_t *) bs_mem_12914)[j_12654];\n            computeIter64_arg0_12665 = ((__global int64_t *) as_mem_12913)[i_12660];\n            ck_l_12666 = mul64(computeIter64_arg1_12659, computeIter64_arg0_12665);\n            n_l_12667 = add64(lhc0_12647, ck_l_12666);\n            zbzg_lhs_12668 = ult64(n_l_12667, ck_l_12666);\n            unsign_arg0_12669 = btoi_bool_i64(zbzg_lhs_12668);\n            n_h_12670 = add64(lhc0_12648, unsign_arg0_12669);\n            unsign_arg0_12671 = futrts_umul_hi64(computeIter64_arg0_12665, computeIter64_arg1_12659);\n            n_h_12672 = add64(n_h_12670, unsign_arg0_12671);\n            zbzg_lhs_12673 = ult64(n_h_12672, unsign_arg0_12671);\n            unsign_arg0_12674 = btoi_bool_i32(zbzg_lhs_12673);\n            n_c_12675 = add32(lhc0_12649, unsign_arg0_12674);\n            computeIter64_arg1_12682 = ((__global int64_t *) bs_mem_12914)[computeIter64_arg1_12677];\n            ck_l_12683 = mul64(computeIter64_arg0_12665, computeIter64_arg1_12682);\n            n_l_12684 = add64(lhc1_12650, ck_l_12683);\n            zbzg_lhs_12685 = ult64(n_l_12684, ck_l_12683);\n            unsign_arg0_12686 = btoi_bool_i64(zbzg_lhs_12685);\n            n_h_12687 = add64(lhc1_12651, unsign_arg0_12686);\n            unsign_arg0_12688 = futrts_umul_hi64(computeIter64_arg0_12665, computeIter64_arg",
                                    "1_12682);\n            n_h_12689 = add64(n_h_12687, unsign_arg0_12688);\n            zbzg_lhs_12690 = ult64(n_h_12689, unsign_arg0_12688);\n            unsign_arg0_12691 = btoi_bool_i32(zbzg_lhs_12690);\n            n_c_12692 = add32(lhc1_12652, unsign_arg0_12691);\n            lhc0_tmp_13042 = n_l_12667;\n            lhc0_tmp_13043 = n_h_12672;\n            lhc0_tmp_13044 = n_c_12675;\n            lhc1_tmp_13045 = n_l_12684;\n            lhc1_tmp_13046 = n_h_12689;\n            lhc1_tmp_13047 = n_c_12692;\n            lhc0_12647 = lhc0_tmp_13042;\n            lhc0_12648 = lhc0_tmp_13043;\n            lhc0_12649 = lhc0_tmp_13044;\n            lhc1_12650 = lhc1_tmp_13045;\n            lhc1_12651 = lhc1_tmp_13046;\n            lhc1_12652 = lhc1_tmp_13047;\n        }\n        convulution4_res_12640 = lhc0_12647;\n        convulution4_res_12641 = lhc0_12648;\n        convulution4_res_12642 = lhc0_12649;\n        convulution4_res_12643 = lhc1_12650;\n        convulution4_res_12644 = lhc1_12651;\n        convulution4_res_12645 = lhc1_12652;\n        computeIter64_arg0_12698 = ((__global int64_t *) as_mem_12913)[computeIter64_arg0_12693];\n        ck_l_12699 = mul64(computeIter64_arg0_12698, computeIter64_arg1_12912);\n        n_l_12700 = add64(convulution4_res_12643, ck_l_12699);\n        zbzg_lhs_12701 = ult64(n_l_12700, ck_l_12699);\n        unsign_arg0_12702 = btoi_bool_i64(zbzg_lhs_12701);\n        n_h_12703 = add64(convulution4_res_12644, unsign_arg0_12702);\n        unsign_arg0_12704 = futrts_umul_hi64(computeIter64_arg0_12698, computeIter64_arg1_12912);\n        n_h_12705 = add64(n_h_12703, unsign_arg0_12704);\n        zbzg_lhs_12706 = ult64(n_h_12705, unsign_arg0_12704);\n        unsign_arg0_12707 = btoi_bool_i32(zbzg_lhs_12706);\n        n_c_12708 = add32(convulution4_res_12645, unsign_arg0_12707);\n        n_l_12709 = add64(convulution4_res_12641, n_l_12700);\n        zbzg_lhs_12710 = ult64(n_l_12709, convulution4_res_12641);\n        unsign_arg0_12711 = btoi_bool_i64(zbzg_lhs_12710);\n        u32_r", "es_12712 = zext_i32_i64(convulution4_res_12642);\n        zp_lhs_12713 = add64(n_h_12705, u32_res_12712);\n        n_h_12714 = add64(unsign_arg0_12711, zp_lhs_12713);\n        zbzg_lhs_12715 = ult64(n_h_12714, n_h_12705);\n        unsign_arg0_12716 = btoi_bool_i64(zbzg_lhs_12715);\n        u32_res_12717 = zext_i32_i64(n_c_12708);\n        n_c_12718 = add64(unsign_arg0_12716, u32_res_12717);\n        lhc2_12729 = (int64_t) 0;\n        lhc2_12730 = (int64_t) 0;\n        lhc2_12731 = 0;\n        lhc3_12732 = (int64_t) 0;\n        lhc3_12733 = (int64_t) 0;\n        lhc3_12734 = 0;\n        for (int32_t kk_12728 = 0; kk_12728 < upper_bound_12721; kk_12728++) {\n            int32_t j_12735;\n            int64_t j_12736;\n            bool x_12737;\n            bool y_12738;\n            bool bounds_check_12739;\n            bool index_certs_12740;\n            int64_t i_12742;\n            bool x_12743;\n            bool y_12744;\n            bool bounds_check_12745;\n            bool index_certs_12746;\n            int32_t computeIter64_arg1_12758;\n            int64_t computeIter64_arg1_12759;\n            bool x_12760;\n            bool y_12761;\n            bool bounds_check_12762;\n            bool index_certs_12763;\n            int64_t computeIter64_arg1_12741;\n            int64_t computeIter64_arg0_12747;\n            int64_t ck_l_12748;\n            int64_t n_l_12749;\n            bool zbzg_lhs_12750;\n            int64_t unsign_arg0_12751;\n            int64_t n_h_12752;\n            int64_t unsign_arg0_12753;\n            int64_t n_h_12754;\n            bool zbzg_lhs_12755;\n            int32_t unsign_arg0_12756;\n            int32_t n_c_12757;\n            int64_t computeIter64_arg1_12764;\n            int64_t ck_l_12765;\n            int64_t n_l_12766;\n            bool zbzg_lhs_12767;\n            int64_t unsign_arg0_12768;\n            int64_t n_h_12769;\n            int64_t unsign_arg0_12770;\n            int64_t n_h_12771;\n            bool zbzg_lhs_12772;\n            int32_t unsign_arg0_12773;\n          ", "  int32_t n_c_12774;\n            int64_t lhc2_tmp_13048;\n            int64_t lhc2_tmp_13049;\n            int32_t lhc2_tmp_13050;\n            int64_t lhc3_tmp_13051;\n            int64_t lhc3_tmp_13052;\n            int32_t lhc3_tmp_13053;\n            \n            j_12735 = sub32(k2_12720, kk_12728);\n            j_12736 = sext_i32_i64(j_12735);\n            x_12737 = sle64((int64_t) 0, j_12736);\n            y_12738 = slt64(j_12736, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n            bounds_check_12739 = x_12737 && y_12738;\n            if (!bounds_check_12739) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 15) == -1) {\n                        global_failure_args[0] = (int64_t) j_12736;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n                        ;\n                    }\n                    return;\n                }\n            }\n            i_12742 = sext_i32_i64(kk_12728);\n            x_12743 = sle64((int64_t) 0, i_12742);\n            y_12744 = slt64(i_12742, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n            bounds_check_12745 = x_12743 && y_12744;\n            if (!bounds_check_12745) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 16) == -1) {\n                        global_failure_args[0] = (int64_t) i_12742;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n                        ;\n                    }\n                    return;\n                }\n            }\n            computeIter64_arg1_12758 = add32(1, j_12735);\n            computeIter64_arg1_12759 = sext_i32_i64(computeIter64_arg1_12758);\n            x_12760 = sle64((int64_t) 0, computeIter64_arg1_12759);\n            y_12761 = slt64(computeIter64_arg1_12759, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n            bounds_check_12762 = x_12760 && y_12761;\n            if (!bounds_check_12762) {\n                {\n                    i",
                                    "f (atomic_cmpxchg_i32_global(global_failure, -1, 17) == -1) {\n                        global_failure_args[0] = (int64_t) computeIter64_arg1_12759;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n                        ;\n                    }\n                    return;\n                }\n            }\n            computeIter64_arg1_12741 = ((__global int64_t *) bs_mem_12914)[j_12736];\n            computeIter64_arg0_12747 = ((__global int64_t *) as_mem_12913)[i_12742];\n            ck_l_12748 = mul64(computeIter64_arg1_12741, computeIter64_arg0_12747);\n            n_l_12749 = add64(lhc2_12729, ck_l_12748);\n            zbzg_lhs_12750 = ult64(n_l_12749, ck_l_12748);\n            unsign_arg0_12751 = btoi_bool_i64(zbzg_lhs_12750);\n            n_h_12752 = add64(lhc2_12730, unsign_arg0_12751);\n            unsign_arg0_12753 = futrts_umul_hi64(computeIter64_arg0_12747, computeIter64_arg1_12741);\n            n_h_12754 = add64(n_h_12752, unsign_arg0_12753);\n            zbzg_lhs_12755 = ult64(n_h_12754, unsign_arg0_12753);\n            unsign_arg0_12756 = btoi_bool_i32(zbzg_lhs_12755);\n            n_c_12757 = add32(lhc2_12731, unsign_arg0_12756);\n            computeIter64_arg1_12764 = ((__global int64_t *) bs_mem_12914)[computeIter64_arg1_12759];\n            ck_l_12765 = mul64(computeIter64_arg0_12747, computeIter64_arg1_12764);\n            n_l_12766 = add64(lhc3_12732, ck_l_12765);\n            zbzg_lhs_12767 = ult64(n_l_12766, ck_l_12765);\n            unsign_arg0_12768 = btoi_bool_i64(zbzg_lhs_12767);\n            n_h_12769 = add64(lhc3_12733, unsign_arg0_12768);\n            unsign_arg0_12770 = futrts_umul_hi64(computeIter64_arg0_12747, computeIter64_arg1_12764);\n            n_h_12771 = add64(n_h_12769, unsign_arg0_12770);\n            zbzg_lhs_12772 = ult64(n_h_12771, unsign_arg0_12770);\n            unsign_arg0_12773 = btoi_bool_i32(zbzg_lhs_12772);\n            n_c_12774 = add32(lhc3_12734, unsign_arg0_12773);\n            lhc2_tmp_13", "048 = n_l_12749;\n            lhc2_tmp_13049 = n_h_12754;\n            lhc2_tmp_13050 = n_c_12757;\n            lhc3_tmp_13051 = n_l_12766;\n            lhc3_tmp_13052 = n_h_12771;\n            lhc3_tmp_13053 = n_c_12774;\n            lhc2_12729 = lhc2_tmp_13048;\n            lhc2_12730 = lhc2_tmp_13049;\n            lhc2_12731 = lhc2_tmp_13050;\n            lhc3_12732 = lhc3_tmp_13051;\n            lhc3_12733 = lhc3_tmp_13052;\n            lhc3_12734 = lhc3_tmp_13053;\n        }\n        convulution4_res_12722 = lhc2_12729;\n        convulution4_res_12723 = lhc2_12730;\n        convulution4_res_12724 = lhc2_12731;\n        convulution4_res_12725 = lhc3_12732;\n        convulution4_res_12726 = lhc3_12733;\n        convulution4_res_12727 = lhc3_12734;\n        computeIter64_arg0_12780 = ((__global int64_t *) as_mem_12913)[computeIter64_arg0_12775];\n        ck_l_12781 = mul64(computeIter64_arg0_12780, computeIter64_arg1_12912);\n        n_l_12782 = add64(convulution4_res_12725, ck_l_12781);\n        zbzg_lhs_12783 = ult64(n_l_12782, ck_l_12781);\n        unsign_arg0_12784 = btoi_bool_i64(zbzg_lhs_12783);\n        n_h_12785 = add64(convulution4_res_12726, unsign_arg0_12784);\n        unsign_arg0_12786 = futrts_umul_hi64(computeIter64_arg0_12780, computeIter64_arg1_12912);\n        n_h_12787 = add64(n_h_12785, unsign_arg0_12786);\n        zbzg_lhs_12788 = ult64(n_h_12787, unsign_arg0_12786);\n        unsign_arg0_12789 = btoi_bool_i32(zbzg_lhs_12788);\n        n_c_12790 = add32(convulution4_res_12727, unsign_arg0_12789);\n        n_l_12791 = add64(convulution4_res_12723, n_l_12782);\n        zbzg_lhs_12792 = ult64(n_l_12791, convulution4_res_12723);\n        unsign_arg0_12793 = btoi_bool_i64(zbzg_lhs_12792);\n        u32_res_12794 = zext_i32_i64(convulution4_res_12724);\n        zp_lhs_12795 = add64(n_h_12787, u32_res_12794);\n        n_h_12796 = add64(unsign_arg0_12793, zp_lhs_12795);\n        zbzg_lhs_12797 = ult64(n_h_12796, n_h_12787);\n        unsign_arg0_12798 = btoi_bool_i64(zbzg_lhs_12797);\n       ", " u32_res_12799 = zext_i32_i64(n_c_12790);\n        n_c_12800 = add64(unsign_arg0_12798, u32_res_12799);\n        ((__global int64_t *) mem_12942)[gtid_12634] = convulution4_res_12640;\n        ((__global int64_t *) mem_12945)[gtid_12634] = n_l_12709;\n        ((__global int64_t *) mem_12948)[gtid_12634] = n_h_12714;\n        ((__global int64_t *) mem_12951)[gtid_12634] = n_c_12718;\n        ((__global int64_t *) mem_12954)[gtid_12634] = convulution4_res_12722;\n        ((__global int64_t *) mem_12957)[gtid_12634] = n_l_12791;\n        ((__global int64_t *) mem_12960)[gtid_12634] = n_h_12796;\n        ((__global int64_t *) mem_12963)[gtid_12634] = n_c_12800;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_12624\n}\nFUTHARK_KERNEL_SIZED(big_mul_debugzisegmap_group_sizze_12804, 1, 1)\nvoid big_mul_debugzisegmap_12802(__global int *global_failure, int64_t n_10772, int64_t dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, int64_t w_minus_1_11403, __global unsigned char *mem_12918, __global unsigned char *mem_12921, __global unsigned char *mem_12924, __global unsigned char *mem_12927, __global unsigned char *mem_12942, __global unsigned char *mem_12948, __global unsigned char *mem_12954, __global unsigned char *mem_12960)\n{\n    #define segmap_group_sizze_12805 (big_mul_debugzisegmap_group_sizze_12804)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13056;\n    int64_t group_sizze_13059;\n    int32_t wave_sizze_13058;\n    int32_t group_tid_13057;\n    int32_t global_tid_13055;\n    int32_t phys_tid_12802;\n    int64_t global_tid_13060;\n    int64_t slice_13061;\n    int64_t write_i_12801;\n    int64_t remnant_13062;\n    \n    local_tid_13056 = get_local_id(0);\n    group_sizze_13059 = get_local_size(0);\n    wave_sizze_13058 = LOCKSTEP_WIDTH;\n    group_tid_13057 = get_group_id(0);\n    global_tid_13055 = group_tid_13057 * group_sizze_13059 + local_tid_13056;\n    phys_tid_12802 = global_tid_13055;\n    global_tid_13060 = sext_i32_i64(group_tid_13057) * segmap_group_sizze",
                                    "_12805 + sext_i32_i64(local_tid_13056);\n    slice_13061 = n_10772;\n    write_i_12801 = global_tid_13060;\n    remnant_13062 = global_tid_13060 - write_i_12801;\n    if (slt64(write_i_12801, n_10772)) {\n        int64_t slice_12904;\n        int64_t write_value_11670;\n        int64_t write_value_11672;\n        int64_t write_value_11674;\n        int64_t write_value_11676;\n        int64_t lifted_lambda_res_11677;\n        \n        slice_12904 = w_minus_1_11403 - write_i_12801;\n        write_value_11670 = ((__global int64_t *) mem_12960)[slice_12904];\n        write_value_11672 = ((__global int64_t *) mem_12948)[write_i_12801];\n        write_value_11674 = ((__global int64_t *) mem_12954)[slice_12904];\n        write_value_11676 = ((__global int64_t *) mem_12942)[write_i_12801];\n        lifted_lambda_res_11677 = mul64((int64_t) 2, write_i_12801);\n        if (sle64((int64_t) 0, lifted_lambda_res_11677) && slt64(lifted_lambda_res_11677, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12918)[lifted_lambda_res_11677] = write_value_11670;\n        }\n        if (sle64((int64_t) 0, lifted_lambda_res_11677) && slt64(lifted_lambda_res_11677, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12921)[lifted_lambda_res_11677] = write_value_11672;\n        }\n        if (sle64((int64_t) 0, lifted_lambda_res_11677) && slt64(lifted_lambda_res_11677, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12924)[lifted_lambda_res_11677] = write_value_11674;\n        }\n        if (sle64((int64_t) 0, lifted_lambda_res_11677) && slt64(lifted_lambda_res_11677, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12927)[lifted_lambda_res_11677] = write_value_11676;\n        }\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_12805\n}\nFUTHARK_KERNEL_SIZED(big_mul_debugzisegmap_group_sizze_12810, 1, 1)\nvoid big_mul_debugzisegmap_12808(__global int *global_failure, int64_t n_10772, int64_t d", "zlz7bUZLztZRz20U2z20Unz7dUzg_11183, int64_t w_minus_1_11403, __global unsigned char *mem_12918, __global unsigned char *mem_12921, __global unsigned char *mem_12924, __global unsigned char *mem_12927, __global unsigned char *mem_12945, __global unsigned char *mem_12951, __global unsigned char *mem_12957, __global unsigned char *mem_12963)\n{\n    #define segmap_group_sizze_12811 (big_mul_debugzisegmap_group_sizze_12810)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13065;\n    int64_t group_sizze_13068;\n    int32_t wave_sizze_13067;\n    int32_t group_tid_13066;\n    int32_t global_tid_13064;\n    int32_t phys_tid_12808;\n    int64_t global_tid_13069;\n    int64_t slice_13070;\n    int64_t write_i_12807;\n    int64_t remnant_13071;\n    \n    local_tid_13065 = get_local_id(0);\n    group_sizze_13068 = get_local_size(0);\n    wave_sizze_13067 = LOCKSTEP_WIDTH;\n    group_tid_13066 = get_group_id(0);\n    global_tid_13064 = group_tid_13066 * group_sizze_13068 + local_tid_13065;\n    phys_tid_12808 = global_tid_13064;\n    global_tid_13069 = sext_i32_i64(group_tid_13066) * segmap_group_sizze_12811 + sext_i32_i64(local_tid_13065);\n    slice_13070 = n_10772;\n    write_i_12807 = global_tid_13069;\n    remnant_13071 = global_tid_13069 - write_i_12807;\n    if (slt64(write_i_12807, n_10772)) {\n        int64_t slice_12892;\n        int64_t write_value_11717;\n        int64_t write_value_11719;\n        int64_t write_value_11721;\n        int64_t write_value_11723;\n        int64_t zp_lhs_11724;\n        int64_t lifted_lambda_res_11725;\n        \n        slice_12892 = w_minus_1_11403 - write_i_12807;\n        write_value_11717 = ((__global int64_t *) mem_12963)[slice_12892];\n        write_value_11719 = ((__global int64_t *) mem_12951)[write_i_12807];\n        write_value_11721 = ((__global int64_t *) mem_12957)[slice_12892];\n        write_value_11723 = ((__global int64_t *) mem_12945)[write_i_12807];\n        zp_lhs_11724 = mul64((int64_t) 2, write_i_12807);\n        lifted_lambd", "a_res_11725 = add64((int64_t) 1, zp_lhs_11724);\n        if (sle64((int64_t) 0, lifted_lambda_res_11725) && slt64(lifted_lambda_res_11725, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12918)[lifted_lambda_res_11725] = write_value_11717;\n        }\n        if (sle64((int64_t) 0, lifted_lambda_res_11725) && slt64(lifted_lambda_res_11725, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12921)[lifted_lambda_res_11725] = write_value_11719;\n        }\n        if (sle64((int64_t) 0, lifted_lambda_res_11725) && slt64(lifted_lambda_res_11725, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12924)[lifted_lambda_res_11725] = write_value_11721;\n        }\n        if (sle64((int64_t) 0, lifted_lambda_res_11725) && slt64(lifted_lambda_res_11725, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12927)[lifted_lambda_res_11725] = write_value_11723;\n        }\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_12811\n}\nFUTHARK_KERNEL_SIZED(big_mul_debugzisegmap_group_sizze_12816, 1, 1)\nvoid big_mul_debugzisegmap_12834(__global int *global_failure, int64_t dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184, __global unsigned char *mem_12918, __global unsigned char *mem_12921, __global unsigned char *mem_12969)\n{\n    #define segmap_group_sizze_12830 (big_mul_debugzisegmap_group_sizze_12816)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13074;\n    int64_t group_sizze_13077;\n    int32_t wave_sizze_13076;\n    int32_t group_tid_13075;\n    int32_t global_tid_13073;\n    int32_t phys_tid_12834;\n    int64_t global_tid_13078;\n    int64_t slice_13079;\n    int64_t gtid_12833;\n    int64_t remnant_13080;\n    \n    local_tid_13074 = get_local_id(0);\n    group_sizze_13077 = get_local_size(0);\n    wave_sizze_13076 = LOCKSTEP_WIDTH;\n    group_tid_13075 = get_group_id(0);\n    global_t",
                                    "id_13073 = group_tid_13075 * group_sizze_13077 + local_tid_13074;\n    phys_tid_12834 = global_tid_13073;\n    global_tid_13078 = sext_i32_i64(group_tid_13075) * segmap_group_sizze_12830 + sext_i32_i64(local_tid_13074);\n    slice_13079 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184;\n    gtid_12833 = global_tid_13078;\n    remnant_13080 = global_tid_13078 - gtid_12833;\n    if (slt64(gtid_12833, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184)) {\n        int64_t zv_lhs_12836;\n        int64_t tmp_12837;\n        bool index_concat_cmp_12838;\n        int64_t index_concat_branch_12839;\n        \n        zv_lhs_12836 = add64((int64_t) -2, gtid_12833);\n        tmp_12837 = smod64(zv_lhs_12836, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184);\n        index_concat_cmp_12838 = sle64(dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, tmp_12837);\n        if (index_concat_cmp_12838 == 1) {\n            int64_t index_concat_i_12840;\n            int64_t index_concat_12841;\n            \n            index_concat_i_12840 = sub64(tmp_12837, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183);\n            index_concat_12841 = ((__global int64_t *) mem_12918)[index_concat_i_12840];\n            index_concat_branch_12839 = index_concat_12841;\n        } else {\n            int64_t index_concat_12842 = ((__global int64_t *) mem_12921)[tmp_12837];\n            \n            index_concat_branch_12839 = index_concat_12842;\n        }\n        ((__global int64_t *) mem_12969)[gtid_12833] = index_concat_branch_12839;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_12830\n}\nFUTHARK_KERNEL_SIZED(big_mul_debugzisegmap_group_sizze_12862, 1, 1)\nvoid big_mul_debugzisegmap_12860(__global int *global_failure, int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, __global unsigned char *exp_res_mem_12915, __global unsigned char *mem_12930, __global unsigned char *mem_12933, __global unsigned char *mem_12936, __global unsigned char *mem_12980, __global unsigne", "d char *mem_12983, __global unsigned char *mem_12986)\n{\n    #define segmap_group_sizze_12863 (big_mul_debugzisegmap_group_sizze_12862)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13351;\n    int64_t group_sizze_13354;\n    int32_t wave_sizze_13353;\n    int32_t group_tid_13352;\n    int32_t global_tid_13350;\n    int32_t phys_tid_12860;\n    int64_t global_tid_13355;\n    int64_t slice_13356;\n    int64_t write_i_12859;\n    int64_t remnant_13357;\n    \n    local_tid_13351 = get_local_id(0);\n    group_sizze_13354 = get_local_size(0);\n    wave_sizze_13353 = LOCKSTEP_WIDTH;\n    group_tid_13352 = get_group_id(0);\n    global_tid_13350 = group_tid_13352 * group_sizze_13354 + local_tid_13351;\n    phys_tid_12860 = global_tid_13350;\n    global_tid_13355 = sext_i32_i64(group_tid_13352) * segmap_group_sizze_12863 + sext_i32_i64(local_tid_13351);\n    slice_13356 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n    write_i_12859 = global_tid_13355;\n    remnant_13357 = global_tid_13355 - write_i_12859;\n    if (slt64(write_i_12859, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {\n        int64_t c_10811;\n        int64_t offset_10812;\n        int64_t v_10813;\n        int64_t v_10814;\n        bool is_this_one_10816;\n        int64_t this_offset_10817;\n        int64_t total_res_10818;\n        \n        c_10811 = ((__global int64_t *) mem_12983)[write_i_12859];\n        offset_10812 = ((__global int64_t *) mem_12980)[write_i_12859];\n        v_10813 = ((__global int64_t *) exp_res_mem_12915)[write_i_12859];\n        v_10814 = ((__global int64_t *) mem_12986)[write_i_12859];\n        is_this_one_10816 = c_10811 == (int64_t) 0;\n        this_offset_10817 = (int64_t) -1 + offset_10812;\n        if (is_this_one_10816 == 1) {\n            total_res_10818 = this_offset_10817;\n        } else {\n            total_res_10818 = (int64_t) -1;\n        }\n        if (sle64((int64_t) 0, total_res_10818) && slt64(total_res_10818, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {\n            ((__global int64_t *) mem_129", "30)[total_res_10818] = v_10813;\n        }\n        if (sle64((int64_t) 0, total_res_10818) && slt64(total_res_10818, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {\n            ((__global int64_t *) mem_12933)[total_res_10818] = v_10814;\n        }\n        if (sle64((int64_t) 0, total_res_10818) && slt64(total_res_10818, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {\n            ((__global int64_t *) mem_12936)[total_res_10818] = write_i_12859;\n        }\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_12863\n}\nFUTHARK_KERNEL_SIZED(big_mul_debugzisegscan_group_sizze_12844, 1, 1)\nvoid big_mul_debugzisegscan_12850(__global int *global_failure, int64_t local_mem_13138_backing_offset_0, int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, int64_t dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, int64_t num_groups_13081, __global unsigned char *mem_12924, __global unsigned char *mem_12927, __global unsigned char *mem_12969, __global unsigned char *mem_12973, __global unsigned char *mem_12976, __global unsigned char *id_counter_mem_13083, __global unsigned char *status_flags_mem_13105, __global unsigned char *aggregates_mem_13107, __global unsigned char *incprefixes_mem_13109)\n{\n    #define segscan_group_sizze_12845 (big_mul_debugzisegscan_group_sizze_12844)\n    \n    volatile __local unsigned char *local_mem_13138_backing_0 = &local_mem[local_mem_13138_backing_offset_0];\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13132;\n    int64_t group_sizze_13135;\n    int32_t wave_sizze_13134;\n    int32_t group_tid_13133;\n    int32_t global_tid_13131;\n    int32_t phys_tid_12850;\n    int64_t byte_offsets_13136;\n    int64_t warp_byte_offset_13137;\n    __local unsigned char *local_mem_13138;\n    int64_t trans_arr_len_13139;\n    int32_t dynamic_id_13145;\n    int64_t blockOff_13146;\n    int64_t sgm_idx_13147;\n    int32_t boundary_13148;\n    int32_t segsizze_compact_13149;\n    int32_t private_mem_13150[(int64_t) 23];\n    int32_t acc_13174;\n    int32_t prefix_13190;\n    bool block",
                                    "_new_sgm_13191;\n    \n    local_tid_13132 = get_local_id(0);\n    group_sizze_13135 = get_local_size(0);\n    wave_sizze_13134 = LOCKSTEP_WIDTH;\n    group_tid_13133 = get_group_id(0);\n    global_tid_13131 = group_tid_13133 * group_sizze_13135 + local_tid_13132;\n    phys_tid_12850 = global_tid_13131;\n    byte_offsets_13136 = segscan_group_sizze_12845 * (int64_t) 4;\n    warp_byte_offset_13137 = (int64_t) 160;\n    // Allocate reused shared memeory\n    { }\n    local_mem_13138 = (__local unsigned char *) local_mem_13138_backing_0;\n    trans_arr_len_13139 = (int64_t) 23 * segscan_group_sizze_12845;\n    if (local_tid_13132 == 0) {\n        dynamic_id_13145 = atomic_add_i32_global(&((volatile __global int *) id_counter_mem_13083)[(int64_t) 0], (int) 1);\n        ((__local int32_t *) local_mem_13138)[(int64_t) 0] = dynamic_id_13145;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dynamic_id_13145 = ((__local int32_t *) local_mem_13138)[(int64_t) 0];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    blockOff_13146 = sext_i32_i64(dynamic_id_13145) * (int64_t) 23 * segscan_group_sizze_12845;\n    sgm_idx_13147 = smod64(blockOff_13146, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n    boundary_13148 = sext_i64_i32(smin64((int64_t) 23 * segscan_group_sizze_12845, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773 - sgm_idx_13147));\n    segsizze_compact_13149 = sext_i64_i32(smin64((int64_t) 23 * segscan_group_sizze_12845, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773));\n    // Load and map\n    {\n        for (int64_t i_13152 = 0; i_13152 < (int64_t) 23; i_13152++) {\n            int64_t phys_tid_13153 = blockOff_13146 + sext_i32_i64(local_tid_13132) + i_13152 * segscan_group_sizze_12845;\n            int64_t slice_13154 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n            int64_t gtid_12849 = phys_tid_13153;\n            int64_t remnant_13155 = phys_tid_13153 - gtid_12849;\n            \n            if (slt64(phys_tid_13153, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {\n                bool index_concat_cmp_12876 = sle64(dzlz7bUZLztZRz20U2z20Unz7dU", "zg_11183, gtid_12849);\n                int64_t index_concat_branch_12880;\n                \n                if (index_concat_cmp_12876 == 1) {\n                    int64_t index_concat_i_12877 = sub64(gtid_12849, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183);\n                    int64_t index_concat_12878 = ((__global int64_t *) mem_12924)[index_concat_i_12877];\n                    \n                    index_concat_branch_12880 = index_concat_12878;\n                } else {\n                    int64_t index_concat_12879 = ((__global int64_t *) mem_12927)[gtid_12849];\n                    \n                    index_concat_branch_12880 = index_concat_12879;\n                }\n                \n                bool index_concat_cmp_12870 = sle64((int64_t) 2, gtid_12849);\n                int64_t index_concat_branch_12874;\n                \n                if (index_concat_cmp_12870 == 1) {\n                    int64_t index_concat_12872 = ((__global int64_t *) mem_12969)[gtid_12849];\n                    \n                    index_concat_branch_12874 = index_concat_12872;\n                } else {\n                    index_concat_branch_12874 = (int64_t) 0;\n                }\n                \n                int64_t s_11590 = add64(index_concat_branch_12874, index_concat_branch_12880);\n                bool bool_arg0_11591 = ult64(s_11590, index_concat_branch_12880);\n                int32_t unsign_arg0_11592 = btoi_bool_i32(bool_arg0_11591);\n                bool bool_arg0_11593 = s_11590 == (int64_t) -1;\n                int32_t unsign_arg0_11594 = btoi_bool_i32(bool_arg0_11593);\n                int32_t zb_rhs_11595 = shl32(unsign_arg0_11594, 1);\n                int32_t c_11596 = unsign_arg0_11592 | zb_rhs_11595;\n                \n                ((__global int64_t *) mem_12976)[gtid_12849] = s_11590;\n                private_mem_13150[i_13152] = c_11596;\n            } else {\n                private_mem_13150[i_13152] = 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    //", " Transpose scan inputs\n    {\n        for (int64_t i_13156 = 0; i_13156 < (int64_t) 23; i_13156++) {\n            int64_t sharedIdx_13157 = sext_i32_i64(local_tid_13132) + i_13156 * segscan_group_sizze_12845;\n            int32_t tmp_13158 = private_mem_13150[i_13156];\n            \n            ((__local int32_t *) local_mem_13138)[sharedIdx_13157] = tmp_13158;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_13159 = 0; i_13159 < 23; i_13159++) {\n            int32_t sharedIdx_13160 = local_tid_13132 * 23 + i_13159;\n            int32_t tmp_13161 = ((__local int32_t *) local_mem_13138)[sext_i32_i64(sharedIdx_13160)];\n            \n            private_mem_13150[sext_i32_i64(i_13159)] = tmp_13161;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // Per thread scan\n    {\n        int32_t gidx_13162 = local_tid_13132 * 23 + 1;\n        \n        for (int64_t i_13163 = 0; i_13163 < (int64_t) 22; i_13163++) {\n            int32_t eta_p_11517;\n            int32_t eta_p_11518;\n            \n            eta_p_11517 = private_mem_13150[i_13163];\n            eta_p_11518 = private_mem_13150[i_13163 + (int64_t) 1];\n            \n            int32_t za_lhs_11519 = eta_p_11517 & eta_p_11518;\n            int32_t zb_lhs_11520 = 2 & za_lhs_11519;\n            int32_t za_rhs_11521 = lshr32(eta_p_11518, 1);\n            int32_t zb_lhs_11522 = eta_p_11517 & za_rhs_11521;\n            int32_t za_lhs_11523 = eta_p_11518 | zb_lhs_11522;\n            int32_t zb_rhs_11524 = 1 & za_lhs_11523;\n            int32_t carry_prop_res_11525 = zb_lhs_11520 | zb_rhs_11524;\n            \n            private_mem_13150[i_13163 + (int64_t) 1] = carry_prop_res_11525;\n        }\n    }\n    // Publish results in shared memory\n    {\n        int32_t tmp_13164 = private_mem_13150[(int64_t) 22];\n        \n        ((__local int32_t *) local_mem_13138)[sext_i32_i64(local_tid_13132)] = tmp_13164;\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // Scan results (with warp scan)\n    {\n        int32_t eta_p_13",
                                    "165;\n        int32_t eta_p_13166;\n        int32_t eta_p_13175;\n        int32_t eta_p_13176;\n        bool ltid_in_bounds_13184 = slt64(sext_i32_i64(local_tid_13132), segscan_group_sizze_12845);\n        int32_t skip_threads_13185;\n        \n        // read input for in-block scan\n        {\n            if (ltid_in_bounds_13184) {\n                eta_p_13166 = ((volatile __local int32_t *) local_mem_13138)[sext_i32_i64(local_tid_13132)];\n                if ((local_tid_13132 - squot32(local_tid_13132, 32) * 32) == 0) {\n                    eta_p_13165 = eta_p_13166;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_13185 = 1;\n            while (slt32(skip_threads_13185, 32)) {\n                bool thread_active_13186 = sle32(skip_threads_13185, local_tid_13132 - squot32(local_tid_13132, 32) * 32) && ltid_in_bounds_13184;\n                \n                if (thread_active_13186) {\n                    // read operands\n                    {\n                        eta_p_13165 = ((volatile __local int32_t *) local_mem_13138)[sext_i32_i64(local_tid_13132) - sext_i32_i64(skip_threads_13185)];\n                    }\n                }\n                // perform operation\n                {\n                    if (thread_active_13186) {\n                        int32_t za_lhs_13167 = eta_p_13165 & eta_p_13166;\n                        int32_t zb_lhs_13168 = 2 & za_lhs_13167;\n                        int32_t za_rhs_13169 = lshr32(eta_p_13166, 1);\n                        int32_t zb_lhs_13170 = eta_p_13165 & za_rhs_13169;\n                        int32_t za_lhs_13171 = eta_p_13166 | zb_lhs_13170;\n                        int32_t zb_rhs_13172 = 1 & za_lhs_13171;\n                        int32_t carry_prop_res_13173 = zb_lhs_13168 | zb_rhs_13172;\n                        \n                        eta_p_13165 = carry_prop_res_13173;\n                    }\n                }\n                if (sle32(wave_sizze_13134, ", "skip_threads_13185)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_13186) {\n                    // write result\n                    {\n                        ((volatile __local int32_t *) local_mem_13138)[sext_i32_i64(local_tid_13132)] = eta_p_13165;\n                        eta_p_13166 = eta_p_13165;\n                    }\n                }\n                if (sle32(wave_sizze_13134, skip_threads_13185)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_13185 *= 2;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // last thread of block 'i' writes its result to offset 'i'\n        {\n            if ((local_tid_13132 - squot32(local_tid_13132, 32) * 32) == 31 && ltid_in_bounds_13184) {\n                ((volatile __local int32_t *) local_mem_13138)[sext_i32_i64(squot32(local_tid_13132, 32))] = eta_p_13165;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n        {\n            int32_t skip_threads_13187;\n            \n            // read input for in-block scan\n            {\n                if (squot32(local_tid_13132, 32) == 0 && ltid_in_bounds_13184) {\n                    eta_p_13176 = ((volatile __local int32_t *) local_mem_13138)[sext_i32_i64(local_tid_13132)];\n                    if ((local_tid_13132 - squot32(local_tid_13132, 32) * 32) == 0) {\n                        eta_p_13175 = eta_p_13176;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_13187 = 1;\n                while (slt32(skip_threads_13187, 32)) {\n                    bool thread_active_13188 = sle32(skip_threads_13187, local_tid_13132 - squot32(local_tid_13132, 32) * 32) && (squot32(local_tid_13132, 32) == 0 && ltid_in_bounds_13184);\n                    \n                    ", "if (thread_active_13188) {\n                        // read operands\n                        {\n                            eta_p_13175 = ((volatile __local int32_t *) local_mem_13138)[sext_i32_i64(local_tid_13132) - sext_i32_i64(skip_threads_13187)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_13188) {\n                            int32_t za_lhs_13177 = eta_p_13175 & eta_p_13176;\n                            int32_t zb_lhs_13178 = 2 & za_lhs_13177;\n                            int32_t za_rhs_13179 = lshr32(eta_p_13176, 1);\n                            int32_t zb_lhs_13180 = eta_p_13175 & za_rhs_13179;\n                            int32_t za_lhs_13181 = eta_p_13176 | zb_lhs_13180;\n                            int32_t zb_rhs_13182 = 1 & za_lhs_13181;\n                            int32_t carry_prop_res_13183 = zb_lhs_13178 | zb_rhs_13182;\n                            \n                            eta_p_13175 = carry_prop_res_13183;\n                        }\n                    }\n                    if (sle32(wave_sizze_13134, skip_threads_13187)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_13188) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_13138)[sext_i32_i64(local_tid_13132)] = eta_p_13175;\n                            eta_p_13176 = eta_p_13175;\n                        }\n                    }\n                    if (sle32(wave_sizze_13134, skip_threads_13187)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_13187 *= 2;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        \n        bool no_carry_in_13189 = squot32(local_tid_13132, 32) == 0 || !ltid_in_bounds_13184;\n        \n        // carry-in for every block except ",
                                    "the first\n        {\n            // read operands\n            {\n                if (!no_carry_in_13189) {\n                    eta_p_13166 = eta_p_13165;\n                    eta_p_13165 = ((__local int32_t *) local_mem_13138)[sext_i32_i64(squot32(local_tid_13132, 32)) - (int64_t) 1];\n                }\n            }\n            // perform operation\n            {\n                if (!no_carry_in_13189) {\n                    int32_t za_lhs_13167 = eta_p_13165 & eta_p_13166;\n                    int32_t zb_lhs_13168 = 2 & za_lhs_13167;\n                    int32_t za_rhs_13169 = lshr32(eta_p_13166, 1);\n                    int32_t zb_lhs_13170 = eta_p_13165 & za_rhs_13169;\n                    int32_t za_lhs_13171 = eta_p_13166 | zb_lhs_13170;\n                    int32_t zb_rhs_13172 = 1 & za_lhs_13171;\n                    int32_t carry_prop_res_13173 = zb_lhs_13168 | zb_rhs_13172;\n                    \n                    eta_p_13165 = carry_prop_res_13173;\n                }\n            }\n            // write final result\n            {\n                if (!no_carry_in_13189) {\n                    ((__local int32_t *) local_mem_13138)[sext_i32_i64(local_tid_13132)] = eta_p_13165;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // restore correct values for first block\n        {\n            if (squot32(local_tid_13132, 32) == 0 && ltid_in_bounds_13184) {\n                ((__local int32_t *) local_mem_13138)[sext_i32_i64(local_tid_13132)] = eta_p_13166;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_tid_13132 == 0) {\n            acc_13174 = ((__local int32_t *) local_mem_13138)[segscan_group_sizze_12845 - (int64_t) 1];\n        } else {\n            acc_13174 = ((__local int32_t *) local_mem_13138)[sext_i32_i64(local_tid_13132) - (int64_t) 1];\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    prefix_13190 = 2;\n    block_new_sgm_13191 = sgm_idx_13147 == (int64_t) 0", ";\n    // Perform lookback\n    {\n        if (block_new_sgm_13191 && local_tid_13132 == 0) {\n            ((volatile __global int32_t *) incprefixes_mem_13109)[dynamic_id_13145] = acc_13174;\n            mem_fence_global();\n            ((volatile __global int8_t *) status_flags_mem_13105)[dynamic_id_13145] = (int8_t) 2;\n            acc_13174 = 2;\n        }\n        if (!block_new_sgm_13191 && slt32(local_tid_13132, wave_sizze_13134)) {\n            if (local_tid_13132 == 0) {\n                ((volatile __global int32_t *) aggregates_mem_13107)[dynamic_id_13145] = acc_13174;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_13105)[dynamic_id_13145] = (int8_t) 1;\n                \n                int8_t tmp_13192 = ((volatile __global int8_t *) status_flags_mem_13105)[dynamic_id_13145 - (int64_t) 1];\n                \n                ((volatile __local int8_t *) local_mem_13138)[(int64_t) 0] = tmp_13192;\n            }\n            mem_fence_local();\n            \n            int8_t status_13193 = ((__local int8_t *) local_mem_13138)[(int64_t) 0];\n            \n            if (status_13193 == (int8_t) 2) {\n                if (local_tid_13132 == 0) {\n                    prefix_13190 = ((volatile __global int32_t *) incprefixes_mem_13109)[dynamic_id_13145 - (int64_t) 1];\n                }\n            } else {\n                int32_t readOffset_13194 = dynamic_id_13145 - sext_i32_i64(wave_sizze_13134);\n                \n                while (slt32(wave_sizze_13134 * -1, readOffset_13194)) {\n                    int32_t read_i_13195 = readOffset_13194 + local_tid_13132;\n                    int32_t aggr_13196 = 2;\n                    int8_t flag_13197 = (int8_t) 0;\n                    \n                    if (sle32(0, read_i_13195)) {\n                        flag_13197 = ((volatile __global int8_t *) status_flags_mem_13105)[sext_i32_i64(read_i_13195)];\n                        if (flag_13197 == (int8_t) 2) {\n                            ag", "gr_13196 = ((volatile __global int32_t *) incprefixes_mem_13109)[sext_i32_i64(read_i_13195)];\n                        } else if (flag_13197 == (int8_t) 1) {\n                            aggr_13196 = ((volatile __global int32_t *) aggregates_mem_13107)[sext_i32_i64(read_i_13195)];\n                        }\n                    }\n                    ((__local int32_t *) local_mem_13138)[(int64_t) 8 + sext_i32_i64(local_tid_13132)] = aggr_13196;\n                    ((__local int8_t *) local_mem_13138)[sext_i32_i64(local_tid_13132)] = flag_13197;\n                    flag_13197 = ((__local int8_t *) local_mem_13138)[sext_i32_i64(wave_sizze_13134) - (int64_t) 1];\n                    if (slt8(flag_13197, (int8_t) 2)) {\n                        int8_t flg_x_13207;\n                        int8_t flg_y_13208;\n                        int32_t eta_p_13198;\n                        int32_t eta_p_13199;\n                        int32_t skip_threads_13209;\n                        \n                        // read input for in-block scan\n                        {\n                            flg_y_13208 = ((volatile __local int8_t *) local_mem_13138)[sext_i32_i64(local_tid_13132)];\n                            eta_p_13199 = ((volatile __local int32_t *) local_mem_13138)[(int64_t) 8 + sext_i32_i64(local_tid_13132)];\n                            if ((local_tid_13132 - squot32(local_tid_13132, 32) * 32) == 0) {\n                                eta_p_13198 = eta_p_13199;\n                                flg_x_13207 = flg_y_13208;\n                            }\n                        }\n                        // in-block scan (hopefully no barriers needed)\n                        {\n                            skip_threads_13209 = 1;\n                            while (slt32(skip_threads_13209, 32)) {\n                                if (sle32(skip_threads_13209, local_tid_13132 - squot32(local_tid_13132, 32) * 32)) {\n                                    // read operands\n                               ",
                                    "     {\n                                        flg_x_13207 = ((volatile __local int8_t *) local_mem_13138)[sext_i32_i64(local_tid_13132) - sext_i32_i64(skip_threads_13209)];\n                                        eta_p_13198 = ((volatile __local int32_t *) local_mem_13138)[(int64_t) 8 + (sext_i32_i64(local_tid_13132) - sext_i32_i64(skip_threads_13209))];\n                                    }\n                                    // perform operation\n                                    {\n                                        if (flg_y_13208 == (int8_t) 2 || flg_y_13208 == (int8_t) 0) {\n                                            flg_x_13207 = flg_y_13208;\n                                            eta_p_13198 = eta_p_13199;\n                                        } else {\n                                            int32_t za_lhs_13200 = eta_p_13198 & eta_p_13199;\n                                            int32_t zb_lhs_13201 = 2 & za_lhs_13200;\n                                            int32_t za_rhs_13202 = lshr32(eta_p_13199, 1);\n                                            int32_t zb_lhs_13203 = eta_p_13198 & za_rhs_13202;\n                                            int32_t za_lhs_13204 = eta_p_13199 | zb_lhs_13203;\n                                            int32_t zb_rhs_13205 = 1 & za_lhs_13204;\n                                            int32_t carry_prop_res_13206 = zb_lhs_13201 | zb_rhs_13205;\n                                            \n                                            eta_p_13198 = carry_prop_res_13206;\n                                        }\n                                    }\n                                    // write result\n                                    {\n                                        ((volatile __local int8_t *) local_mem_13138)[sext_i32_i64(local_tid_13132)] = flg_x_13207;\n                                        flg_y_13208 = flg_x_13207;\n                                        ((volatile __local int32_t *) loc", "al_mem_13138)[(int64_t) 8 + sext_i32_i64(local_tid_13132)] = eta_p_13198;\n                                        eta_p_13199 = eta_p_13198;\n                                    }\n                                }\n                                skip_threads_13209 *= 2;\n                            }\n                        }\n                    }\n                    flag_13197 = ((__local int8_t *) local_mem_13138)[sext_i32_i64(wave_sizze_13134) - (int64_t) 1];\n                    aggr_13196 = ((__local int32_t *) local_mem_13138)[(int64_t) 8 + (sext_i32_i64(wave_sizze_13134) - (int64_t) 1)];\n                    if (flag_13197 == (int8_t) 2) {\n                        readOffset_13194 = wave_sizze_13134 * -1;\n                    } else if (flag_13197 == (int8_t) 1) {\n                        readOffset_13194 -= wave_sizze_13134;\n                    }\n                    if (slt8((int8_t) 0, flag_13197)) {\n                        int32_t eta_p_13210 = aggr_13196;\n                        int32_t eta_p_13211 = prefix_13190;\n                        int32_t za_lhs_13212 = eta_p_13210 & eta_p_13211;\n                        int32_t zb_lhs_13213 = 2 & za_lhs_13212;\n                        int32_t za_rhs_13214 = lshr32(eta_p_13211, 1);\n                        int32_t zb_lhs_13215 = eta_p_13210 & za_rhs_13214;\n                        int32_t za_lhs_13216 = eta_p_13211 | zb_lhs_13215;\n                        int32_t zb_rhs_13217 = 1 & za_lhs_13216;\n                        int32_t carry_prop_res_13218 = zb_lhs_13213 | zb_rhs_13217;\n                        \n                        prefix_13190 = carry_prop_res_13218;\n                    }\n                    mem_fence_local();\n                }\n            }\n            if (local_tid_13132 == 0) {\n                if (boundary_13148 == sext_i64_i32(segscan_group_sizze_12845 * (int64_t) 23)) {\n                    int32_t eta_p_13219 = prefix_13190;\n                    int32_t eta_p_13220 = acc_13174;\n                    int32_t za_lh", "s_13221 = eta_p_13219 & eta_p_13220;\n                    int32_t zb_lhs_13222 = 2 & za_lhs_13221;\n                    int32_t za_rhs_13223 = lshr32(eta_p_13220, 1);\n                    int32_t zb_lhs_13224 = eta_p_13219 & za_rhs_13223;\n                    int32_t za_lhs_13225 = eta_p_13220 | zb_lhs_13224;\n                    int32_t zb_rhs_13226 = 1 & za_lhs_13225;\n                    int32_t carry_prop_res_13227 = zb_lhs_13222 | zb_rhs_13226;\n                    \n                    ((volatile __global int32_t *) incprefixes_mem_13109)[dynamic_id_13145] = carry_prop_res_13227;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_13105)[dynamic_id_13145] = (int8_t) 2;\n                }\n                ((__local int32_t *) local_mem_13138)[(int64_t) 8] = prefix_13190;\n                acc_13174 = 2;\n            }\n        }\n        if (!(dynamic_id_13145 == (int64_t) 0)) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            prefix_13190 = ((__local int32_t *) local_mem_13138)[(int64_t) 8];\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    // Distribute results\n    {\n        int32_t eta_p_13228;\n        int32_t eta_p_13229;\n        int32_t eta_p_13237 = prefix_13190;\n        int32_t eta_p_13238 = acc_13174;\n        \n        if (slt32(local_tid_13132 * 23, boundary_13148) && !block_new_sgm_13191) {\n            int32_t za_lhs_13239 = eta_p_13237 & eta_p_13238;\n            int32_t zb_lhs_13240 = 2 & za_lhs_13239;\n            int32_t za_rhs_13241 = lshr32(eta_p_13238, 1);\n            int32_t zb_lhs_13242 = eta_p_13237 & za_rhs_13241;\n            int32_t za_lhs_13243 = eta_p_13238 | zb_lhs_13242;\n            int32_t zb_rhs_13244 = 1 & za_lhs_13243;\n            int32_t carry_prop_res_13245 = zb_lhs_13240 | zb_rhs_13244;\n            \n            eta_p_13228 = carry_prop_res_13245;\n        } else {\n            eta_p_13228 = acc_13174;\n        }\n        \n        int32_t stopping_point_13246 = segsizze_compact_13",
                                    "149 - srem32(local_tid_13132 * 23 - 1 + segsizze_compact_13149 - boundary_13148, segsizze_compact_13149);\n        \n        for (int64_t i_13247 = 0; i_13247 < (int64_t) 23; i_13247++) {\n            if (slt32(sext_i64_i32(i_13247), stopping_point_13246 - 1)) {\n                eta_p_13229 = private_mem_13150[i_13247];\n                \n                int32_t za_lhs_13230 = eta_p_13228 & eta_p_13229;\n                int32_t zb_lhs_13231 = 2 & za_lhs_13230;\n                int32_t za_rhs_13232 = lshr32(eta_p_13229, 1);\n                int32_t zb_lhs_13233 = eta_p_13228 & za_rhs_13232;\n                int32_t za_lhs_13234 = eta_p_13229 | zb_lhs_13233;\n                int32_t zb_rhs_13235 = 1 & za_lhs_13234;\n                int32_t carry_prop_res_13236 = zb_lhs_13231 | zb_rhs_13235;\n                \n                private_mem_13150[i_13247] = carry_prop_res_13236;\n            }\n        }\n    }\n    // Transpose scan output and Write it to global memory in coalesced fashion\n    {\n        for (int64_t i_13248 = 0; i_13248 < (int64_t) 23; i_13248++) {\n            int64_t sharedIdx_13249 = sext_i32_i64(local_tid_13132 * 23) + i_13248;\n            int32_t tmp_13250 = private_mem_13150[i_13248];\n            \n            ((__local int32_t *) local_mem_13138)[sharedIdx_13249] = tmp_13250;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int64_t i_13251 = 0; i_13251 < (int64_t) 23; i_13251++) {\n            int64_t flat_idx_13252 = blockOff_13146 + segscan_group_sizze_12845 * i_13251 + sext_i32_i64(local_tid_13132);\n            int64_t slice_13253 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n            int64_t gtid_12849 = flat_idx_13252;\n            int64_t remnant_13254 = flat_idx_13252 - gtid_12849;\n            \n            if (slt64(flat_idx_13252, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {\n                int32_t tmp_13255 = ((__local int32_t *) local_mem_13138)[flat_idx_13252 - blockOff_13146];\n                \n                ((__global int32_t *) mem_12973)[gtid_12849] ", "= tmp_13255;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // If this is the last block, reset the dynamicId\n    {\n        if (dynamic_id_13145 == num_groups_13081 - (int64_t) 1) {\n            ((__global int32_t *) id_counter_mem_13083)[(int64_t) 0] = 0;\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_group_sizze_12845\n}\nFUTHARK_KERNEL_SIZED(big_mul_debugzisegscan_group_sizze_12852, 1, 1)\nvoid big_mul_debugzisegscan_12858(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t local_mem_13273_backing_offset_0, int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, int64_t num_groups_13256, __global unsigned char *exp_res_mem_12915, __global unsigned char *mem_12973, __global unsigned char *mem_12976, __global unsigned char *mem_12980, __global unsigned char *mem_12983, __global unsigned char *mem_12986, __global unsigned char *id_counter_mem_13258, __global unsigned char *status_flags_mem_13260, __global unsigned char *aggregates_mem_13262, __global unsigned char *incprefixes_mem_13264)\n{\n    #define segscan_group_sizze_12853 (big_mul_debugzisegscan_group_sizze_12852)\n    \n    volatile __local unsigned char *local_mem_13273_backing_0 = &local_mem[local_mem_13273_backing_offset_0];\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    int32_t local_tid_13267;\n    int64_t group_sizze_13270;\n    int32_t wave_sizze_13269;\n    int32_t group_tid_13268;\n    int32_t global_tid_13266;\n    int32_t phys_tid_12858;\n    int64_t byte_offsets_13271;\n    int64_t warp_byte_offset_13272;\n    __local unsigned char *local_mem_13273;\n    int64_t trans_arr_len_13274;\n    int32_t dynamic_id_13280;\n    int64_t blockOff_13281;\n    int64_t sgm_idx_13282;\n    int32_t boundary_13283;\n    int32_t segsizze_compact_13284;\n    int64_t pr", "ivate_mem_13285[(int64_t) 11];\n    int64_t acc_13303;\n    int64_t prefix_13313;\n    bool block_new_sgm_13314;\n    \n    local_tid_13267 = get_local_id(0);\n    group_sizze_13270 = get_local_size(0);\n    wave_sizze_13269 = LOCKSTEP_WIDTH;\n    group_tid_13268 = get_group_id(0);\n    global_tid_13266 = group_tid_13268 * group_sizze_13270 + local_tid_13267;\n    phys_tid_12858 = global_tid_13266;\n    byte_offsets_13271 = segscan_group_sizze_12853 * (int64_t) 8;\n    warp_byte_offset_13272 = (int64_t) 288;\n    // Allocate reused shared memeory\n    { }\n    local_mem_13273 = (__local unsigned char *) local_mem_13273_backing_0;\n    trans_arr_len_13274 = (int64_t) 11 * segscan_group_sizze_12853;\n    if (local_tid_13267 == 0) {\n        dynamic_id_13280 = atomic_add_i32_global(&((volatile __global int *) id_counter_mem_13258)[(int64_t) 0], (int) 1);\n        ((__local int32_t *) local_mem_13273)[(int64_t) 0] = dynamic_id_13280;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dynamic_id_13280 = ((__local int32_t *) local_mem_13273)[(int64_t) 0];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    blockOff_13281 = sext_i32_i64(dynamic_id_13280) * (int64_t) 11 * segscan_group_sizze_12853;\n    sgm_idx_13282 = smod64(blockOff_13281, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n    boundary_13283 = sext_i64_i32(smin64((int64_t) 11 * segscan_group_sizze_12853, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773 - sgm_idx_13282));\n    segsizze_compact_13284 = sext_i64_i32(smin64((int64_t) 11 * segscan_group_sizze_12853, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773));\n    // Load and map\n    {\n        for (int64_t i_13287 = 0; i_13287 < (int64_t) 11; i_13287++) {\n            int64_t phys_tid_13288 = blockOff_13281 + sext_i32_i64(local_tid_13267) + i_13287 * segscan_group_sizze_12853;\n            int64_t slice_13289 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n            int64_t gtid_12857 = phys_tid_13288;\n            int64_t remnant_13290 = phys_tid_13288 - gtid_12857;\n            \n            if (slt64(phys_tid_13288, dzlz7bUZLztZRz20U4z20Unz7",
                                    "dUzg_10773)) {\n                int64_t eta_p_11562 = ((__global int64_t *) mem_12976)[gtid_12857];\n                int64_t x_11564 = ((__global int64_t *) exp_res_mem_12915)[gtid_12857];\n                bool cond_11565 = slt64((int64_t) 0, gtid_12857);\n                bool bool_arg0_11566;\n                \n                if (cond_11565 == 1) {\n                    int64_t za_lhs_11749 = sub64(gtid_12857, (int64_t) 1);\n                    bool x_11750 = sle64((int64_t) 0, za_lhs_11749);\n                    bool y_11751 = slt64(za_lhs_11749, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);\n                    bool bounds_check_11752 = x_11750 && y_11751;\n                    bool index_certs_11753;\n                    \n                    if (!bounds_check_11752) {\n                        {\n                            if (atomic_cmpxchg_i32_global(global_failure, -1, 18) == -1) {\n                                global_failure_args[0] = (int64_t) za_lhs_11749;\n                                global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n                                ;\n                            }\n                            local_failure = 1;\n                            goto error_0;\n                        }\n                    }\n                    \n                    int32_t za_lhs_11754 = ((__global int32_t *) mem_12973)[za_lhs_11749];\n                    int32_t zeze_lhs_11755 = 1 & za_lhs_11754;\n                    bool bool_arg0_t_res_11756 = zeze_lhs_11755 == 1;\n                    \n                    bool_arg0_11566 = bool_arg0_t_res_11756;\n                } else {\n                    bool_arg0_11566 = 0;\n                }\n                \n                int64_t unsign_arg0_11575 = btoi_bool_i64(bool_arg0_11566);\n                int64_t lifted_lambda_res_11576 = add64(eta_p_11562, unsign_arg0_11575);\n                bool lifted_lambda_res_11578 = lifted_lambda_res_11576 == x_11564;\n                int64_t defunc_0_partition_arg1_res_11579 =", " btoi_bool_i64(lifted_lambda_res_11578);\n                bool is_i_11580 = defunc_0_partition_arg1_res_11579 == (int64_t) 0;\n                bool cond_neg_11581 = !is_i_11580;\n                int64_t part_res_11582 = btoi_bool_i64(cond_neg_11581);\n                int64_t part_res_11583 = btoi_bool_i64(is_i_11580);\n                \n                ((__global int64_t *) mem_12983)[gtid_12857] = part_res_11582;\n                ((__global int64_t *) mem_12986)[gtid_12857] = lifted_lambda_res_11576;\n                private_mem_13285[i_13287] = part_res_11583;\n            } else {\n                private_mem_13285[i_13287] = (int64_t) 0;\n            }\n        }\n    }\n    \n  error_0:\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_failure)\n        return;\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Transpose scan inputs\n    {\n        for (int64_t i_13291 = 0; i_13291 < (int64_t) 11; i_13291++) {\n            int64_t sharedIdx_13292 = sext_i32_i64(local_tid_13267) + i_13291 * segscan_group_sizze_12853;\n            int64_t tmp_13293 = private_mem_13285[i_13291];\n            \n            ((__local int64_t *) local_mem_13273)[sharedIdx_13292] = tmp_13293;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_13294 = 0; i_13294 < 11; i_13294++) {\n            int32_t sharedIdx_13295 = local_tid_13267 * 11 + i_13294;\n            int64_t tmp_13296 = ((__local int64_t *) local_mem_13273)[sext_i32_i64(sharedIdx_13295)];\n            \n            private_mem_13285[sext_i32_i64(i_13294)] = tmp_13296;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // Per thread scan\n    {\n        int32_t gidx_13297 = local_tid_13267 * 11 + 1;\n        \n        for (int64_t i_13298 = 0; i_13298 < (int64_t) 10; i_13298++) {\n            int64_t x_10795;\n            int64_t y_10796;\n            \n            x_10795 = private_mem_13285[i_13298];\n            y_10796 = private_mem_13285[i_13298 + (int64_t) 1];\n            \n            int64_t zz_10797 = x_10795 + y_10796;\n            \n  ", "          private_mem_13285[i_13298 + (int64_t) 1] = zz_10797;\n        }\n    }\n    // Publish results in shared memory\n    {\n        int64_t tmp_13299 = private_mem_13285[(int64_t) 10];\n        \n        ((__local int64_t *) local_mem_13273)[sext_i32_i64(local_tid_13267)] = tmp_13299;\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // Scan results (with warp scan)\n    {\n        int64_t x_13300;\n        int64_t y_13301;\n        int64_t x_13304;\n        int64_t y_13305;\n        bool ltid_in_bounds_13307 = slt64(sext_i32_i64(local_tid_13267), segscan_group_sizze_12853);\n        int32_t skip_threads_13308;\n        \n        // read input for in-block scan\n        {\n            if (ltid_in_bounds_13307) {\n                y_13301 = ((volatile __local int64_t *) local_mem_13273)[sext_i32_i64(local_tid_13267)];\n                if ((local_tid_13267 - squot32(local_tid_13267, 32) * 32) == 0) {\n                    x_13300 = y_13301;\n                }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_13308 = 1;\n            while (slt32(skip_threads_13308, 32)) {\n                bool thread_active_13309 = sle32(skip_threads_13308, local_tid_13267 - squot32(local_tid_13267, 32) * 32) && ltid_in_bounds_13307;\n                \n                if (thread_active_13309) {\n                    // read operands\n                    {\n                        x_13300 = ((volatile __local int64_t *) local_mem_13273)[sext_i32_i64(local_tid_13267) - sext_i32_i64(skip_threads_13308)];\n                    }\n                }\n                // perform operation\n                {\n                    if (thread_active_13309) {\n                        int64_t zz_13302 = x_13300 + y_13301;\n                        \n                        x_13300 = zz_13302;\n                    }\n                }\n                if (sle32(wave_sizze_13269, skip_threads_13308)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n        ",
                                    "        if (thread_active_13309) {\n                    // write result\n                    {\n                        ((volatile __local int64_t *) local_mem_13273)[sext_i32_i64(local_tid_13267)] = x_13300;\n                        y_13301 = x_13300;\n                    }\n                }\n                if (sle32(wave_sizze_13269, skip_threads_13308)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_13308 *= 2;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // last thread of block 'i' writes its result to offset 'i'\n        {\n            if ((local_tid_13267 - squot32(local_tid_13267, 32) * 32) == 31 && ltid_in_bounds_13307) {\n                ((volatile __local int64_t *) local_mem_13273)[sext_i32_i64(squot32(local_tid_13267, 32))] = x_13300;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n        {\n            int32_t skip_threads_13310;\n            \n            // read input for in-block scan\n            {\n                if (squot32(local_tid_13267, 32) == 0 && ltid_in_bounds_13307) {\n                    y_13305 = ((volatile __local int64_t *) local_mem_13273)[sext_i32_i64(local_tid_13267)];\n                    if ((local_tid_13267 - squot32(local_tid_13267, 32) * 32) == 0) {\n                        x_13304 = y_13305;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_13310 = 1;\n                while (slt32(skip_threads_13310, 32)) {\n                    bool thread_active_13311 = sle32(skip_threads_13310, local_tid_13267 - squot32(local_tid_13267, 32) * 32) && (squot32(local_tid_13267, 32) == 0 && ltid_in_bounds_13307);\n                    \n                    if (thread_active_13311) {\n                        // read operands\n                        {\n                            x_133", "04 = ((volatile __local int64_t *) local_mem_13273)[sext_i32_i64(local_tid_13267) - sext_i32_i64(skip_threads_13310)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_13311) {\n                            int64_t zz_13306 = x_13304 + y_13305;\n                            \n                            x_13304 = zz_13306;\n                        }\n                    }\n                    if (sle32(wave_sizze_13269, skip_threads_13310)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_13311) {\n                        // write result\n                        {\n                            ((volatile __local int64_t *) local_mem_13273)[sext_i32_i64(local_tid_13267)] = x_13304;\n                            y_13305 = x_13304;\n                        }\n                    }\n                    if (sle32(wave_sizze_13269, skip_threads_13310)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_13310 *= 2;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        \n        bool no_carry_in_13312 = squot32(local_tid_13267, 32) == 0 || !ltid_in_bounds_13307;\n        \n        // carry-in for every block except the first\n        {\n            // read operands\n            {\n                if (!no_carry_in_13312) {\n                    y_13301 = x_13300;\n                    x_13300 = ((__local int64_t *) local_mem_13273)[sext_i32_i64(squot32(local_tid_13267, 32)) - (int64_t) 1];\n                }\n            }\n            // perform operation\n            {\n                if (!no_carry_in_13312) {\n                    int64_t zz_13302 = x_13300 + y_13301;\n                    \n                    x_13300 = zz_13302;\n                }\n            }\n            // write final result\n            {\n                if (!no_carry_in_13312)", " {\n                    ((__local int64_t *) local_mem_13273)[sext_i32_i64(local_tid_13267)] = x_13300;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // restore correct values for first block\n        {\n            if (squot32(local_tid_13267, 32) == 0 && ltid_in_bounds_13307) {\n                ((__local int64_t *) local_mem_13273)[sext_i32_i64(local_tid_13267)] = y_13301;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_tid_13267 == 0) {\n            acc_13303 = ((__local int64_t *) local_mem_13273)[segscan_group_sizze_12853 - (int64_t) 1];\n        } else {\n            acc_13303 = ((__local int64_t *) local_mem_13273)[sext_i32_i64(local_tid_13267) - (int64_t) 1];\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    prefix_13313 = (int64_t) 0;\n    block_new_sgm_13314 = sgm_idx_13282 == (int64_t) 0;\n    // Perform lookback\n    {\n        if (block_new_sgm_13314 && local_tid_13267 == 0) {\n            ((volatile __global int64_t *) incprefixes_mem_13264)[dynamic_id_13280] = acc_13303;\n            mem_fence_global();\n            ((volatile __global int8_t *) status_flags_mem_13260)[dynamic_id_13280] = (int8_t) 2;\n            acc_13303 = (int64_t) 0;\n        }\n        if (!block_new_sgm_13314 && slt32(local_tid_13267, wave_sizze_13269)) {\n            if (local_tid_13267 == 0) {\n                ((volatile __global int64_t *) aggregates_mem_13262)[dynamic_id_13280] = acc_13303;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_13260)[dynamic_id_13280] = (int8_t) 1;\n                \n                int8_t tmp_13315 = ((volatile __global int8_t *) status_flags_mem_13260)[dynamic_id_13280 - (int64_t) 1];\n                \n                ((volatile __local int8_t *) local_mem_13273)[(int64_t) 0] = tmp_13315;\n            }\n            mem_fence_local();\n            \n            int8_t status_13316 = ((__local int8_t *) ",
                                    "local_mem_13273)[(int64_t) 0];\n            \n            if (status_13316 == (int8_t) 2) {\n                if (local_tid_13267 == 0) {\n                    prefix_13313 = ((volatile __global int64_t *) incprefixes_mem_13264)[dynamic_id_13280 - (int64_t) 1];\n                }\n            } else {\n                int32_t readOffset_13317 = dynamic_id_13280 - sext_i32_i64(wave_sizze_13269);\n                \n                while (slt32(wave_sizze_13269 * -1, readOffset_13317)) {\n                    int32_t read_i_13318 = readOffset_13317 + local_tid_13267;\n                    int64_t aggr_13319 = (int64_t) 0;\n                    int8_t flag_13320 = (int8_t) 0;\n                    \n                    if (sle32(0, read_i_13318)) {\n                        flag_13320 = ((volatile __global int8_t *) status_flags_mem_13260)[sext_i32_i64(read_i_13318)];\n                        if (flag_13320 == (int8_t) 2) {\n                            aggr_13319 = ((volatile __global int64_t *) incprefixes_mem_13264)[sext_i32_i64(read_i_13318)];\n                        } else if (flag_13320 == (int8_t) 1) {\n                            aggr_13319 = ((volatile __global int64_t *) aggregates_mem_13262)[sext_i32_i64(read_i_13318)];\n                        }\n                    }\n                    ((__local int64_t *) local_mem_13273)[(int64_t) 4 + sext_i32_i64(local_tid_13267)] = aggr_13319;\n                    ((__local int8_t *) local_mem_13273)[sext_i32_i64(local_tid_13267)] = flag_13320;\n                    flag_13320 = ((__local int8_t *) local_mem_13273)[sext_i32_i64(wave_sizze_13269) - (int64_t) 1];\n                    if (slt8(flag_13320, (int8_t) 2)) {\n                        int8_t flg_x_13324;\n                        int8_t flg_y_13325;\n                        int64_t x_13321;\n                        int64_t y_13322;\n                        int32_t skip_threads_13326;\n                        \n                        // read input for in-block scan\n                        {\n          ", "                  flg_y_13325 = ((volatile __local int8_t *) local_mem_13273)[sext_i32_i64(local_tid_13267)];\n                            y_13322 = ((volatile __local int64_t *) local_mem_13273)[(int64_t) 4 + sext_i32_i64(local_tid_13267)];\n                            if ((local_tid_13267 - squot32(local_tid_13267, 32) * 32) == 0) {\n                                x_13321 = y_13322;\n                                flg_x_13324 = flg_y_13325;\n                            }\n                        }\n                        // in-block scan (hopefully no barriers needed)\n                        {\n                            skip_threads_13326 = 1;\n                            while (slt32(skip_threads_13326, 32)) {\n                                if (sle32(skip_threads_13326, local_tid_13267 - squot32(local_tid_13267, 32) * 32)) {\n                                    // read operands\n                                    {\n                                        flg_x_13324 = ((volatile __local int8_t *) local_mem_13273)[sext_i32_i64(local_tid_13267) - sext_i32_i64(skip_threads_13326)];\n                                        x_13321 = ((volatile __local int64_t *) local_mem_13273)[(int64_t) 4 + (sext_i32_i64(local_tid_13267) - sext_i32_i64(skip_threads_13326))];\n                                    }\n                                    // perform operation\n                                    {\n                                        if (flg_y_13325 == (int8_t) 2 || flg_y_13325 == (int8_t) 0) {\n                                            flg_x_13324 = flg_y_13325;\n                                            x_13321 = y_13322;\n                                        } else {\n                                            int64_t zz_13323 = x_13321 + y_13322;\n                                            \n                                            x_13321 = zz_13323;\n                                        }\n                                    }\n                                    ", "// write result\n                                    {\n                                        ((volatile __local int8_t *) local_mem_13273)[sext_i32_i64(local_tid_13267)] = flg_x_13324;\n                                        flg_y_13325 = flg_x_13324;\n                                        ((volatile __local int64_t *) local_mem_13273)[(int64_t) 4 + sext_i32_i64(local_tid_13267)] = x_13321;\n                                        y_13322 = x_13321;\n                                    }\n                                }\n                                skip_threads_13326 *= 2;\n                            }\n                        }\n                    }\n                    flag_13320 = ((__local int8_t *) local_mem_13273)[sext_i32_i64(wave_sizze_13269) - (int64_t) 1];\n                    aggr_13319 = ((__local int64_t *) local_mem_13273)[(int64_t) 4 + (sext_i32_i64(wave_sizze_13269) - (int64_t) 1)];\n                    if (flag_13320 == (int8_t) 2) {\n                        readOffset_13317 = wave_sizze_13269 * -1;\n                    } else if (flag_13320 == (int8_t) 1) {\n                        readOffset_13317 -= wave_sizze_13269;\n                    }\n                    if (slt8((int8_t) 0, flag_13320)) {\n                        int64_t x_13327 = aggr_13319;\n                        int64_t y_13328 = prefix_13313;\n                        int64_t zz_13329 = x_13327 + y_13328;\n                        \n                        prefix_13313 = zz_13329;\n                    }\n                    mem_fence_local();\n                }\n            }\n            if (local_tid_13267 == 0) {\n                if (boundary_13283 == sext_i64_i32(segscan_group_sizze_12853 * (int64_t) 11)) {\n                    int64_t x_13330 = prefix_13313;\n                    int64_t y_13331 = acc_13303;\n                    int64_t zz_13332 = x_13330 + y_13331;\n                    \n                    ((volatile __global int64_t *) incprefixes_mem_13264)[dynamic_id_13280] = zz_13332;\n           ",
                                    "         mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_13260)[dynamic_id_13280] = (int8_t) 2;\n                }\n                ((__local int64_t *) local_mem_13273)[(int64_t) 4] = prefix_13313;\n                acc_13303 = (int64_t) 0;\n            }\n        }\n        if (!(dynamic_id_13280 == (int64_t) 0)) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            prefix_13313 = ((__local int64_t *) local_mem_13273)[(int64_t) 4];\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    // Distribute results\n    {\n        int64_t x_13333;\n        int64_t y_13334;\n        int64_t x_13336 = prefix_13313;\n        int64_t y_13337 = acc_13303;\n        \n        if (slt32(local_tid_13267 * 11, boundary_13283) && !block_new_sgm_13314) {\n            int64_t zz_13338 = x_13336 + y_13337;\n            \n            x_13333 = zz_13338;\n        } else {\n            x_13333 = acc_13303;\n        }\n        \n        int32_t stopping_point_13339 = segsizze_compact_13284 - srem32(local_tid_13267 * 11 - 1 + segsizze_compact_13284 - boundary_13283, segsizze_compact_13284);\n        \n        for (int64_t i_13340 = 0; i_13340 < (int64_t) 11; i_13340++) {\n            if (slt32(sext_i64_i32(i_13340), stopping_point_13339 - 1)) {\n                y_13334 = private_mem_13285[i_13340];\n                \n                int64_t zz_13335 = x_13333 + y_13334;\n                \n                private_mem_13285[i_13340] = zz_13335;\n            }\n        }\n    }\n    // Transpose scan output and Write it to global memory in coalesced fashion\n    {\n        for (int64_t i_13341 = 0; i_13341 < (int64_t) 11; i_13341++) {\n            int64_t sharedIdx_13342 = sext_i32_i64(local_tid_13267 * 11) + i_13341;\n            int64_t tmp_13343 = private_mem_13285[i_13341];\n            \n            ((__local int64_t *) local_mem_13273)[sharedIdx_13342] = tmp_13343;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int64_t i_13344 = 0; i_13344 < (int64_t) 11; i_13344++)", " {\n            int64_t flat_idx_13345 = blockOff_13281 + segscan_group_sizze_12853 * i_13344 + sext_i32_i64(local_tid_13267);\n            int64_t slice_13346 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773;\n            int64_t gtid_12857 = flat_idx_13345;\n            int64_t remnant_13347 = flat_idx_13345 - gtid_12857;\n            \n            if (slt64(flat_idx_13345, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {\n                int64_t tmp_13348 = ((__local int64_t *) local_mem_13273)[flat_idx_13345 - blockOff_13281];\n                \n                ((__global int64_t *) mem_12980)[gtid_12857] = tmp_13348;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // If this is the last block, reset the dynamicId\n    {\n        if (dynamic_id_13280 == num_groups_13256 - (int64_t) 1) {\n            ((__global int32_t *) id_counter_mem_13258)[(int64_t) 0] = 0;\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_group_sizze_12853\n}\nFUTHARK_KERNEL_SIZED(1, 1, 1)\nvoid big_mul_validationzigpuseq_13024(__global int *global_failure, __global unsigned char *bs_mem_12914, __global unsigned char *mem_12929)\n{\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13026;\n    int64_t group_sizze_13029;\n    int32_t wave_sizze_13028;\n    int32_t group_tid_13027;\n    int32_t global_tid_13025;\n    int32_t tid_13024;\n    int64_t computeIter64_arg1_12910;\n    \n    local_tid_13026 = get_local_id(0);\n    group_sizze_13029 = get_local_size(0);\n    wave_sizze_13028 = LOCKSTEP_WIDTH;\n    group_tid_13027 = get_group_id(0);\n    global_tid_13025 = group_tid_13027 * group_sizze_13029 + local_tid_13026;\n    tid_13024 = global_tid_13025;\n    computeIter64_arg1_12910 = ((__global int64_t *) bs_mem_12914)[(int64_t) 0];\n    ((__global int64_t *) mem_12929)[(int64_t) 0] = computeIter64_arg1_12910;\n    \n  error_0:\n    return;\n}\nFUTHARK_KERNEL_SIZED(big_mul_validationzisegmap_group_sizze_11891, 1, 1)\nvoid big_mul_validationzisegmap_12073(__global int *global_failure, int fai", "lure_is_an_option, __global int64_t *global_failure_args, int64_t n_10211, int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, int32_t zm_lhs_11194, __global unsigned char *as_mem_12913, __global unsigned char *bs_mem_12914, __global unsigned char *mem_12929, __global unsigned char *mem_12933, __global unsigned char *mem_12936, __global unsigned char *mem_12939, __global unsigned char *mem_12942, __global unsigned char *mem_12945, __global unsigned char *mem_12948, __global unsigned char *mem_12951, __global unsigned char *mem_12954)\n{\n    #define segmap_group_sizze_12062 (big_mul_validationzisegmap_group_sizze_11891)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13032;\n    int64_t group_sizze_13035;\n    int32_t wave_sizze_13034;\n    int32_t group_tid_13033;\n    int32_t global_tid_13031;\n    int32_t phys_tid_12073;\n    int64_t global_tid_13036;\n    int64_t slice_13037;\n    int64_t gtid_12072;\n    int64_t remnant_13038;\n    \n    local_tid_13032 = get_local_id(0);\n    group_sizze_13035 = get_local_size(0);\n    wave_sizze_13034 = LOCKSTEP_WIDTH;\n    group_tid_13033 = get_group_id(0);\n    global_tid_13031 = group_tid_13033 * group_sizze_13035 + local_tid_13032;\n    phys_tid_12073 = global_tid_13031;\n    global_tid_13036 = sext_i32_i64(group_tid_13033) * segmap_group_sizze_12062 + sext_i32_i64(local_tid_13032);\n    slice_13037 = n_10211;\n    gtid_12072 = global_tid_13036;\n    remnant_13038 = global_tid_13036 - gtid_12072;\n    if (slt64(gtid_12072, n_10211)) {\n        int32_t i64_res_12075;\n        int32_t k1_12076;\n        int32_t upper_bound_12077;\n        int64_t computeIter64_arg0_12131;\n        bool x_12132;\n        bool y_12133;\n        bool bounds_check_12134;\n        bool index_certs_12135;\n        int32_t zm_lhs_12157;\n        int32_t k2_12158;\n        int32_t upper_bound_12159;\n        int64_t computeIter64_arg0_12213;\n        bool x_12214;\n        bool y_12215;\n        bool bounds_check_12216;\n        bool index_certs_12217;\n        int64_t ",
                                    "computeIter64_arg1_12912;\n        int64_t convulution4_res_12078;\n        int64_t convulution4_res_12079;\n        int32_t convulution4_res_12080;\n        int64_t convulution4_res_12081;\n        int64_t convulution4_res_12082;\n        int32_t convulution4_res_12083;\n        int64_t lhc0_12085;\n        int64_t lhc0_12086;\n        int32_t lhc0_12087;\n        int64_t lhc1_12088;\n        int64_t lhc1_12089;\n        int32_t lhc1_12090;\n        int64_t computeIter64_arg0_12136;\n        int64_t ck_l_12137;\n        int64_t n_l_12138;\n        bool zbzg_lhs_12139;\n        int64_t unsign_arg0_12140;\n        int64_t n_h_12141;\n        int64_t unsign_arg0_12142;\n        int64_t n_h_12143;\n        bool zbzg_lhs_12144;\n        int32_t unsign_arg0_12145;\n        int32_t n_c_12146;\n        int64_t n_l_12147;\n        bool zbzg_lhs_12148;\n        int64_t unsign_arg0_12149;\n        int64_t u32_res_12150;\n        int64_t zp_lhs_12151;\n        int64_t n_h_12152;\n        bool zbzg_lhs_12153;\n        int64_t unsign_arg0_12154;\n        int64_t u32_res_12155;\n        int64_t n_c_12156;\n        int64_t convulution4_res_12160;\n        int64_t convulution4_res_12161;\n        int32_t convulution4_res_12162;\n        int64_t convulution4_res_12163;\n        int64_t convulution4_res_12164;\n        int32_t convulution4_res_12165;\n        int64_t lhc2_12167;\n        int64_t lhc2_12168;\n        int32_t lhc2_12169;\n        int64_t lhc3_12170;\n        int64_t lhc3_12171;\n        int32_t lhc3_12172;\n        int64_t computeIter64_arg0_12218;\n        int64_t ck_l_12219;\n        int64_t n_l_12220;\n        bool zbzg_lhs_12221;\n        int64_t unsign_arg0_12222;\n        int64_t n_h_12223;\n        int64_t unsign_arg0_12224;\n        int64_t n_h_12225;\n        bool zbzg_lhs_12226;\n        int32_t unsign_arg0_12227;\n        int32_t n_c_12228;\n        int64_t n_l_12229;\n        bool zbzg_lhs_12230;\n        int64_t unsign_arg0_12231;\n        int64_t u32_res_12232;\n        int64_t zp_lhs_12233;\n        int64_t n_h_122", "34;\n        bool zbzg_lhs_12235;\n        int64_t unsign_arg0_12236;\n        int64_t u32_res_12237;\n        int64_t n_c_12238;\n        \n        i64_res_12075 = sext_i64_i32(gtid_12072);\n        k1_12076 = mul32(2, i64_res_12075);\n        upper_bound_12077 = add32(1, k1_12076);\n        computeIter64_arg0_12131 = sext_i32_i64(upper_bound_12077);\n        x_12132 = sle64((int64_t) 0, computeIter64_arg0_12131);\n        y_12133 = slt64(computeIter64_arg0_12131, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);\n        bounds_check_12134 = x_12132 && y_12133;\n        if (!bounds_check_12134) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 19) == -1) {\n                    global_failure_args[0] = (int64_t) computeIter64_arg0_12131;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n                    ;\n                }\n                return;\n            }\n        }\n        zm_lhs_12157 = sub32(zm_lhs_11194, k1_12076);\n        k2_12158 = sub32(zm_lhs_12157, 2);\n        upper_bound_12159 = add32(1, k2_12158);\n        computeIter64_arg0_12213 = sext_i32_i64(upper_bound_12159);\n        x_12214 = sle64((int64_t) 0, computeIter64_arg0_12213);\n        y_12215 = slt64(computeIter64_arg0_12213, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);\n        bounds_check_12216 = x_12214 && y_12215;\n        if (!bounds_check_12216) {\n            {\n                if (atomic_cmpxchg_i32_global(global_failure, -1, 20) == -1) {\n                    global_failure_args[0] = (int64_t) computeIter64_arg0_12213;\n                    global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n                    ;\n                }\n                return;\n            }\n        }\n        computeIter64_arg1_12912 = ((__global int64_t *) mem_12929)[(int64_t) 0];\n        lhc0_12085 = (int64_t) 0;\n        lhc0_12086 = (int64_t) 0;\n        lhc0_12087 = 0;\n        lhc1_12088 = (int64_t) 0;\n        lhc1_12089 = (int64_t) 0;\n        lhc1_12090 =", " 0;\n        for (int32_t kk_12084 = 0; kk_12084 < upper_bound_12077; kk_12084++) {\n            int32_t j_12091;\n            int64_t j_12092;\n            bool x_12093;\n            bool y_12094;\n            bool bounds_check_12095;\n            bool index_certs_12096;\n            int64_t i_12098;\n            bool x_12099;\n            bool y_12100;\n            bool bounds_check_12101;\n            bool index_certs_12102;\n            int32_t computeIter64_arg1_12114;\n            int64_t computeIter64_arg1_12115;\n            bool x_12116;\n            bool y_12117;\n            bool bounds_check_12118;\n            bool index_certs_12119;\n            int64_t computeIter64_arg1_12097;\n            int64_t computeIter64_arg0_12103;\n            int64_t ck_l_12104;\n            int64_t n_l_12105;\n            bool zbzg_lhs_12106;\n            int64_t unsign_arg0_12107;\n            int64_t n_h_12108;\n            int64_t unsign_arg0_12109;\n            int64_t n_h_12110;\n            bool zbzg_lhs_12111;\n            int32_t unsign_arg0_12112;\n            int32_t n_c_12113;\n            int64_t computeIter64_arg1_12120;\n            int64_t ck_l_12121;\n            int64_t n_l_12122;\n            bool zbzg_lhs_12123;\n            int64_t unsign_arg0_12124;\n            int64_t n_h_12125;\n            int64_t unsign_arg0_12126;\n            int64_t n_h_12127;\n            bool zbzg_lhs_12128;\n            int32_t unsign_arg0_12129;\n            int32_t n_c_12130;\n            int64_t lhc0_tmp_13039;\n            int64_t lhc0_tmp_13040;\n            int32_t lhc0_tmp_13041;\n            int64_t lhc1_tmp_13042;\n            int64_t lhc1_tmp_13043;\n            int32_t lhc1_tmp_13044;\n            \n            j_12091 = sub32(k1_12076, kk_12084);\n            j_12092 = sext_i32_i64(j_12091);\n            x_12093 = sle64((int64_t) 0, j_12092);\n            y_12094 = slt64(j_12092, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);\n            bounds_check_12095 = x_12093 && y_12094;\n            if (!bounds_check_12095) {\n      ",
                                    "          {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 21) == -1) {\n                        global_failure_args[0] = (int64_t) j_12092;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n                        ;\n                    }\n                    return;\n                }\n            }\n            i_12098 = sext_i32_i64(kk_12084);\n            x_12099 = sle64((int64_t) 0, i_12098);\n            y_12100 = slt64(i_12098, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);\n            bounds_check_12101 = x_12099 && y_12100;\n            if (!bounds_check_12101) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 22) == -1) {\n                        global_failure_args[0] = (int64_t) i_12098;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n                        ;\n                    }\n                    return;\n                }\n            }\n            computeIter64_arg1_12114 = add32(1, j_12091);\n            computeIter64_arg1_12115 = sext_i32_i64(computeIter64_arg1_12114);\n            x_12116 = sle64((int64_t) 0, computeIter64_arg1_12115);\n            y_12117 = slt64(computeIter64_arg1_12115, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);\n            bounds_check_12118 = x_12116 && y_12117;\n            if (!bounds_check_12118) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 23) == -1) {\n                        global_failure_args[0] = (int64_t) computeIter64_arg1_12115;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n                        ;\n                    }\n                    return;\n                }\n            }\n            computeIter64_arg1_12097 = ((__global int64_t *) bs_mem_12914)[j_12092];\n            computeIter64_arg0_12103 = ((__global int64_t *) as_mem_12913)[i_12098];\n            ck_l_12104 = mul64(computeIter64_ar", "g1_12097, computeIter64_arg0_12103);\n            n_l_12105 = add64(lhc0_12085, ck_l_12104);\n            zbzg_lhs_12106 = ult64(n_l_12105, ck_l_12104);\n            unsign_arg0_12107 = btoi_bool_i64(zbzg_lhs_12106);\n            n_h_12108 = add64(lhc0_12086, unsign_arg0_12107);\n            unsign_arg0_12109 = futrts_umul_hi64(computeIter64_arg0_12103, computeIter64_arg1_12097);\n            n_h_12110 = add64(n_h_12108, unsign_arg0_12109);\n            zbzg_lhs_12111 = ult64(n_h_12110, unsign_arg0_12109);\n            unsign_arg0_12112 = btoi_bool_i32(zbzg_lhs_12111);\n            n_c_12113 = add32(lhc0_12087, unsign_arg0_12112);\n            computeIter64_arg1_12120 = ((__global int64_t *) bs_mem_12914)[computeIter64_arg1_12115];\n            ck_l_12121 = mul64(computeIter64_arg0_12103, computeIter64_arg1_12120);\n            n_l_12122 = add64(lhc1_12088, ck_l_12121);\n            zbzg_lhs_12123 = ult64(n_l_12122, ck_l_12121);\n            unsign_arg0_12124 = btoi_bool_i64(zbzg_lhs_12123);\n            n_h_12125 = add64(lhc1_12089, unsign_arg0_12124);\n            unsign_arg0_12126 = futrts_umul_hi64(computeIter64_arg0_12103, computeIter64_arg1_12120);\n            n_h_12127 = add64(n_h_12125, unsign_arg0_12126);\n            zbzg_lhs_12128 = ult64(n_h_12127, unsign_arg0_12126);\n            unsign_arg0_12129 = btoi_bool_i32(zbzg_lhs_12128);\n            n_c_12130 = add32(lhc1_12090, unsign_arg0_12129);\n            lhc0_tmp_13039 = n_l_12105;\n            lhc0_tmp_13040 = n_h_12110;\n            lhc0_tmp_13041 = n_c_12113;\n            lhc1_tmp_13042 = n_l_12122;\n            lhc1_tmp_13043 = n_h_12127;\n            lhc1_tmp_13044 = n_c_12130;\n            lhc0_12085 = lhc0_tmp_13039;\n            lhc0_12086 = lhc0_tmp_13040;\n            lhc0_12087 = lhc0_tmp_13041;\n            lhc1_12088 = lhc1_tmp_13042;\n            lhc1_12089 = lhc1_tmp_13043;\n            lhc1_12090 = lhc1_tmp_13044;\n        }\n        convulution4_res_12078 = lhc0_12085;\n        convulution4_res_12079 = lhc0_12086;\n     ", "   convulution4_res_12080 = lhc0_12087;\n        convulution4_res_12081 = lhc1_12088;\n        convulution4_res_12082 = lhc1_12089;\n        convulution4_res_12083 = lhc1_12090;\n        computeIter64_arg0_12136 = ((__global int64_t *) as_mem_12913)[computeIter64_arg0_12131];\n        ck_l_12137 = mul64(computeIter64_arg0_12136, computeIter64_arg1_12912);\n        n_l_12138 = add64(convulution4_res_12081, ck_l_12137);\n        zbzg_lhs_12139 = ult64(n_l_12138, ck_l_12137);\n        unsign_arg0_12140 = btoi_bool_i64(zbzg_lhs_12139);\n        n_h_12141 = add64(convulution4_res_12082, unsign_arg0_12140);\n        unsign_arg0_12142 = futrts_umul_hi64(computeIter64_arg0_12136, computeIter64_arg1_12912);\n        n_h_12143 = add64(n_h_12141, unsign_arg0_12142);\n        zbzg_lhs_12144 = ult64(n_h_12143, unsign_arg0_12142);\n        unsign_arg0_12145 = btoi_bool_i32(zbzg_lhs_12144);\n        n_c_12146 = add32(convulution4_res_12083, unsign_arg0_12145);\n        n_l_12147 = add64(convulution4_res_12079, n_l_12138);\n        zbzg_lhs_12148 = ult64(n_l_12147, convulution4_res_12079);\n        unsign_arg0_12149 = btoi_bool_i64(zbzg_lhs_12148);\n        u32_res_12150 = zext_i32_i64(convulution4_res_12080);\n        zp_lhs_12151 = add64(n_h_12143, u32_res_12150);\n        n_h_12152 = add64(unsign_arg0_12149, zp_lhs_12151);\n        zbzg_lhs_12153 = ult64(n_h_12152, n_h_12143);\n        unsign_arg0_12154 = btoi_bool_i64(zbzg_lhs_12153);\n        u32_res_12155 = zext_i32_i64(n_c_12146);\n        n_c_12156 = add64(unsign_arg0_12154, u32_res_12155);\n        lhc2_12167 = (int64_t) 0;\n        lhc2_12168 = (int64_t) 0;\n        lhc2_12169 = 0;\n        lhc3_12170 = (int64_t) 0;\n        lhc3_12171 = (int64_t) 0;\n        lhc3_12172 = 0;\n        for (int32_t kk_12166 = 0; kk_12166 < upper_bound_12159; kk_12166++) {\n            int32_t j_12173;\n            int64_t j_12174;\n            bool x_12175;\n            bool y_12176;\n            bool bounds_check_12177;\n            bool index_certs_12178;\n            int64_t",
                                    " i_12180;\n            bool x_12181;\n            bool y_12182;\n            bool bounds_check_12183;\n            bool index_certs_12184;\n            int32_t computeIter64_arg1_12196;\n            int64_t computeIter64_arg1_12197;\n            bool x_12198;\n            bool y_12199;\n            bool bounds_check_12200;\n            bool index_certs_12201;\n            int64_t computeIter64_arg1_12179;\n            int64_t computeIter64_arg0_12185;\n            int64_t ck_l_12186;\n            int64_t n_l_12187;\n            bool zbzg_lhs_12188;\n            int64_t unsign_arg0_12189;\n            int64_t n_h_12190;\n            int64_t unsign_arg0_12191;\n            int64_t n_h_12192;\n            bool zbzg_lhs_12193;\n            int32_t unsign_arg0_12194;\n            int32_t n_c_12195;\n            int64_t computeIter64_arg1_12202;\n            int64_t ck_l_12203;\n            int64_t n_l_12204;\n            bool zbzg_lhs_12205;\n            int64_t unsign_arg0_12206;\n            int64_t n_h_12207;\n            int64_t unsign_arg0_12208;\n            int64_t n_h_12209;\n            bool zbzg_lhs_12210;\n            int32_t unsign_arg0_12211;\n            int32_t n_c_12212;\n            int64_t lhc2_tmp_13045;\n            int64_t lhc2_tmp_13046;\n            int32_t lhc2_tmp_13047;\n            int64_t lhc3_tmp_13048;\n            int64_t lhc3_tmp_13049;\n            int32_t lhc3_tmp_13050;\n            \n            j_12173 = sub32(k2_12158, kk_12166);\n            j_12174 = sext_i32_i64(j_12173);\n            x_12175 = sle64((int64_t) 0, j_12174);\n            y_12176 = slt64(j_12174, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);\n            bounds_check_12177 = x_12175 && y_12176;\n            if (!bounds_check_12177) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 24) == -1) {\n                        global_failure_args[0] = (int64_t) j_12174;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n                        ;\n", "                    }\n                    return;\n                }\n            }\n            i_12180 = sext_i32_i64(kk_12166);\n            x_12181 = sle64((int64_t) 0, i_12180);\n            y_12182 = slt64(i_12180, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);\n            bounds_check_12183 = x_12181 && y_12182;\n            if (!bounds_check_12183) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 25) == -1) {\n                        global_failure_args[0] = (int64_t) i_12180;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n                        ;\n                    }\n                    return;\n                }\n            }\n            computeIter64_arg1_12196 = add32(1, j_12173);\n            computeIter64_arg1_12197 = sext_i32_i64(computeIter64_arg1_12196);\n            x_12198 = sle64((int64_t) 0, computeIter64_arg1_12197);\n            y_12199 = slt64(computeIter64_arg1_12197, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);\n            bounds_check_12200 = x_12198 && y_12199;\n            if (!bounds_check_12200) {\n                {\n                    if (atomic_cmpxchg_i32_global(global_failure, -1, 26) == -1) {\n                        global_failure_args[0] = (int64_t) computeIter64_arg1_12197;\n                        global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n                        ;\n                    }\n                    return;\n                }\n            }\n            computeIter64_arg1_12179 = ((__global int64_t *) bs_mem_12914)[j_12174];\n            computeIter64_arg0_12185 = ((__global int64_t *) as_mem_12913)[i_12180];\n            ck_l_12186 = mul64(computeIter64_arg1_12179, computeIter64_arg0_12185);\n            n_l_12187 = add64(lhc2_12167, ck_l_12186);\n            zbzg_lhs_12188 = ult64(n_l_12187, ck_l_12186);\n            unsign_arg0_12189 = btoi_bool_i64(zbzg_lhs_12188);\n            n_h_12190 = add64(lhc2_12168, unsign_arg0_12189);\n         ", "   unsign_arg0_12191 = futrts_umul_hi64(computeIter64_arg0_12185, computeIter64_arg1_12179);\n            n_h_12192 = add64(n_h_12190, unsign_arg0_12191);\n            zbzg_lhs_12193 = ult64(n_h_12192, unsign_arg0_12191);\n            unsign_arg0_12194 = btoi_bool_i32(zbzg_lhs_12193);\n            n_c_12195 = add32(lhc2_12169, unsign_arg0_12194);\n            computeIter64_arg1_12202 = ((__global int64_t *) bs_mem_12914)[computeIter64_arg1_12197];\n            ck_l_12203 = mul64(computeIter64_arg0_12185, computeIter64_arg1_12202);\n            n_l_12204 = add64(lhc3_12170, ck_l_12203);\n            zbzg_lhs_12205 = ult64(n_l_12204, ck_l_12203);\n            unsign_arg0_12206 = btoi_bool_i64(zbzg_lhs_12205);\n            n_h_12207 = add64(lhc3_12171, unsign_arg0_12206);\n            unsign_arg0_12208 = futrts_umul_hi64(computeIter64_arg0_12185, computeIter64_arg1_12202);\n            n_h_12209 = add64(n_h_12207, unsign_arg0_12208);\n            zbzg_lhs_12210 = ult64(n_h_12209, unsign_arg0_12208);\n            unsign_arg0_12211 = btoi_bool_i32(zbzg_lhs_12210);\n            n_c_12212 = add32(lhc3_12172, unsign_arg0_12211);\n            lhc2_tmp_13045 = n_l_12187;\n            lhc2_tmp_13046 = n_h_12192;\n            lhc2_tmp_13047 = n_c_12195;\n            lhc3_tmp_13048 = n_l_12204;\n            lhc3_tmp_13049 = n_h_12209;\n            lhc3_tmp_13050 = n_c_12212;\n            lhc2_12167 = lhc2_tmp_13045;\n            lhc2_12168 = lhc2_tmp_13046;\n            lhc2_12169 = lhc2_tmp_13047;\n            lhc3_12170 = lhc3_tmp_13048;\n            lhc3_12171 = lhc3_tmp_13049;\n            lhc3_12172 = lhc3_tmp_13050;\n        }\n        convulution4_res_12160 = lhc2_12167;\n        convulution4_res_12161 = lhc2_12168;\n        convulution4_res_12162 = lhc2_12169;\n        convulution4_res_12163 = lhc3_12170;\n        convulution4_res_12164 = lhc3_12171;\n        convulution4_res_12165 = lhc3_12172;\n        computeIter64_arg0_12218 = ((__global int64_t *) as_mem_12913)[computeIter64_arg0_12213];\n        ck_l",
                                    "_12219 = mul64(computeIter64_arg0_12218, computeIter64_arg1_12912);\n        n_l_12220 = add64(convulution4_res_12163, ck_l_12219);\n        zbzg_lhs_12221 = ult64(n_l_12220, ck_l_12219);\n        unsign_arg0_12222 = btoi_bool_i64(zbzg_lhs_12221);\n        n_h_12223 = add64(convulution4_res_12164, unsign_arg0_12222);\n        unsign_arg0_12224 = futrts_umul_hi64(computeIter64_arg0_12218, computeIter64_arg1_12912);\n        n_h_12225 = add64(n_h_12223, unsign_arg0_12224);\n        zbzg_lhs_12226 = ult64(n_h_12225, unsign_arg0_12224);\n        unsign_arg0_12227 = btoi_bool_i32(zbzg_lhs_12226);\n        n_c_12228 = add32(convulution4_res_12165, unsign_arg0_12227);\n        n_l_12229 = add64(convulution4_res_12161, n_l_12220);\n        zbzg_lhs_12230 = ult64(n_l_12229, convulution4_res_12161);\n        unsign_arg0_12231 = btoi_bool_i64(zbzg_lhs_12230);\n        u32_res_12232 = zext_i32_i64(convulution4_res_12162);\n        zp_lhs_12233 = add64(n_h_12225, u32_res_12232);\n        n_h_12234 = add64(unsign_arg0_12231, zp_lhs_12233);\n        zbzg_lhs_12235 = ult64(n_h_12234, n_h_12225);\n        unsign_arg0_12236 = btoi_bool_i64(zbzg_lhs_12235);\n        u32_res_12237 = zext_i32_i64(n_c_12228);\n        n_c_12238 = add64(unsign_arg0_12236, u32_res_12237);\n        ((__global int64_t *) mem_12933)[gtid_12072] = convulution4_res_12078;\n        ((__global int64_t *) mem_12936)[gtid_12072] = n_l_12147;\n        ((__global int64_t *) mem_12939)[gtid_12072] = n_h_12152;\n        ((__global int64_t *) mem_12942)[gtid_12072] = n_c_12156;\n        ((__global int64_t *) mem_12945)[gtid_12072] = convulution4_res_12160;\n        ((__global int64_t *) mem_12948)[gtid_12072] = n_l_12229;\n        ((__global int64_t *) mem_12951)[gtid_12072] = n_h_12234;\n        ((__global int64_t *) mem_12954)[gtid_12072] = n_c_12238;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_12062\n}\nFUTHARK_KERNEL_SIZED(big_mul_validationzisegmap_group_sizze_12242, 1, 1)\nvoid big_mul_validationzisegmap_12240(__global int ", "*global_failure, int64_t n_10211, int64_t dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, int64_t w_minus_1_11403, __global unsigned char *mem_12918, __global unsigned char *mem_12921, __global unsigned char *mem_12924, __global unsigned char *mem_12927, __global unsigned char *mem_12933, __global unsigned char *mem_12939, __global unsigned char *mem_12945, __global unsigned char *mem_12951)\n{\n    #define segmap_group_sizze_12243 (big_mul_validationzisegmap_group_sizze_12242)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13053;\n    int64_t group_sizze_13056;\n    int32_t wave_sizze_13055;\n    int32_t group_tid_13054;\n    int32_t global_tid_13052;\n    int32_t phys_tid_12240;\n    int64_t global_tid_13057;\n    int64_t slice_13058;\n    int64_t write_i_12239;\n    int64_t remnant_13059;\n    \n    local_tid_13053 = get_local_id(0);\n    group_sizze_13056 = get_local_size(0);\n    wave_sizze_13055 = LOCKSTEP_WIDTH;\n    group_tid_13054 = get_group_id(0);\n    global_tid_13052 = group_tid_13054 * group_sizze_13056 + local_tid_13053;\n    phys_tid_12240 = global_tid_13052;\n    global_tid_13057 = sext_i32_i64(group_tid_13054) * segmap_group_sizze_12243 + sext_i32_i64(local_tid_13053);\n    slice_13058 = n_10211;\n    write_i_12239 = global_tid_13057;\n    remnant_13059 = global_tid_13057 - write_i_12239;\n    if (slt64(write_i_12239, n_10211)) {\n        int64_t slice_12902;\n        int64_t write_value_11657;\n        int64_t write_value_11659;\n        int64_t write_value_11661;\n        int64_t write_value_11663;\n        int64_t lifted_lambda_res_11664;\n        \n        slice_12902 = w_minus_1_11403 - write_i_12239;\n        write_value_11657 = ((__global int64_t *) mem_12951)[slice_12902];\n        write_value_11659 = ((__global int64_t *) mem_12939)[write_i_12239];\n        write_value_11661 = ((__global int64_t *) mem_12945)[slice_12902];\n        write_value_11663 = ((__global int64_t *) mem_12933)[write_i_12239];\n        lifted_lambda_res_11664 = mul64((int64_t) 2, write_i", "_12239);\n        if (sle64((int64_t) 0, lifted_lambda_res_11664) && slt64(lifted_lambda_res_11664, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12918)[lifted_lambda_res_11664] = write_value_11657;\n        }\n        if (sle64((int64_t) 0, lifted_lambda_res_11664) && slt64(lifted_lambda_res_11664, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12921)[lifted_lambda_res_11664] = write_value_11659;\n        }\n        if (sle64((int64_t) 0, lifted_lambda_res_11664) && slt64(lifted_lambda_res_11664, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12924)[lifted_lambda_res_11664] = write_value_11661;\n        }\n        if (sle64((int64_t) 0, lifted_lambda_res_11664) && slt64(lifted_lambda_res_11664, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12927)[lifted_lambda_res_11664] = write_value_11663;\n        }\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_12243\n}\nFUTHARK_KERNEL_SIZED(big_mul_validationzisegmap_group_sizze_12248, 1, 1)\nvoid big_mul_validationzisegmap_12246(__global int *global_failure, int64_t n_10211, int64_t dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, int64_t w_minus_1_11403, __global unsigned char *mem_12918, __global unsigned char *mem_12921, __global unsigned char *mem_12924, __global unsigned char *mem_12927, __global unsigned char *mem_12936, __global unsigned char *mem_12942, __global unsigned char *mem_12948, __global unsigned char *mem_12954)\n{\n    #define segmap_group_sizze_12249 (big_mul_validationzisegmap_group_sizze_12248)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13062;\n    int64_t group_sizze_13065;\n    int32_t wave_sizze_13064;\n    int32_t group_tid_13063;\n    int32_t global_tid_13061;\n    int32_t phys_tid_12246;\n    int64_t global_tid_13066;\n    int64_t slice_13067;\n    int64_t write_i_12245;\n    int64_t remnant_13068;\n    \n    local_tid_13062 = get_local_id(0);\n    group_sizze_1306",
                                    "5 = get_local_size(0);\n    wave_sizze_13064 = LOCKSTEP_WIDTH;\n    group_tid_13063 = get_group_id(0);\n    global_tid_13061 = group_tid_13063 * group_sizze_13065 + local_tid_13062;\n    phys_tid_12246 = global_tid_13061;\n    global_tid_13066 = sext_i32_i64(group_tid_13063) * segmap_group_sizze_12249 + sext_i32_i64(local_tid_13062);\n    slice_13067 = n_10211;\n    write_i_12245 = global_tid_13066;\n    remnant_13068 = global_tid_13066 - write_i_12245;\n    if (slt64(write_i_12245, n_10211)) {\n        int64_t slice_12890;\n        int64_t write_value_11704;\n        int64_t write_value_11706;\n        int64_t write_value_11708;\n        int64_t write_value_11710;\n        int64_t zp_lhs_11711;\n        int64_t lifted_lambda_res_11712;\n        \n        slice_12890 = w_minus_1_11403 - write_i_12245;\n        write_value_11704 = ((__global int64_t *) mem_12954)[slice_12890];\n        write_value_11706 = ((__global int64_t *) mem_12942)[write_i_12245];\n        write_value_11708 = ((__global int64_t *) mem_12948)[slice_12890];\n        write_value_11710 = ((__global int64_t *) mem_12936)[write_i_12245];\n        zp_lhs_11711 = mul64((int64_t) 2, write_i_12245);\n        lifted_lambda_res_11712 = add64((int64_t) 1, zp_lhs_11711);\n        if (sle64((int64_t) 0, lifted_lambda_res_11712) && slt64(lifted_lambda_res_11712, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12918)[lifted_lambda_res_11712] = write_value_11704;\n        }\n        if (sle64((int64_t) 0, lifted_lambda_res_11712) && slt64(lifted_lambda_res_11712, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12921)[lifted_lambda_res_11712] = write_value_11706;\n        }\n        if (sle64((int64_t) 0, lifted_lambda_res_11712) && slt64(lifted_lambda_res_11712, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12924)[lifted_lambda_res_11712] = write_value_11708;\n        }\n        if (sle64((int64_t) 0, lifted_lambda_res_11712) && slt64(lifted_lambda_res", "_11712, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183)) {\n            ((__global int64_t *) mem_12927)[lifted_lambda_res_11712] = write_value_11710;\n        }\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_12249\n}\nFUTHARK_KERNEL_SIZED(big_mul_validationzisegmap_group_sizze_12254, 1, 1)\nvoid big_mul_validationzisegmap_12272(__global int *global_failure, int64_t dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184, __global unsigned char *mem_12918, __global unsigned char *mem_12921, __global unsigned char *mem_12960)\n{\n    #define segmap_group_sizze_12268 (big_mul_validationzisegmap_group_sizze_12254)\n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13071;\n    int64_t group_sizze_13074;\n    int32_t wave_sizze_13073;\n    int32_t group_tid_13072;\n    int32_t global_tid_13070;\n    int32_t phys_tid_12272;\n    int64_t global_tid_13075;\n    int64_t slice_13076;\n    int64_t gtid_12271;\n    int64_t remnant_13077;\n    \n    local_tid_13071 = get_local_id(0);\n    group_sizze_13074 = get_local_size(0);\n    wave_sizze_13073 = LOCKSTEP_WIDTH;\n    group_tid_13072 = get_group_id(0);\n    global_tid_13070 = group_tid_13072 * group_sizze_13074 + local_tid_13071;\n    phys_tid_12272 = global_tid_13070;\n    global_tid_13075 = sext_i32_i64(group_tid_13072) * segmap_group_sizze_12268 + sext_i32_i64(local_tid_13071);\n    slice_13076 = dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184;\n    gtid_12271 = global_tid_13075;\n    remnant_13077 = global_tid_13075 - gtid_12271;\n    if (slt64(gtid_12271, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184)) {\n        int64_t zv_lhs_12274;\n        int64_t tmp_12275;\n        bool index_concat_cmp_12276;\n        int64_t index_concat_branch_12277;\n        \n        zv_lhs_12274 = add64((int64_t) -2, gtid_12271);\n        tmp_12275 = smod64(zv_lhs_12274, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7d", "Uzg_11184);\n        index_concat_cmp_12276 = sle64(dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, tmp_12275);\n        if (index_concat_cmp_12276 == 1) {\n            int64_t index_concat_i_12278;\n            int64_t index_concat_12279;\n            \n            index_concat_i_12278 = sub64(tmp_12275, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183);\n            index_concat_12279 = ((__global int64_t *) mem_12918)[index_concat_i_12278];\n            index_concat_branch_12277 = index_concat_12279;\n        } else {\n            int64_t index_concat_12280 = ((__global int64_t *) mem_12921)[tmp_12275];\n            \n            index_concat_branch_12277 = index_concat_12280;\n        }\n        ((__global int64_t *) mem_12960)[gtid_12271] = index_concat_branch_12277;\n    }\n    \n  error_0:\n    return;\n    #undef segmap_group_sizze_12268\n}\nFUTHARK_KERNEL_SIZED(big_mul_validationzisegred_group_sizze_12290, 1, 1)\nvoid big_mul_validationzisegred_nonseg_12298(__global int *global_failure, int failure_is_an_option, __global int64_t *global_failure_args, int64_t red_arr_mem_13265_backing_offset_0, int64_t sync_arr_mem_13263_backing_offset_1, int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, int64_t num_groups_12293, int64_t num_threads_13257, __global unsigned char *exp_res_mem_12915, __global unsigned char *mem_12964, __global unsigned char *mem_12967, __global unsigned char *mem_12970, __global unsigned char *counters_mem_13253, __global unsigned char *segred_tmp_mem_13255)\n{\n    #define segred_group_sizze_12291 (big_mul_validationzisegred_group_sizze_12290)\n    \n    volatile __local unsigned char *red_arr_mem_13265_backing_1 = &local_mem[red_arr_mem_13265_backing_offset_0];\n    volatile __local unsigned char *sync_arr_mem_13263_backing_0 = &local_mem[sync_arr_mem_13263_backing_offset_1];\n    volatile __local int local_failure;\n    \n    if (failure_is_an_option) {\n        int failed = *global_failure >= 0;\n        \n        if (failed)\n            return;\n    }\n    local_failure = 0;\n    barrier(CLK_LOCAL_MEM_",
                                    "FENCE);\n    \n    int32_t local_tid_13259;\n    int64_t group_sizze_13262;\n    int32_t wave_sizze_13261;\n    int32_t group_tid_13260;\n    int32_t global_tid_13258;\n    int32_t phys_tid_12298;\n    __local unsigned char *sync_arr_mem_13263;\n    __local unsigned char *red_arr_mem_13265;\n    int64_t dummy_12296;\n    int64_t gtid_12297;\n    bool x_acc_13267;\n    int64_t chunk_sizze_13268;\n    bool x_10230;\n    bool y_10231;\n    int32_t offset_13273;\n    int32_t skip_waves_13274;\n    bool x_13269;\n    bool y_13270;\n    int32_t old_counter_13275;\n    bool is_last_group_13276;\n    \n    local_tid_13259 = get_local_id(0);\n    group_sizze_13262 = get_local_size(0);\n    wave_sizze_13261 = LOCKSTEP_WIDTH;\n    group_tid_13260 = get_group_id(0);\n    global_tid_13258 = group_tid_13260 * group_sizze_13262 + local_tid_13259;\n    phys_tid_12298 = global_tid_13258;\n    sync_arr_mem_13263 = (__local unsigned char *) sync_arr_mem_13263_backing_0;\n    red_arr_mem_13265 = (__local unsigned char *) red_arr_mem_13265_backing_1;\n    dummy_12296 = (int64_t) 0;\n    gtid_12297 = (int64_t) 0;\n    chunk_sizze_13268 = smin64(sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, sext_i32_i64(sext_i64_i32(segred_group_sizze_12291 * num_groups_12293))), sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10212 - phys_tid_12298, num_threads_13257));\n    // neutral-initialise the accumulators\n    {\n        x_acc_13267 = 1;\n    }\n    for (int64_t i_13272 = 0; i_13272 < chunk_sizze_13268; i_13272++) {\n        gtid_12297 = phys_tid_12298 + num_threads_13257 * i_13272;\n        // apply map function\n        {\n            int64_t eta_p_11555 = ((__global int64_t *) mem_12967)[gtid_12297];\n            int64_t y_11557 = ((__global int64_t *) exp_res_mem_12915)[gtid_12297];\n            bool cond_11558 = slt64((int64_t) 0, gtid_12297);\n            bool bool_arg0_11559;\n            \n            if (cond_11558 == 1) {\n                int64_t za_lhs_11735 = sub64(gtid_12297, (int64_t) 1);\n                bool x_11736 = sle64((int64_t) 0", ", za_lhs_11735);\n                bool y_11737 = slt64(za_lhs_11735, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);\n                bool bounds_check_11738 = x_11736 && y_11737;\n                bool index_certs_11739;\n                \n                if (!bounds_check_11738) {\n                    {\n                        if (atomic_cmpxchg_i32_global(global_failure, -1, 27) == -1) {\n                            global_failure_args[0] = (int64_t) za_lhs_11735;\n                            global_failure_args[1] = (int64_t) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n                            ;\n                        }\n                        local_failure = 1;\n                        goto error_0;\n                    }\n                }\n                \n                int32_t za_lhs_11740 = ((__global int32_t *) mem_12964)[za_lhs_11735];\n                int32_t zeze_lhs_11741 = 1 & za_lhs_11740;\n                bool bool_arg0_t_res_11742 = zeze_lhs_11741 == 1;\n                \n                bool_arg0_11559 = bool_arg0_t_res_11742;\n            } else {\n                bool_arg0_11559 = 0;\n            }\n            \n            int64_t unsign_arg0_11568 = btoi_bool_i64(bool_arg0_11559);\n            int64_t lifted_lambda_res_11569 = add64(eta_p_11555, unsign_arg0_11568);\n            bool binlam_res_11571 = lifted_lambda_res_11569 == y_11557;\n            \n            // save map-out results\n            { }\n            // load accumulator\n            {\n                x_10230 = x_acc_13267;\n            }\n            // load new values\n            {\n                y_10231 = binlam_res_11571;\n            }\n            // apply reduction operator\n            {\n                bool binlam_res_10232 = x_10230 && y_10231;\n                \n                // store in accumulator\n                {\n                    x_acc_13267 = binlam_res_10232;\n                }\n            }\n        }\n    }\n    \n  error_0:\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if (local_failure)\n        return;\n    bar", "rier(CLK_LOCAL_MEM_FENCE);\n    // to reduce current chunk, first store our result in memory\n    {\n        x_10230 = x_acc_13267;\n        ((__local bool *) red_arr_mem_13265)[sext_i32_i64(local_tid_13259)] = x_10230;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    skip_waves_13274 = 1;\n    offset_13273 = 0;\n    // participating threads read initial accumulator\n    {\n        if (slt32(local_tid_13259, sext_i64_i32(segred_group_sizze_12291))) {\n            x_13269 = ((__local bool *) red_arr_mem_13265)[sext_i32_i64(local_tid_13259 + offset_13273)];\n        }\n    }\n    offset_13273 = 1;\n    while (slt32(offset_13273, wave_sizze_13261)) {\n        if (slt32(local_tid_13259 + offset_13273, sext_i64_i32(segred_group_sizze_12291)) && ((local_tid_13259 - squot32(local_tid_13259, wave_sizze_13261) * wave_sizze_13261) & (2 * offset_13273 - 1)) == 0) {\n            // read array element\n            {\n                y_13270 = ((volatile __local bool *) red_arr_mem_13265)[sext_i32_i64(local_tid_13259 + offset_13273)];\n            }\n            // apply reduction operation\n            {\n                bool binlam_res_13271 = x_13269 && y_13270;\n                \n                x_13269 = binlam_res_13271;\n            }\n            // write result of operation\n            {\n                ((volatile __local bool *) red_arr_mem_13265)[sext_i32_i64(local_tid_13259)] = x_13269;\n            }\n        }\n        offset_13273 *= 2;\n    }\n    while (slt32(skip_waves_13274, squot32(sext_i64_i32(segred_group_sizze_12291) + wave_sizze_13261 - 1, wave_sizze_13261))) {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        offset_13273 = skip_waves_13274 * wave_sizze_13261;\n        if (slt32(local_tid_13259 + offset_13273, sext_i64_i32(segred_group_sizze_12291)) && ((local_tid_13259 - squot32(local_tid_13259, wave_sizze_13261) * wave_sizze_13261) == 0 && (squot32(local_tid_13259, wave_sizze_13261) & (2 * skip_waves_13274 - 1)) == 0)) {\n            // read array element\n            {\n                y_13270 ",
                                    "= ((__local bool *) red_arr_mem_13265)[sext_i32_i64(local_tid_13259 + offset_13273)];\n            }\n            // apply reduction operation\n            {\n                bool binlam_res_13271 = x_13269 && y_13270;\n                \n                x_13269 = binlam_res_13271;\n            }\n            // write result of operation\n            {\n                ((__local bool *) red_arr_mem_13265)[sext_i32_i64(local_tid_13259)] = x_13269;\n            }\n        }\n        skip_waves_13274 *= 2;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Copy array-typed operands to result array\n    {\n        if (local_tid_13259 == 0) { }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // first thread saves the result in accumulator\n    {\n        if (sext_i32_i64(local_tid_13259) == (int64_t) 0) {\n            x_acc_13267 = x_13269;\n        }\n    }\n    // first thread in group saves group result to global memory\n    {\n        if (local_tid_13259 == 0) {\n            ((__global bool *) segred_tmp_mem_13255)[sext_i32_i64(group_tid_13260)] = x_acc_13267;\n            mem_fence_global();\n            old_counter_13275 = atomic_add_i32_global(&((volatile __global int *) counters_mem_13253)[(int64_t) 0], (int) 1);\n            ((__local bool *) sync_arr_mem_13263)[(int64_t) 0] = old_counter_13275 == num_groups_12293 - (int64_t) 1;\n        }\n    }\n    barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    is_last_group_13276 = ((__local bool *) sync_arr_mem_13263)[(int64_t) 0];\n    if (is_last_group_13276) {\n        if (local_tid_13259 == 0) {\n            old_counter_13275 = atomic_add_i32_global(&((volatile __global int *) counters_mem_13253)[(int64_t) 0], (int) ((int64_t) 0 - num_groups_12293));\n        }\n        // read in the per-group-results\n        {\n            int64_t read_per_thread_13277 = sdiv_up64(num_groups_12293, segred_group_sizze_12291);\n            \n            x_10230 = 1;\n            for (int64_t i_13278 = 0; i_13278 < read_per_thread_13277; i_13278++) {\n                int64_t ", "group_res_id_13279 = sext_i32_i64(local_tid_13259) * read_per_thread_13277 + i_13278;\n                int64_t index_of_group_res_13280 = group_res_id_13279;\n                \n                if (slt64(group_res_id_13279, num_groups_12293)) {\n                    y_10231 = ((__global bool *) segred_tmp_mem_13255)[index_of_group_res_13280];\n                    \n                    bool binlam_res_10232 = x_10230 && y_10231;\n                    \n                    x_10230 = binlam_res_10232;\n                }\n            }\n        }\n        ((__local bool *) red_arr_mem_13265)[sext_i32_i64(local_tid_13259)] = x_10230;\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // reduce the per-group results\n        {\n            int32_t offset_13281;\n            int32_t skip_waves_13282 = 1;\n            bool x_13269;\n            bool y_13270;\n            \n            offset_13281 = 0;\n            // participating threads read initial accumulator\n            {\n                if (slt32(local_tid_13259, sext_i64_i32(segred_group_sizze_12291))) {\n                    x_13269 = ((__local bool *) red_arr_mem_13265)[sext_i32_i64(local_tid_13259 + offset_13281)];\n                }\n            }\n            offset_13281 = 1;\n            while (slt32(offset_13281, wave_sizze_13261)) {\n                if (slt32(local_tid_13259 + offset_13281, sext_i64_i32(segred_group_sizze_12291)) && ((local_tid_13259 - squot32(local_tid_13259, wave_sizze_13261) * wave_sizze_13261) & (2 * offset_13281 - 1)) == 0) {\n                    // read array element\n                    {\n                        y_13270 = ((volatile __local bool *) red_arr_mem_13265)[sext_i32_i64(local_tid_13259 + offset_13281)];\n                    }\n                    // apply reduction operation\n                    {\n                        bool binlam_res_13271 = x_13269 && y_13270;\n                        \n                        x_13269 = binlam_res_13271;\n                    }\n                    // write result of operation\n   ", "                 {\n                        ((volatile __local bool *) red_arr_mem_13265)[sext_i32_i64(local_tid_13259)] = x_13269;\n                    }\n                }\n                offset_13281 *= 2;\n            }\n            while (slt32(skip_waves_13282, squot32(sext_i64_i32(segred_group_sizze_12291) + wave_sizze_13261 - 1, wave_sizze_13261))) {\n                barrier(CLK_LOCAL_MEM_FENCE);\n                offset_13281 = skip_waves_13282 * wave_sizze_13261;\n                if (slt32(local_tid_13259 + offset_13281, sext_i64_i32(segred_group_sizze_12291)) && ((local_tid_13259 - squot32(local_tid_13259, wave_sizze_13261) * wave_sizze_13261) == 0 && (squot32(local_tid_13259, wave_sizze_13261) & (2 * skip_waves_13282 - 1)) == 0)) {\n                    // read array element\n                    {\n                        y_13270 = ((__local bool *) red_arr_mem_13265)[sext_i32_i64(local_tid_13259 + offset_13281)];\n                    }\n                    // apply reduction operation\n                    {\n                        bool binlam_res_13271 = x_13269 && y_13270;\n                        \n                        x_13269 = binlam_res_13271;\n                    }\n                    // write result of operation\n                    {\n                        ((__local bool *) red_arr_mem_13265)[sext_i32_i64(local_tid_13259)] = x_13269;\n                    }\n                }\n                skip_waves_13282 *= 2;\n            }\n            barrier(CLK_LOCAL_MEM_FENCE);\n            // Copy array-typed operands to result array\n            {\n                if (local_tid_13259 == 0) { }\n            }\n            // and back to memory with the final result\n            {\n                if (local_tid_13259 == 0) {\n                    ((__global bool *) mem_12970)[(int64_t) 0] = x_13269;\n                }\n            }\n        }\n    }\n    \n  error_5:\n    return;\n    #undef segred_group_sizze_12291\n}\nFUTHARK_KERNEL_SIZED(big_mul_validationzisegscan_group_sizze_12282, 1, ",
                                    "1)\nvoid big_mul_validationzisegscan_12288(__global int *global_failure, int64_t local_mem_13135_backing_offset_0, int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, int64_t dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, int64_t num_groups_13078, __global unsigned char *mem_12924, __global unsigned char *mem_12927, __global unsigned char *mem_12960, __global unsigned char *mem_12964, __global unsigned char *mem_12967, __global unsigned char *id_counter_mem_13080, __global unsigned char *status_flags_mem_13102, __global unsigned char *aggregates_mem_13104, __global unsigned char *incprefixes_mem_13106)\n{\n    #define segscan_group_sizze_12283 (big_mul_validationzisegscan_group_sizze_12282)\n    \n    volatile __local unsigned char *local_mem_13135_backing_0 = &local_mem[local_mem_13135_backing_offset_0];\n    \n    if (*global_failure >= 0)\n        return;\n    \n    int32_t local_tid_13129;\n    int64_t group_sizze_13132;\n    int32_t wave_sizze_13131;\n    int32_t group_tid_13130;\n    int32_t global_tid_13128;\n    int32_t phys_tid_12288;\n    int64_t byte_offsets_13133;\n    int64_t warp_byte_offset_13134;\n    __local unsigned char *local_mem_13135;\n    int64_t trans_arr_len_13136;\n    int32_t dynamic_id_13142;\n    int64_t blockOff_13143;\n    int64_t sgm_idx_13144;\n    int32_t boundary_13145;\n    int32_t segsizze_compact_13146;\n    int32_t private_mem_13147[(int64_t) 23];\n    int32_t acc_13171;\n    int32_t prefix_13187;\n    bool block_new_sgm_13188;\n    \n    local_tid_13129 = get_local_id(0);\n    group_sizze_13132 = get_local_size(0);\n    wave_sizze_13131 = LOCKSTEP_WIDTH;\n    group_tid_13130 = get_group_id(0);\n    global_tid_13128 = group_tid_13130 * group_sizze_13132 + local_tid_13129;\n    phys_tid_12288 = global_tid_13128;\n    byte_offsets_13133 = segscan_group_sizze_12283 * (int64_t) 4;\n    warp_byte_offset_13134 = (int64_t) 160;\n    // Allocate reused shared memeory\n    { }\n    local_mem_13135 = (__local unsigned char *) local_mem_13135_backing_0;\n    trans_arr_len_13136 = (int64_t) 23 * ", "segscan_group_sizze_12283;\n    if (local_tid_13129 == 0) {\n        dynamic_id_13142 = atomic_add_i32_global(&((volatile __global int *) id_counter_mem_13080)[(int64_t) 0], (int) 1);\n        ((__local int32_t *) local_mem_13135)[(int64_t) 0] = dynamic_id_13142;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    dynamic_id_13142 = ((__local int32_t *) local_mem_13135)[(int64_t) 0];\n    barrier(CLK_LOCAL_MEM_FENCE);\n    blockOff_13143 = sext_i32_i64(dynamic_id_13142) * (int64_t) 23 * segscan_group_sizze_12283;\n    sgm_idx_13144 = smod64(blockOff_13143, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);\n    boundary_13145 = sext_i64_i32(smin64((int64_t) 23 * segscan_group_sizze_12283, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212 - sgm_idx_13144));\n    segsizze_compact_13146 = sext_i64_i32(smin64((int64_t) 23 * segscan_group_sizze_12283, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212));\n    // Load and map\n    {\n        for (int64_t i_13149 = 0; i_13149 < (int64_t) 23; i_13149++) {\n            int64_t phys_tid_13150 = blockOff_13143 + sext_i32_i64(local_tid_13129) + i_13149 * segscan_group_sizze_12283;\n            int64_t slice_13151 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n            int64_t gtid_12287 = phys_tid_13150;\n            int64_t remnant_13152 = phys_tid_13150 - gtid_12287;\n            \n            if (slt64(phys_tid_13150, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212)) {\n                bool index_concat_cmp_12874 = sle64(dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, gtid_12287);\n                int64_t index_concat_branch_12878;\n                \n                if (index_concat_cmp_12874 == 1) {\n                    int64_t index_concat_i_12875 = sub64(gtid_12287, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183);\n                    int64_t index_concat_12876 = ((__global int64_t *) mem_12924)[index_concat_i_12875];\n                    \n                    index_concat_branch_12878 = index_concat_12876;\n                } else {\n                    int64_t index_concat_12877 = ((__global int64_t *) mem_12927)[gtid_12287];\n       ", "             \n                    index_concat_branch_12878 = index_concat_12877;\n                }\n                \n                bool index_concat_cmp_12868 = sle64((int64_t) 2, gtid_12287);\n                int64_t index_concat_branch_12872;\n                \n                if (index_concat_cmp_12868 == 1) {\n                    int64_t index_concat_12870 = ((__global int64_t *) mem_12960)[gtid_12287];\n                    \n                    index_concat_branch_12872 = index_concat_12870;\n                } else {\n                    index_concat_branch_12872 = (int64_t) 0;\n                }\n                \n                int64_t s_11577 = add64(index_concat_branch_12872, index_concat_branch_12878);\n                bool bool_arg0_11578 = ult64(s_11577, index_concat_branch_12878);\n                int32_t unsign_arg0_11579 = btoi_bool_i32(bool_arg0_11578);\n                bool bool_arg0_11580 = s_11577 == (int64_t) -1;\n                int32_t unsign_arg0_11581 = btoi_bool_i32(bool_arg0_11580);\n                int32_t zb_rhs_11582 = shl32(unsign_arg0_11581, 1);\n                int32_t c_11583 = unsign_arg0_11579 | zb_rhs_11582;\n                \n                ((__global int64_t *) mem_12967)[gtid_12287] = s_11577;\n                private_mem_13147[i_13149] = c_11583;\n            } else {\n                private_mem_13147[i_13149] = 2;\n            }\n        }\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n    // Transpose scan inputs\n    {\n        for (int64_t i_13153 = 0; i_13153 < (int64_t) 23; i_13153++) {\n            int64_t sharedIdx_13154 = sext_i32_i64(local_tid_13129) + i_13153 * segscan_group_sizze_12283;\n            int32_t tmp_13155 = private_mem_13147[i_13153];\n            \n            ((__local int32_t *) local_mem_13135)[sharedIdx_13154] = tmp_13155;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int32_t i_13156 = 0; i_13156 < 23; i_13156++) {\n            int32_t sharedIdx_13157 = local_tid_13129 * 23 + i_13156;\n            int32_t tmp_13158 =",
                                    " ((__local int32_t *) local_mem_13135)[sext_i32_i64(sharedIdx_13157)];\n            \n            private_mem_13147[sext_i32_i64(i_13156)] = tmp_13158;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // Per thread scan\n    {\n        int32_t gidx_13159 = local_tid_13129 * 23 + 1;\n        \n        for (int64_t i_13160 = 0; i_13160 < (int64_t) 22; i_13160++) {\n            int32_t eta_p_11517;\n            int32_t eta_p_11518;\n            \n            eta_p_11517 = private_mem_13147[i_13160];\n            eta_p_11518 = private_mem_13147[i_13160 + (int64_t) 1];\n            \n            int32_t za_lhs_11519 = eta_p_11517 & eta_p_11518;\n            int32_t zb_lhs_11520 = 2 & za_lhs_11519;\n            int32_t za_rhs_11521 = lshr32(eta_p_11518, 1);\n            int32_t zb_lhs_11522 = eta_p_11517 & za_rhs_11521;\n            int32_t za_lhs_11523 = eta_p_11518 | zb_lhs_11522;\n            int32_t zb_rhs_11524 = 1 & za_lhs_11523;\n            int32_t carry_prop_res_11525 = zb_lhs_11520 | zb_rhs_11524;\n            \n            private_mem_13147[i_13160 + (int64_t) 1] = carry_prop_res_11525;\n        }\n    }\n    // Publish results in shared memory\n    {\n        int32_t tmp_13161 = private_mem_13147[(int64_t) 22];\n        \n        ((__local int32_t *) local_mem_13135)[sext_i32_i64(local_tid_13129)] = tmp_13161;\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // Scan results (with warp scan)\n    {\n        int32_t eta_p_13162;\n        int32_t eta_p_13163;\n        int32_t eta_p_13172;\n        int32_t eta_p_13173;\n        bool ltid_in_bounds_13181 = slt64(sext_i32_i64(local_tid_13129), segscan_group_sizze_12283);\n        int32_t skip_threads_13182;\n        \n        // read input for in-block scan\n        {\n            if (ltid_in_bounds_13181) {\n                eta_p_13163 = ((volatile __local int32_t *) local_mem_13135)[sext_i32_i64(local_tid_13129)];\n                if ((local_tid_13129 - squot32(local_tid_13129, 32) * 32) == 0) {\n                    eta_p_13162 = eta_p_13163;\n    ", "            }\n            }\n        }\n        // in-block scan (hopefully no barriers needed)\n        {\n            skip_threads_13182 = 1;\n            while (slt32(skip_threads_13182, 32)) {\n                bool thread_active_13183 = sle32(skip_threads_13182, local_tid_13129 - squot32(local_tid_13129, 32) * 32) && ltid_in_bounds_13181;\n                \n                if (thread_active_13183) {\n                    // read operands\n                    {\n                        eta_p_13162 = ((volatile __local int32_t *) local_mem_13135)[sext_i32_i64(local_tid_13129) - sext_i32_i64(skip_threads_13182)];\n                    }\n                }\n                // perform operation\n                {\n                    if (thread_active_13183) {\n                        int32_t za_lhs_13164 = eta_p_13162 & eta_p_13163;\n                        int32_t zb_lhs_13165 = 2 & za_lhs_13164;\n                        int32_t za_rhs_13166 = lshr32(eta_p_13163, 1);\n                        int32_t zb_lhs_13167 = eta_p_13162 & za_rhs_13166;\n                        int32_t za_lhs_13168 = eta_p_13163 | zb_lhs_13167;\n                        int32_t zb_rhs_13169 = 1 & za_lhs_13168;\n                        int32_t carry_prop_res_13170 = zb_lhs_13165 | zb_rhs_13169;\n                        \n                        eta_p_13162 = carry_prop_res_13170;\n                    }\n                }\n                if (sle32(wave_sizze_13131, skip_threads_13182)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                if (thread_active_13183) {\n                    // write result\n                    {\n                        ((volatile __local int32_t *) local_mem_13135)[sext_i32_i64(local_tid_13129)] = eta_p_13162;\n                        eta_p_13163 = eta_p_13162;\n                    }\n                }\n                if (sle32(wave_sizze_13131, skip_threads_13182)) {\n                    barrier(CLK_LOCAL_MEM_FENCE);\n                }\n                skip_threads_13182 ", "*= 2;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // last thread of block 'i' writes its result to offset 'i'\n        {\n            if ((local_tid_13129 - squot32(local_tid_13129, 32) * 32) == 31 && ltid_in_bounds_13181) {\n                ((volatile __local int32_t *) local_mem_13135)[sext_i32_i64(squot32(local_tid_13129, 32))] = eta_p_13162;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // scan the first block, after which offset 'i' contains carry-in for block 'i+1'\n        {\n            int32_t skip_threads_13184;\n            \n            // read input for in-block scan\n            {\n                if (squot32(local_tid_13129, 32) == 0 && ltid_in_bounds_13181) {\n                    eta_p_13173 = ((volatile __local int32_t *) local_mem_13135)[sext_i32_i64(local_tid_13129)];\n                    if ((local_tid_13129 - squot32(local_tid_13129, 32) * 32) == 0) {\n                        eta_p_13172 = eta_p_13173;\n                    }\n                }\n            }\n            // in-block scan (hopefully no barriers needed)\n            {\n                skip_threads_13184 = 1;\n                while (slt32(skip_threads_13184, 32)) {\n                    bool thread_active_13185 = sle32(skip_threads_13184, local_tid_13129 - squot32(local_tid_13129, 32) * 32) && (squot32(local_tid_13129, 32) == 0 && ltid_in_bounds_13181);\n                    \n                    if (thread_active_13185) {\n                        // read operands\n                        {\n                            eta_p_13172 = ((volatile __local int32_t *) local_mem_13135)[sext_i32_i64(local_tid_13129) - sext_i32_i64(skip_threads_13184)];\n                        }\n                    }\n                    // perform operation\n                    {\n                        if (thread_active_13185) {\n                            int32_t za_lhs_13174 = eta_p_13172 & eta_p_13173;\n                            int32_t zb_lhs_13175 = 2 & za_lhs_13174;\n           ",
                                    "                 int32_t za_rhs_13176 = lshr32(eta_p_13173, 1);\n                            int32_t zb_lhs_13177 = eta_p_13172 & za_rhs_13176;\n                            int32_t za_lhs_13178 = eta_p_13173 | zb_lhs_13177;\n                            int32_t zb_rhs_13179 = 1 & za_lhs_13178;\n                            int32_t carry_prop_res_13180 = zb_lhs_13175 | zb_rhs_13179;\n                            \n                            eta_p_13172 = carry_prop_res_13180;\n                        }\n                    }\n                    if (sle32(wave_sizze_13131, skip_threads_13184)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    if (thread_active_13185) {\n                        // write result\n                        {\n                            ((volatile __local int32_t *) local_mem_13135)[sext_i32_i64(local_tid_13129)] = eta_p_13172;\n                            eta_p_13173 = eta_p_13172;\n                        }\n                    }\n                    if (sle32(wave_sizze_13131, skip_threads_13184)) {\n                        barrier(CLK_LOCAL_MEM_FENCE);\n                    }\n                    skip_threads_13184 *= 2;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        \n        bool no_carry_in_13186 = squot32(local_tid_13129, 32) == 0 || !ltid_in_bounds_13181;\n        \n        // carry-in for every block except the first\n        {\n            // read operands\n            {\n                if (!no_carry_in_13186) {\n                    eta_p_13163 = eta_p_13162;\n                    eta_p_13162 = ((__local int32_t *) local_mem_13135)[sext_i32_i64(squot32(local_tid_13129, 32)) - (int64_t) 1];\n                }\n            }\n            // perform operation\n            {\n                if (!no_carry_in_13186) {\n                    int32_t za_lhs_13164 = eta_p_13162 & eta_p_13163;\n                    int32_t zb_lhs_13165 = 2 & za_lhs_13164;\n                    int32_t za_rhs_", "13166 = lshr32(eta_p_13163, 1);\n                    int32_t zb_lhs_13167 = eta_p_13162 & za_rhs_13166;\n                    int32_t za_lhs_13168 = eta_p_13163 | zb_lhs_13167;\n                    int32_t zb_rhs_13169 = 1 & za_lhs_13168;\n                    int32_t carry_prop_res_13170 = zb_lhs_13165 | zb_rhs_13169;\n                    \n                    eta_p_13162 = carry_prop_res_13170;\n                }\n            }\n            // write final result\n            {\n                if (!no_carry_in_13186) {\n                    ((__local int32_t *) local_mem_13135)[sext_i32_i64(local_tid_13129)] = eta_p_13162;\n                }\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        // restore correct values for first block\n        {\n            if (squot32(local_tid_13129, 32) == 0 && ltid_in_bounds_13181) {\n                ((__local int32_t *) local_mem_13135)[sext_i32_i64(local_tid_13129)] = eta_p_13163;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if (local_tid_13129 == 0) {\n            acc_13171 = ((__local int32_t *) local_mem_13135)[segscan_group_sizze_12283 - (int64_t) 1];\n        } else {\n            acc_13171 = ((__local int32_t *) local_mem_13135)[sext_i32_i64(local_tid_13129) - (int64_t) 1];\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    prefix_13187 = 2;\n    block_new_sgm_13188 = sgm_idx_13144 == (int64_t) 0;\n    // Perform lookback\n    {\n        if (block_new_sgm_13188 && local_tid_13129 == 0) {\n            ((volatile __global int32_t *) incprefixes_mem_13106)[dynamic_id_13142] = acc_13171;\n            mem_fence_global();\n            ((volatile __global int8_t *) status_flags_mem_13102)[dynamic_id_13142] = (int8_t) 2;\n            acc_13171 = 2;\n        }\n        if (!block_new_sgm_13188 && slt32(local_tid_13129, wave_sizze_13131)) {\n            if (local_tid_13129 == 0) {\n                ((volatile __global int32_t *) aggregates_mem_13104)[dynamic_id_13142] = acc_13", "171;\n                mem_fence_global();\n                ((volatile __global int8_t *) status_flags_mem_13102)[dynamic_id_13142] = (int8_t) 1;\n                \n                int8_t tmp_13189 = ((volatile __global int8_t *) status_flags_mem_13102)[dynamic_id_13142 - (int64_t) 1];\n                \n                ((volatile __local int8_t *) local_mem_13135)[(int64_t) 0] = tmp_13189;\n            }\n            mem_fence_local();\n            \n            int8_t status_13190 = ((__local int8_t *) local_mem_13135)[(int64_t) 0];\n            \n            if (status_13190 == (int8_t) 2) {\n                if (local_tid_13129 == 0) {\n                    prefix_13187 = ((volatile __global int32_t *) incprefixes_mem_13106)[dynamic_id_13142 - (int64_t) 1];\n                }\n            } else {\n                int32_t readOffset_13191 = dynamic_id_13142 - sext_i32_i64(wave_sizze_13131);\n                \n                while (slt32(wave_sizze_13131 * -1, readOffset_13191)) {\n                    int32_t read_i_13192 = readOffset_13191 + local_tid_13129;\n                    int32_t aggr_13193 = 2;\n                    int8_t flag_13194 = (int8_t) 0;\n                    \n                    if (sle32(0, read_i_13192)) {\n                        flag_13194 = ((volatile __global int8_t *) status_flags_mem_13102)[sext_i32_i64(read_i_13192)];\n                        if (flag_13194 == (int8_t) 2) {\n                            aggr_13193 = ((volatile __global int32_t *) incprefixes_mem_13106)[sext_i32_i64(read_i_13192)];\n                        } else if (flag_13194 == (int8_t) 1) {\n                            aggr_13193 = ((volatile __global int32_t *) aggregates_mem_13104)[sext_i32_i64(read_i_13192)];\n                        }\n                    }\n                    ((__local int32_t *) local_mem_13135)[(int64_t) 8 + sext_i32_i64(local_tid_13129)] = aggr_13193;\n                    ((__local int8_t *) local_mem_13135)[sext_i32_i64(local_tid_13129)] = flag_13194;\n                    fla",
                                    "g_13194 = ((__local int8_t *) local_mem_13135)[sext_i32_i64(wave_sizze_13131) - (int64_t) 1];\n                    if (slt8(flag_13194, (int8_t) 2)) {\n                        int8_t flg_x_13204;\n                        int8_t flg_y_13205;\n                        int32_t eta_p_13195;\n                        int32_t eta_p_13196;\n                        int32_t skip_threads_13206;\n                        \n                        // read input for in-block scan\n                        {\n                            flg_y_13205 = ((volatile __local int8_t *) local_mem_13135)[sext_i32_i64(local_tid_13129)];\n                            eta_p_13196 = ((volatile __local int32_t *) local_mem_13135)[(int64_t) 8 + sext_i32_i64(local_tid_13129)];\n                            if ((local_tid_13129 - squot32(local_tid_13129, 32) * 32) == 0) {\n                                eta_p_13195 = eta_p_13196;\n                                flg_x_13204 = flg_y_13205;\n                            }\n                        }\n                        // in-block scan (hopefully no barriers needed)\n                        {\n                            skip_threads_13206 = 1;\n                            while (slt32(skip_threads_13206, 32)) {\n                                if (sle32(skip_threads_13206, local_tid_13129 - squot32(local_tid_13129, 32) * 32)) {\n                                    // read operands\n                                    {\n                                        flg_x_13204 = ((volatile __local int8_t *) local_mem_13135)[sext_i32_i64(local_tid_13129) - sext_i32_i64(skip_threads_13206)];\n                                        eta_p_13195 = ((volatile __local int32_t *) local_mem_13135)[(int64_t) 8 + (sext_i32_i64(local_tid_13129) - sext_i32_i64(skip_threads_13206))];\n                                    }\n                                    // perform operation\n                                    {\n                                        if (flg_y_13205 == (int8_t) 2 || flg_y_", "13205 == (int8_t) 0) {\n                                            flg_x_13204 = flg_y_13205;\n                                            eta_p_13195 = eta_p_13196;\n                                        } else {\n                                            int32_t za_lhs_13197 = eta_p_13195 & eta_p_13196;\n                                            int32_t zb_lhs_13198 = 2 & za_lhs_13197;\n                                            int32_t za_rhs_13199 = lshr32(eta_p_13196, 1);\n                                            int32_t zb_lhs_13200 = eta_p_13195 & za_rhs_13199;\n                                            int32_t za_lhs_13201 = eta_p_13196 | zb_lhs_13200;\n                                            int32_t zb_rhs_13202 = 1 & za_lhs_13201;\n                                            int32_t carry_prop_res_13203 = zb_lhs_13198 | zb_rhs_13202;\n                                            \n                                            eta_p_13195 = carry_prop_res_13203;\n                                        }\n                                    }\n                                    // write result\n                                    {\n                                        ((volatile __local int8_t *) local_mem_13135)[sext_i32_i64(local_tid_13129)] = flg_x_13204;\n                                        flg_y_13205 = flg_x_13204;\n                                        ((volatile __local int32_t *) local_mem_13135)[(int64_t) 8 + sext_i32_i64(local_tid_13129)] = eta_p_13195;\n                                        eta_p_13196 = eta_p_13195;\n                                    }\n                                }\n                                skip_threads_13206 *= 2;\n                            }\n                        }\n                    }\n                    flag_13194 = ((__local int8_t *) local_mem_13135)[sext_i32_i64(wave_sizze_13131) - (int64_t) 1];\n                    aggr_13193 = ((__local int32_t *) local_mem_13135)[(int64_t) 8 + (sext_i32_i64(wave_s", "izze_13131) - (int64_t) 1)];\n                    if (flag_13194 == (int8_t) 2) {\n                        readOffset_13191 = wave_sizze_13131 * -1;\n                    } else if (flag_13194 == (int8_t) 1) {\n                        readOffset_13191 -= wave_sizze_13131;\n                    }\n                    if (slt8((int8_t) 0, flag_13194)) {\n                        int32_t eta_p_13207 = aggr_13193;\n                        int32_t eta_p_13208 = prefix_13187;\n                        int32_t za_lhs_13209 = eta_p_13207 & eta_p_13208;\n                        int32_t zb_lhs_13210 = 2 & za_lhs_13209;\n                        int32_t za_rhs_13211 = lshr32(eta_p_13208, 1);\n                        int32_t zb_lhs_13212 = eta_p_13207 & za_rhs_13211;\n                        int32_t za_lhs_13213 = eta_p_13208 | zb_lhs_13212;\n                        int32_t zb_rhs_13214 = 1 & za_lhs_13213;\n                        int32_t carry_prop_res_13215 = zb_lhs_13210 | zb_rhs_13214;\n                        \n                        prefix_13187 = carry_prop_res_13215;\n                    }\n                    mem_fence_local();\n                }\n            }\n            if (local_tid_13129 == 0) {\n                if (boundary_13145 == sext_i64_i32(segscan_group_sizze_12283 * (int64_t) 23)) {\n                    int32_t eta_p_13216 = prefix_13187;\n                    int32_t eta_p_13217 = acc_13171;\n                    int32_t za_lhs_13218 = eta_p_13216 & eta_p_13217;\n                    int32_t zb_lhs_13219 = 2 & za_lhs_13218;\n                    int32_t za_rhs_13220 = lshr32(eta_p_13217, 1);\n                    int32_t zb_lhs_13221 = eta_p_13216 & za_rhs_13220;\n                    int32_t za_lhs_13222 = eta_p_13217 | zb_lhs_13221;\n                    int32_t zb_rhs_13223 = 1 & za_lhs_13222;\n                    int32_t carry_prop_res_13224 = zb_lhs_13219 | zb_rhs_13223;\n                    \n                    ((volatile __global int32_t *) incprefixes_mem_13106)[dynamic_id_13142] = carry_p",
                                    "rop_res_13224;\n                    mem_fence_global();\n                    ((volatile __global int8_t *) status_flags_mem_13102)[dynamic_id_13142] = (int8_t) 2;\n                }\n                ((__local int32_t *) local_mem_13135)[(int64_t) 8] = prefix_13187;\n                acc_13171 = 2;\n            }\n        }\n        if (!(dynamic_id_13142 == (int64_t) 0)) {\n            barrier(CLK_LOCAL_MEM_FENCE);\n            prefix_13187 = ((__local int32_t *) local_mem_13135)[(int64_t) 8];\n            barrier(CLK_LOCAL_MEM_FENCE);\n        }\n    }\n    // Distribute results\n    {\n        int32_t eta_p_13225;\n        int32_t eta_p_13226;\n        int32_t eta_p_13234 = prefix_13187;\n        int32_t eta_p_13235 = acc_13171;\n        \n        if (slt32(local_tid_13129 * 23, boundary_13145) && !block_new_sgm_13188) {\n            int32_t za_lhs_13236 = eta_p_13234 & eta_p_13235;\n            int32_t zb_lhs_13237 = 2 & za_lhs_13236;\n            int32_t za_rhs_13238 = lshr32(eta_p_13235, 1);\n            int32_t zb_lhs_13239 = eta_p_13234 & za_rhs_13238;\n            int32_t za_lhs_13240 = eta_p_13235 | zb_lhs_13239;\n            int32_t zb_rhs_13241 = 1 & za_lhs_13240;\n            int32_t carry_prop_res_13242 = zb_lhs_13237 | zb_rhs_13241;\n            \n            eta_p_13225 = carry_prop_res_13242;\n        } else {\n            eta_p_13225 = acc_13171;\n        }\n        \n        int32_t stopping_point_13243 = segsizze_compact_13146 - srem32(local_tid_13129 * 23 - 1 + segsizze_compact_13146 - boundary_13145, segsizze_compact_13146);\n        \n        for (int64_t i_13244 = 0; i_13244 < (int64_t) 23; i_13244++) {\n            if (slt32(sext_i64_i32(i_13244), stopping_point_13243 - 1)) {\n                eta_p_13226 = private_mem_13147[i_13244];\n                \n                int32_t za_lhs_13227 = eta_p_13225 & eta_p_13226;\n                int32_t zb_lhs_13228 = 2 & za_lhs_13227;\n                int32_t za_rhs_13229 = lshr32(eta_p_13226, 1);\n                int32_t zb_lhs_13230 = eta_p_1322", "5 & za_rhs_13229;\n                int32_t za_lhs_13231 = eta_p_13226 | zb_lhs_13230;\n                int32_t zb_rhs_13232 = 1 & za_lhs_13231;\n                int32_t carry_prop_res_13233 = zb_lhs_13228 | zb_rhs_13232;\n                \n                private_mem_13147[i_13244] = carry_prop_res_13233;\n            }\n        }\n    }\n    // Transpose scan output and Write it to global memory in coalesced fashion\n    {\n        for (int64_t i_13245 = 0; i_13245 < (int64_t) 23; i_13245++) {\n            int64_t sharedIdx_13246 = sext_i32_i64(local_tid_13129 * 23) + i_13245;\n            int32_t tmp_13247 = private_mem_13147[i_13245];\n            \n            ((__local int32_t *) local_mem_13135)[sharedIdx_13246] = tmp_13247;\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n        for (int64_t i_13248 = 0; i_13248 < (int64_t) 23; i_13248++) {\n            int64_t flat_idx_13249 = blockOff_13143 + segscan_group_sizze_12283 * i_13248 + sext_i32_i64(local_tid_13129);\n            int64_t slice_13250 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10212;\n            int64_t gtid_12287 = flat_idx_13249;\n            int64_t remnant_13251 = flat_idx_13249 - gtid_12287;\n            \n            if (slt64(flat_idx_13249, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212)) {\n                int32_t tmp_13252 = ((__local int32_t *) local_mem_13135)[flat_idx_13249 - blockOff_13143];\n                \n                ((__global int32_t *) mem_12964)[gtid_12287] = tmp_13252;\n            }\n        }\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    // If this is the last block, reset the dynamicId\n    {\n        if (dynamic_id_13142 == num_groups_13078 - (int64_t) 1) {\n            ((__global int32_t *) id_counter_mem_13080)[(int64_t) 0] = 0;\n        }\n    }\n    \n  error_3:\n    return;\n    #undef segscan_group_sizze_12283\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i32zireplicate_13090(int64_t num_elems_13086, int32_t val_13087, int64_t replicate_n_13089, int64_t virt_num_groups_13095, int64_t num_groups_13096, __global unsigned ", "char *mem_13085)\n{\n    int32_t replicate_ltid_13091;\n    int64_t group_sizze_13093;\n    int32_t replicate_gid_13092;\n    int32_t replicate_gtid_13090;\n    int32_t phys_group_id_13097;\n    int32_t iterations_13098;\n    \n    replicate_ltid_13091 = get_local_id(0);\n    group_sizze_13093 = get_local_size(0);\n    replicate_gid_13092 = get_group_id(0);\n    replicate_gtid_13090 = replicate_gid_13092 * group_sizze_13093 + replicate_ltid_13091;\n    phys_group_id_13097 = get_group_id(0);\n    iterations_13098 = sdiv_up32(sext_i64_i32(virt_num_groups_13095) - phys_group_id_13097, sext_i64_i32(num_groups_13096));\n    for (int32_t i_13099 = 0; i_13099 < iterations_13098; i_13099++) {\n        int32_t virt_group_id_13100;\n        int64_t global_tid_13101;\n        int64_t slice_13103;\n        int64_t rep_i_13102;\n        int64_t remnant_13104;\n        \n        virt_group_id_13100 = phys_group_id_13097 + i_13099 * sext_i64_i32(num_groups_13096);\n        global_tid_13101 = sext_i32_i64(virt_group_id_13100) * sext_i32_i64(group_sizze_13093) + sext_i32_i64(replicate_ltid_13091);\n        slice_13103 = num_elems_13086;\n        rep_i_13102 = global_tid_13101;\n        remnant_13104 = global_tid_13101 - rep_i_13102;\n        if (slt64(global_tid_13101, replicate_n_13089)) {\n            ((__global int32_t *) mem_13085)[rep_i_13102] = val_13087;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i64zireplicate_13010(int64_t num_elems_13006, int64_t val_13007, int64_t replicate_n_13009, int64_t virt_num_groups_13015, int64_t num_groups_13016, __global unsigned char *mem_13005)\n{\n    int32_t replicate_ltid_13011;\n    int64_t group_sizze_13013;\n    int32_t replicate_gid_13012;\n    int32_t replicate_gtid_13010;\n    int32_t phys_group_id_13017;\n    int32_t iterations_13018;\n    \n    replicate_ltid_13011 = get_local_id(0);\n    group_sizze_13013 = get_local_size(0);\n    replicate_gid_13012 = get_group_id(0);",
                                    "\n    replicate_gtid_13010 = replicate_gid_13012 * group_sizze_13013 + replicate_ltid_13011;\n    phys_group_id_13017 = get_group_id(0);\n    iterations_13018 = sdiv_up32(sext_i64_i32(virt_num_groups_13015) - phys_group_id_13017, sext_i64_i32(num_groups_13016));\n    for (int32_t i_13019 = 0; i_13019 < iterations_13018; i_13019++) {\n        int32_t virt_group_id_13020;\n        int64_t global_tid_13021;\n        int64_t slice_13023;\n        int64_t rep_i_13022;\n        int64_t remnant_13024;\n        \n        virt_group_id_13020 = phys_group_id_13017 + i_13019 * sext_i64_i32(num_groups_13016);\n        global_tid_13021 = sext_i32_i64(virt_group_id_13020) * sext_i32_i64(group_sizze_13013) + sext_i32_i64(replicate_ltid_13011);\n        slice_13023 = num_elems_13006;\n        rep_i_13022 = global_tid_13021;\n        remnant_13024 = global_tid_13021 - rep_i_13022;\n        if (slt64(global_tid_13021, replicate_n_13009)) {\n            ((__global int64_t *) mem_13005)[rep_i_13022] = val_13007;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\nFUTHARK_KERNEL\nvoid builtinzhreplicate_i8zireplicate_13116(int64_t num_elems_13112, int8_t val_13113, int64_t replicate_n_13115, int64_t virt_num_groups_13121, int64_t num_groups_13122, __global unsigned char *mem_13111)\n{\n    int32_t replicate_ltid_13117;\n    int64_t group_sizze_13119;\n    int32_t replicate_gid_13118;\n    int32_t replicate_gtid_13116;\n    int32_t phys_group_id_13123;\n    int32_t iterations_13124;\n    \n    replicate_ltid_13117 = get_local_id(0);\n    group_sizze_13119 = get_local_size(0);\n    replicate_gid_13118 = get_group_id(0);\n    replicate_gtid_13116 = replicate_gid_13118 * group_sizze_13119 + replicate_ltid_13117;\n    phys_group_id_13123 = get_group_id(0);\n    iterations_13124 = sdiv_up32(sext_i64_i32(virt_num_groups_13121) - phys_group_id_13123, sext_i64_i32(num_groups_13122));\n    for (int32_t i_13125 = 0; i_13125 < iterations_13124; i_13125++) {\n        int32_t vir", "t_group_id_13126;\n        int64_t global_tid_13127;\n        int64_t slice_13129;\n        int64_t rep_i_13128;\n        int64_t remnant_13130;\n        \n        virt_group_id_13126 = phys_group_id_13123 + i_13125 * sext_i64_i32(num_groups_13122);\n        global_tid_13127 = sext_i32_i64(virt_group_id_13126) * sext_i32_i64(group_sizze_13119) + sext_i32_i64(replicate_ltid_13117);\n        slice_13129 = num_elems_13112;\n        rep_i_13128 = global_tid_13127;\n        remnant_13130 = global_tid_13127 - rep_i_13128;\n        if (slt64(global_tid_13127, replicate_n_13115)) {\n            ((__global int8_t *) mem_13111)[rep_i_13128] = val_13113;\n        }\n        barrier(CLK_GLOBAL_MEM_FENCE | CLK_LOCAL_MEM_FENCE);\n    }\n    \n  error_1:\n    return;\n}\n", NULL};
// Start of gpu_prototypes.h

// Constants used for transpositions.  In principle these should be configurable.
#define TR_BLOCK_DIM 16
#define TR_TILE_DIM (TR_BLOCK_DIM*2)
#define TR_ELEMS_PER_THREAD 8

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);
static int gpu_free_all(struct futhark_context *ctx);

// End of gpu_prototypes.h

// Start of backends/cuda.h.

// Forward declarations.
// Invoked by setup_opencl() after the platform and device has been
// found, but before the program is loaded.  Its intended use is to
// tune constants based on the selected platform and device.
static void set_tuning_params(struct futhark_context* ctx);
static char* get_failure_msg(int failure_idx, int64_t args[]);

#define CUDA_SUCCEED_FATAL(x) cuda_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define CUDA_SUCCEED_NONFATAL(x) cuda_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_FATAL(x) nvrtc_api_succeed_fatal(x, #x, __FILE__, __LINE__)
#define NVRTC_SUCCEED_NONFATAL(x) nvrtc_api_succeed_nonfatal(x, #x, __FILE__, __LINE__)
// Take care not to override an existing error.
#define CUDA_SUCCEED_OR_RETURN(e) {             \
    char *serror = CUDA_SUCCEED_NONFATAL(e);    \
    if (serror) {                               \
      if (!ctx->error) {                        \
        ctx->error = serror;                    \
        return bad;                             \
      } else {                                  \
        free(serror);                           \
      }                                         \
    }                                           \
  }

// CUDA_SUCCEED_OR_RETURN returns the value of the variable 'bad' in
// scope.  By default, it will be this one.  Create a local variable
// of some other type if needed.  This is a bit of a hack, but it
// saves effort in the code generator.
static const int bad = 1;

static inline void cuda_api_succeed_fatal(CUresult res, const char *call,
                                          const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    futhark_panic(-1, "%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* cuda_api_succeed_nonfatal(CUresult res, const char *call,
                                       const char *file, int line) {
  if (res != CUDA_SUCCESS) {
    const char *err_str;
    cuGetErrorString(res, &err_str);
    if (err_str == NULL) { err_str = "Unknown"; }
    return msgprintf("%s:%d: CUDA call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

static inline void nvrtc_api_succeed_fatal(nvrtcResult res, const char *call,
                                           const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    futhark_panic(-1, "%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                  file, line, call, res, err_str);
  }
}

static char* nvrtc_api_succeed_nonfatal(nvrtcResult res, const char *call,
                                        const char *file, int line) {
  if (res != NVRTC_SUCCESS) {
    const char *err_str = nvrtcGetErrorString(res);
    return msgprintf("%s:%d: NVRTC call\n  %s\nfailed with error code %d (%s)\n",
                     file, line, call, res, err_str);
  } else {
    return NULL;
  }
}

struct futhark_context_config {
  int in_use;
  int debugging;
  int profiling;
  int logging;
  const char *cache_fname;
  int num_tuning_params;
  int64_t *tuning_params;
  const char** tuning_param_names;
  const char** tuning_param_vars;
  const char** tuning_param_classes;
  // Uniform fields above.

  char* program;
  int num_nvrtc_opts;
  const char **nvrtc_opts;

  const char *preferred_device;
  int preferred_device_num;

  const char *dump_ptx_to;
  const char *load_ptx_from;

  size_t default_block_size;
  size_t default_grid_size;
  size_t default_tile_size;
  size_t default_reg_tile_size;
  size_t default_threshold;

  int default_block_size_changed;
  int default_grid_size_changed;
  int default_tile_size_changed;
};

static void backend_context_config_setup(struct futhark_context_config *cfg) {
  cfg->num_nvrtc_opts = 0;
  cfg->nvrtc_opts = (const char**) malloc(sizeof(const char*));
  cfg->nvrtc_opts[0] = NULL;

  cfg->program = strconcat(gpu_program);

  cfg->preferred_device_num = 0;
  cfg->preferred_device = "";

  cfg->dump_ptx_to = NULL;
  cfg->load_ptx_from = NULL;

  cfg->default_block_size = 256;
  cfg->default_grid_size = 0; // Set properly later.
  cfg->default_tile_size = 32;
  cfg->default_reg_tile_size = 2;
  cfg->default_threshold = 32*1024;

  cfg->default_block_size_changed = 0;
  cfg->default_grid_size_changed = 0;
  cfg->default_tile_size_changed = 0;
}

static void backend_context_config_teardown(struct futhark_context_config* cfg) {
  free(cfg->nvrtc_opts);
}

void futhark_context_config_add_nvrtc_option(struct futhark_context_config *cfg, const char *opt) {
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = opt;
  cfg->num_nvrtc_opts++;
  cfg->nvrtc_opts = (const char **) realloc(cfg->nvrtc_opts, (cfg->num_nvrtc_opts + 1) * sizeof(const char *));
  cfg->nvrtc_opts[cfg->num_nvrtc_opts] = NULL;
}

void futhark_context_config_set_device(struct futhark_context_config *cfg, const char *s) {
  int x = 0;
  if (*s == '#') {
    s++;
    while (isdigit(*s)) {
      x = x * 10 + (*s++)-'0';
    }
    // Skip trailing spaces.
    while (isspace(*s)) {
      s++;
    }
  }
  cfg->preferred_device = s;
  cfg->preferred_device_num = x;
}

const char* futhark_context_config_get_program(struct futhark_context_config *cfg) {
  return cfg->program;
}

void futhark_context_config_set_program(struct futhark_context_config *cfg, const char *s) {
  cfg->program = strdup(s);
}

void futhark_context_config_dump_ptx_to(struct futhark_context_config *cfg, const char *path) {
  cfg->dump_ptx_to = path;
}

void futhark_context_config_load_ptx_from(struct futhark_context_config *cfg, const char *path) {
  cfg->load_ptx_from = path;
}

void futhark_context_config_set_default_group_size(struct futhark_context_config *cfg, int size) {
  cfg->default_block_size = size;
  cfg->default_block_size_changed = 1;
}

void futhark_context_config_set_default_num_groups(struct futhark_context_config *cfg, int num) {
  cfg->default_grid_size = num;
  cfg->default_grid_size_changed = 1;
}

void futhark_context_config_set_default_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->default_tile_size = size;
  cfg->default_tile_size_changed = 1;
}

void futhark_context_config_set_default_reg_tile_size(struct futhark_context_config *cfg, int size) {
  cfg->default_reg_tile_size = size;
}

void futhark_context_config_set_default_threshold(struct futhark_context_config *cfg, int size) {
  cfg->default_threshold = size;
}

int futhark_context_config_set_tuning_param(struct futhark_context_config *cfg,
                                            const char *param_name,
                                            size_t new_value) {
  for (int i = 0; i < cfg->num_tuning_params; i++) {
    if (strcmp(param_name, cfg->tuning_param_names[i]) == 0) {
      cfg->tuning_params[i] = new_value;
      return 0;
    }
  }
  if (strcmp(param_name, "default_group_size") == 0) {
    cfg->default_block_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_num_groups") == 0) {
    cfg->default_grid_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_threshold") == 0) {
    cfg->default_threshold = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_tile_size") == 0) {
    cfg->default_tile_size = new_value;
    return 0;
  }
  if (strcmp(param_name, "default_reg_tile_size") == 0) {
    cfg->default_reg_tile_size = new_value;
    return 0;
  }
  return 1;
}

// A record of something that happened.
struct profiling_record {
  cudaEvent_t *events; // Points to two events.
  const char *name;
};

struct futhark_context {
  struct futhark_context_config* cfg;
  int detail_memory;
  int debugging;
  int profiling;
  int profiling_paused;
  int logging;
  lock_t lock;
  char *error;
  lock_t error_lock;
  FILE *log;
  struct constants *constants;
  struct free_list free_list;
  int64_t peak_mem_usage_default;
  int64_t cur_mem_usage_default;
  // Uniform fields above.

  CUdeviceptr global_failure;
  CUdeviceptr global_failure_args;
  struct tuning_params tuning_params;
  // True if a potentially failing kernel has been enqueued.
  int32_t failure_is_an_option;
  int total_runs;
  long int total_runtime;
  int64_t peak_mem_usage_device;
  int64_t cur_mem_usage_device;
  struct program* program;

  CUdevice dev;
  CUcontext cu_ctx;
  CUmodule module;
  CUstream stream;

  struct free_list gpu_free_list;

  size_t max_group_size;
  size_t max_grid_size;
  size_t max_tile_size;
  size_t max_threshold;
  size_t max_local_memory;
  size_t max_bespoke;

  size_t lockstep_width;

  struct profiling_record *profiling_records;
  int profiling_records_capacity;
  int profiling_records_used;

  struct builtin_kernels* kernels;
};

#define CU_DEV_ATTR(x) (CU_DEVICE_ATTRIBUTE_##x)
#define device_query(dev,attrib) _device_query(dev, CU_DEV_ATTR(attrib))
static int _device_query(CUdevice dev, CUdevice_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuDeviceGetAttribute(&val, attrib, dev));
  return val;
}

#define CU_FUN_ATTR(x) (CU_FUNC_ATTRIBUTE_##x)
#define function_query(fn,attrib) _function_query(dev, CU_FUN_ATTR(attrib))
static int _function_query(CUfunction dev, CUfunction_attribute attrib) {
  int val;
  CUDA_SUCCEED_FATAL(cuFuncGetAttribute(&val, attrib, dev));
  return val;
}

static int cuda_device_setup(struct futhark_context *ctx) {
  struct futhark_context_config *cfg = ctx->cfg;
  char name[256];
  int count, chosen = -1, best_cc = -1;
  int cc_major_best = 0, cc_minor_best = 0;
  int cc_major = 0, cc_minor = 0;
  CUdevice dev;

  CUDA_SUCCEED_FATAL(cuDeviceGetCount(&count));
  if (count == 0) { return 1; }

  int num_device_matches = 0;

  // XXX: Current device selection policy is to choose the device with the
  // highest compute capability (if no preferred device is set).
  // This should maybe be changed, since greater compute capability is not
  // necessarily an indicator of better performance.
  for (int i = 0; i < count; i++) {
    CUDA_SUCCEED_FATAL(cuDeviceGet(&dev, i));

    cc_major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
    cc_minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

    CUDA_SUCCEED_FATAL(cuDeviceGetName(name, sizeof(name) - 1, dev));
    name[sizeof(name) - 1] = 0;

    if (cfg->logging) {
      fprintf(ctx->log, "Device #%d: name=\"%s\", compute capability=%d.%d\n",
              i, name, cc_major, cc_minor);
    }

    if (device_query(dev, COMPUTE_MODE) == CU_COMPUTEMODE_PROHIBITED) {
      if (cfg->logging) {
        fprintf(ctx->log, "Device #%d is compute-prohibited, ignoring\n", i);
      }
      continue;
    }

    if (best_cc == -1 || cc_major > cc_major_best ||
        (cc_major == cc_major_best && cc_minor > cc_minor_best)) {
      best_cc = i;
      cc_major_best = cc_major;
      cc_minor_best = cc_minor;
    }

    if (strstr(name, cfg->preferred_device) != NULL &&
        num_device_matches++ == cfg->preferred_device_num) {
      chosen = i;
      break;
    }
  }

  if (chosen == -1) { chosen = best_cc; }
  if (chosen == -1) { return 1; }

  if (cfg->logging) {
    fprintf(ctx->log, "Using device #%d\n", chosen);
  }

  CUDA_SUCCEED_FATAL(cuDeviceGet(&ctx->dev, chosen));
  return 0;
}

static const char *cuda_nvrtc_get_arch(CUdevice dev) {
  static struct {
    int major;
    int minor;
    const char *arch_str;
  } const x[] = {
    { 3, 0, "compute_30" },
    { 3, 2, "compute_32" },
    { 3, 5, "compute_35" },
    { 3, 7, "compute_37" },
    { 5, 0, "compute_50" },
    { 5, 2, "compute_52" },
    { 5, 3, "compute_53" },
    { 6, 0, "compute_60" },
    { 6, 1, "compute_61" },
    { 6, 2, "compute_62" },
    { 7, 0, "compute_70" },
    { 7, 2, "compute_72" },
    { 7, 5, "compute_75" },
    { 8, 0, "compute_80" },
    { 8, 6, "compute_80" },
    { 8, 7, "compute_80" }
  };

  int major = device_query(dev, COMPUTE_CAPABILITY_MAJOR);
  int minor = device_query(dev, COMPUTE_CAPABILITY_MINOR);

  int chosen = -1;
  int num_archs = sizeof(x)/sizeof(x[0]);
  for (int i = 0; i < num_archs; i++) {
    if (x[i].major < major || (x[i].major == major && x[i].minor <= minor)) {
      chosen = i;
    } else {
      break;
    }
  }

  if (chosen == -1) {
    futhark_panic(-1, "Unsupported compute capability %d.%d\n", major, minor);
  }

  if (x[chosen].major != major || x[chosen].minor != minor) {
    fprintf(stderr,
            "Warning: device compute capability is %d.%d, but newest supported by Futhark is %d.%d.\n",
            major, minor, x[chosen].major, x[chosen].minor);
  }

  return x[chosen].arch_str;
}

static void cuda_nvrtc_mk_build_options(struct futhark_context *ctx, const char *extra_opts[],
                                        char*** opts_out, size_t *n_opts) {
  int arch_set = 0, num_extra_opts;
  struct futhark_context_config *cfg = ctx->cfg;

  // nvrtc cannot handle multiple -arch options.  Hence, if one of the
  // extra_opts is -arch, we have to be careful not to do our usual
  // automatic generation.
  for (num_extra_opts = 0; extra_opts[num_extra_opts] != NULL; num_extra_opts++) {
    if (strstr(extra_opts[num_extra_opts], "-arch")
        == extra_opts[num_extra_opts] ||
        strstr(extra_opts[num_extra_opts], "--gpu-architecture")
        == extra_opts[num_extra_opts]) {
      arch_set = 1;
    }
  }

  size_t i = 0, n_opts_alloc = 20 + num_extra_opts + cfg->num_tuning_params;
  char **opts = (char**) malloc(n_opts_alloc * sizeof(char *));
  if (!arch_set) {
    opts[i++] = strdup("-arch");
    opts[i++] = strdup(cuda_nvrtc_get_arch(ctx->dev));
  }
  opts[i++] = strdup("-default-device");
  if (cfg->debugging) {
    opts[i++] = strdup("-G");
    opts[i++] = strdup("-lineinfo");
  } else {
    opts[i++] = strdup("--disable-warnings");
  }
  opts[i++] = msgprintf("-D%s=%d",
                        "max_group_size",
                        (int)ctx->max_group_size);
  for (int j = 0; j < cfg->num_tuning_params; j++) {
    opts[i++] = msgprintf("-D%s=%zu", cfg->tuning_param_vars[j],
                          cfg->tuning_params[j]);
  }
  opts[i++] = msgprintf("-DLOCKSTEP_WIDTH=%zu", ctx->lockstep_width);
  opts[i++] = msgprintf("-DMAX_THREADS_PER_BLOCK=%zu", ctx->max_group_size);

  // Time for the best lines of the code in the entire compiler.
  if (getenv("CUDA_HOME") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_HOME"));
  }
  if (getenv("CUDA_ROOT") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_ROOT"));
  }
  if (getenv("CUDA_PATH") != NULL) {
    opts[i++] = msgprintf("-I%s/include", getenv("CUDA_PATH"));
  }
  opts[i++] = msgprintf("-I/usr/local/cuda/include");
  opts[i++] = msgprintf("-I/usr/include");

  for (int j = 0; extra_opts[j] != NULL; j++) {
    opts[i++] = strdup(extra_opts[j]);
  }

  opts[i++] = msgprintf("-DTR_BLOCK_DIM=%d", TR_BLOCK_DIM);
  opts[i++] = msgprintf("-DTR_TILE_DIM=%d", TR_TILE_DIM);
  opts[i++] = msgprintf("-DTR_ELEMS_PER_THREAD=%d", TR_ELEMS_PER_THREAD);

  *n_opts = i;
  *opts_out = opts;
}

static char* cuda_nvrtc_build(const char *src, const char *opts[], size_t n_opts,
                              char **ptx) {
  nvrtcProgram prog;
  char *problem = NULL;

  problem = NVRTC_SUCCEED_NONFATAL(nvrtcCreateProgram(&prog, src, "futhark-cuda", 0, NULL, NULL));

  if (problem) {
    return problem;
  }

  nvrtcResult res = nvrtcCompileProgram(prog, n_opts, opts);
  if (res != NVRTC_SUCCESS) {
    size_t log_size;
    if (nvrtcGetProgramLogSize(prog, &log_size) == NVRTC_SUCCESS) {
      char *log = (char*) malloc(log_size);
      if (nvrtcGetProgramLog(prog, log) == NVRTC_SUCCESS) {
        problem = msgprintf("NVRTC compilation failed.\n\n%s\n", log);
      } else {
        problem = msgprintf("Could not retrieve compilation log\n");
      }
      free(log);
    }
    return problem;
  }

  size_t ptx_size;
  NVRTC_SUCCEED_FATAL(nvrtcGetPTXSize(prog, &ptx_size));
  *ptx = (char*) malloc(ptx_size);
  NVRTC_SUCCEED_FATAL(nvrtcGetPTX(prog, *ptx));

  NVRTC_SUCCEED_FATAL(nvrtcDestroyProgram(&prog));

  return NULL;
}

static void cuda_load_ptx_from_cache(struct futhark_context_config *cfg,
                                     const char *src,
                                     const char *opts[], size_t n_opts,
                                     struct cache_hash *h, const char *cache_fname,
                                     char **ptx) {
  if (cfg->logging) {
    fprintf(stderr, "Restoring cache from from %s...\n", cache_fname);
  }
  cache_hash_init(h);
  for (size_t i = 0; i < n_opts; i++) {
    cache_hash(h, opts[i], strlen(opts[i]));
  }
  cache_hash(h, src, strlen(src));
  size_t ptxsize;
  errno = 0;
  if (cache_restore(cache_fname, h, (unsigned char**)ptx, &ptxsize) != 0) {
    if (cfg->logging) {
      fprintf(stderr, "Failed to restore cache (errno: %s)\n", strerror(errno));
    }
  }
}

static void cuda_size_setup(struct futhark_context *ctx)
{
  struct futhark_context_config *cfg = ctx->cfg;
  if (cfg->default_block_size > ctx->max_group_size) {
    if (cfg->default_block_size_changed) {
      fprintf(stderr,
              "Note: Device limits default block size to %zu (down from %zu).\n",
              ctx->max_group_size, cfg->default_block_size);
    }
    cfg->default_block_size = ctx->max_group_size;
  }
  if (cfg->default_grid_size > ctx->max_grid_size) {
    if (cfg->default_grid_size_changed) {
      fprintf(stderr,
              "Note: Device limits default grid size to %zu (down from %zu).\n",
              ctx->max_grid_size, cfg->default_grid_size);
    }
    cfg->default_grid_size = ctx->max_grid_size;
  }
  if (cfg->default_tile_size > ctx->max_tile_size) {
    if (cfg->default_tile_size_changed) {
      fprintf(stderr,
              "Note: Device limits default tile size to %zu (down from %zu).\n",
              ctx->max_tile_size, cfg->default_tile_size);
    }
    cfg->default_tile_size = ctx->max_tile_size;
  }

  if (!cfg->default_grid_size_changed) {
    cfg->default_grid_size =
      (device_query(ctx->dev, MULTIPROCESSOR_COUNT) *
       device_query(ctx->dev, MAX_THREADS_PER_MULTIPROCESSOR))
      / cfg->default_block_size;
  }

  for (int i = 0; i < cfg->num_tuning_params; i++) {
    const char *size_class = cfg->tuning_param_classes[i];
    int64_t *size_value = &cfg->tuning_params[i];
    const char* size_name = cfg->tuning_param_names[i];
    int64_t max_value = 0, default_value = 0;

    if (strstr(size_class, "group_size") == size_class) {
      max_value = ctx->max_group_size;
      default_value = cfg->default_block_size;
    } else if (strstr(size_class, "num_groups") == size_class) {
      max_value = ctx->max_grid_size;
      default_value = cfg->default_grid_size;
      // XXX: as a quick and dirty hack, use twice as many threads for
      // histograms by default.  We really should just be smarter
      // about sizes somehow.
      if (strstr(size_name, ".seghist_") != NULL) {
        default_value *= 2;
      }
    } else if (strstr(size_class, "tile_size") == size_class) {
      max_value = ctx->max_tile_size;
      default_value = cfg->default_tile_size;
    } else if (strstr(size_class, "reg_tile_size") == size_class) {
      max_value = 0; // No limit.
      default_value = cfg->default_reg_tile_size;
    } else if (strstr(size_class, "threshold") == size_class) {
      // Threshold can be as large as it takes.
      default_value = cfg->default_threshold;
    } else {
      // Bespoke sizes have no limit or default.
    }

    if (*size_value == 0) {
      *size_value = default_value;
    } else if (max_value > 0 && *size_value > max_value) {
      fprintf(stderr, "Note: Device limits %s to %zu (down from %zu)\n",
              size_name, max_value, *size_value);
      *size_value = max_value;
    }
  }
}

static char* cuda_module_setup(struct futhark_context *ctx,
                               const char *src,
                               const char *extra_opts[],
                               const char* cache_fname) {
  char *ptx = NULL;
  struct futhark_context_config *cfg = ctx->cfg;

  if (cfg->load_ptx_from) {
    ptx = slurp_file(cfg->load_ptx_from, NULL);
  }

  char **opts;
  size_t n_opts;
  cuda_nvrtc_mk_build_options(ctx, extra_opts, &opts, &n_opts);

  if (cfg->logging) {
    fprintf(stderr, "NVRTC compile options:\n");
    for (size_t j = 0; j < n_opts; j++) {
      fprintf(stderr, "\t%s\n", opts[j]);
    }
    fprintf(stderr, "\n");
  }

  struct cache_hash h;
  int loaded_ptx_from_cache = 0;
  if (cache_fname != NULL) {
    cuda_load_ptx_from_cache(cfg, src, (const char**)opts, n_opts, &h, cache_fname, &ptx);

    if (ptx != NULL) {
      if (cfg->logging) {
        fprintf(stderr, "Restored PTX from cache; now loading module...\n");
      }
      if (cuModuleLoadData(&ctx->module, ptx) == CUDA_SUCCESS) {
        if (cfg->logging) {
          fprintf(stderr, "Success!\n");
        }
        loaded_ptx_from_cache = 1;
      } else {
        if (cfg->logging) {
          fprintf(stderr, "Failed!\n");
        }
        free(ptx);
        ptx = NULL;
      }
    }
  }

  if (ptx == NULL) {
    char* problem = cuda_nvrtc_build(src, (const char**)opts, n_opts, &ptx);
    if (problem != NULL) {
      return problem;
    }
  }

  if (cfg->dump_ptx_to != NULL) {
    dump_file(cfg->dump_ptx_to, ptx, strlen(ptx));
  }

  if (!loaded_ptx_from_cache) {
    CUDA_SUCCEED_FATAL(cuModuleLoadData(&ctx->module, ptx));
  }

  if (cache_fname != NULL && !loaded_ptx_from_cache) {
    if (cfg->logging) {
      fprintf(stderr, "Caching PTX in %s...\n", cache_fname);
    }
    errno = 0;
    if (cache_store(cache_fname, &h, (const unsigned char*)ptx, strlen(ptx)) != 0) {
      fprintf(stderr, "Failed to cache PTX: %s\n", strerror(errno));
    }
  }

  for (size_t i = 0; i < n_opts; i++) {
    free((char *)opts[i]);
  }
  free(opts);
  free(ptx);

  return NULL;
}

// Count up the runtime all the profiling_records that occured during execution.
// Also clears the buffer of profiling_records.
static CUresult tally_profiling_records(struct futhark_context *ctx,
                                        struct cost_centres* ccs) {
  CUresult err;
  for (int i = 0; i < ctx->profiling_records_used; i++) {
    struct profiling_record record = ctx->profiling_records[i];

    float ms;
    if ((err = cuEventElapsedTime(&ms, record.events[0], record.events[1])) != CUDA_SUCCESS) {
      return err;
    }

    if (ccs) {
      // CUDA provides milisecond resolution, but we want microseconds.
      struct cost_centre c = {
        .name = record.name,
        .runs = 1,
        .runtime = ms*1000
      };
      cost_centres_add(ccs, c);
    }

    if ((err = cuEventDestroy(record.events[0])) != CUDA_SUCCESS) {
      return err;
    }
    if ((err = cuEventDestroy(record.events[1])) != CUDA_SUCCESS) {
      return err;
    }

    free(record.events);
  }

  ctx->profiling_records_used = 0;

  return CUDA_SUCCESS;
}

// Returns pointer to two events.
static cudaEvent_t* cuda_get_events(struct futhark_context *ctx, const char* name) {
  if (ctx->profiling_records_used == ctx->profiling_records_capacity) {
    ctx->profiling_records_capacity *= 2;
    ctx->profiling_records =
      realloc(ctx->profiling_records,
              ctx->profiling_records_capacity *
              sizeof(struct profiling_record));
  }
  cudaEvent_t *events = calloc(2, sizeof(cudaEvent_t));
  cudaEventCreate(&events[0]);
  cudaEventCreate(&events[1]);
  ctx->profiling_records[ctx->profiling_records_used].events = events;
  ctx->profiling_records[ctx->profiling_records_used].name = name;
  ctx->profiling_records_used++;
  return events;
}

int futhark_context_sync(struct futhark_context* ctx) {
  CUDA_SUCCEED_OR_RETURN(cuCtxPushCurrent(ctx->cu_ctx));
  CUDA_SUCCEED_OR_RETURN(cuCtxSynchronize());
  if (ctx->failure_is_an_option) {
    // Check for any delayed error.
    int32_t failure_idx;
    CUDA_SUCCEED_OR_RETURN(
                           cuMemcpyDtoH(&failure_idx,
                                        ctx->global_failure,
                                        sizeof(int32_t)));
    ctx->failure_is_an_option = 0;

    if (failure_idx >= 0) {
      // We have to clear global_failure so that the next entry point
      // is not considered a failure from the start.
      int32_t no_failure = -1;
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyHtoD(ctx->global_failure,
                                          &no_failure,
                                          sizeof(int32_t)));

      int64_t args[max_failure_args+1];
      CUDA_SUCCEED_OR_RETURN(
                             cuMemcpyDtoH(&args,
                                          ctx->global_failure_args,
                                          sizeof(args)));

      ctx->error = get_failure_msg(failure_idx, args);

      return FUTHARK_PROGRAM_ERROR;
    }
  }

  CUDA_SUCCEED_OR_RETURN(cuCtxPopCurrent(&ctx->cu_ctx));
  return 0;
}

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx);
void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels);

int backend_context_setup(struct futhark_context* ctx) {
  ctx->profiling_records_capacity = 200;
  ctx->profiling_records_used = 0;
  ctx->profiling_records =
    malloc(ctx->profiling_records_capacity *
           sizeof(struct profiling_record));
  ctx->failure_is_an_option = 0;
  ctx->total_runs = 0;
  ctx->total_runtime = 0;
  ctx->peak_mem_usage_device = 0;
  ctx->cur_mem_usage_device = 0;

  CUDA_SUCCEED_FATAL(cuInit(0));
  if (cuda_device_setup(ctx) != 0) {
    futhark_panic(-1, "No suitable CUDA device found.\n");
  }
  CUDA_SUCCEED_FATAL(cuCtxCreate(&ctx->cu_ctx, 0, ctx->dev));

  free_list_init(&ctx->gpu_free_list);

  ctx->max_local_memory = device_query(ctx->dev, MAX_SHARED_MEMORY_PER_BLOCK);
  ctx->max_group_size = device_query(ctx->dev, MAX_THREADS_PER_BLOCK);
  ctx->max_grid_size = device_query(ctx->dev, MAX_GRID_DIM_X);
  ctx->max_tile_size = sqrt(ctx->max_group_size);
  ctx->max_threshold = 0;
  ctx->max_bespoke = 0;
  ctx->lockstep_width = device_query(ctx->dev, WARP_SIZE);
  CUDA_SUCCEED_FATAL(cuStreamCreate(&ctx->stream, CU_STREAM_DEFAULT));
  cuda_size_setup(ctx);
  ctx->error = cuda_module_setup(ctx, ctx->cfg->program,
                                 ctx->cfg->nvrtc_opts, ctx->cfg->cache_fname);

  if (ctx->error != NULL) {
    futhark_panic(1, "During CUDA initialisation:\n%s\n", ctx->error);
  }

  int32_t no_error = -1;
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure, sizeof(no_error)));
  CUDA_SUCCEED_FATAL(cuMemcpyHtoD(ctx->global_failure, &no_error, sizeof(no_error)));
  // The +1 is to avoid zero-byte allocations.
  CUDA_SUCCEED_FATAL(cuMemAlloc(&ctx->global_failure_args, sizeof(int64_t)*(max_failure_args+1)));

  if ((ctx->kernels = init_builtin_kernels(ctx)) == NULL) {
    return 1;
  }

  return 0;
}

void backend_context_teardown(struct futhark_context* ctx) {
  free_builtin_kernels(ctx, ctx->kernels);
  cuMemFree(ctx->global_failure);
  cuMemFree(ctx->global_failure_args);
  CUDA_SUCCEED_FATAL(gpu_free_all(ctx));
  (void)tally_profiling_records(ctx, NULL);
  free(ctx->profiling_records);
  CUDA_SUCCEED_FATAL(cuStreamDestroy(ctx->stream));
  CUDA_SUCCEED_FATAL(cuModuleUnload(ctx->module));
  CUDA_SUCCEED_FATAL(cuCtxDestroy(ctx->cu_ctx));
}

// GPU ABSTRACTION LAYER

// Types.

typedef CUfunction gpu_kernel;
typedef CUdeviceptr gpu_mem;

static void gpu_create_kernel(struct futhark_context *ctx,
                              gpu_kernel* kernel,
                              const char* name) {
  if (ctx->debugging) {
    fprintf(ctx->log, "Creating kernel %s.\n", name);
  }
  CUDA_SUCCEED_FATAL(cuModuleGetFunction(kernel, ctx->module, name));
}

static void gpu_free_kernel(struct futhark_context *ctx,
                            gpu_kernel kernel) {
  (void)ctx;
  (void)kernel;
}

static int gpu_scalar_to_device(struct futhark_context* ctx,
                                gpu_mem dst, size_t offset, size_t size,
                                void *src) {
  CUevent *pevents = NULL;
  if (ctx->profiling && !ctx->profiling_paused) {
    pevents = cuda_get_events(ctx, "copy_scalar_to_dev");
    CUDA_SUCCEED_FATAL(cuEventRecord(pevents[0], ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyHtoD(dst + offset, src, size));
  if (pevents != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(pevents[1], ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_scalar_from_device(struct futhark_context* ctx,
                                  void *dst,
                                  gpu_mem src, size_t offset, size_t size) {
  CUevent *pevents = NULL;
  if (ctx->profiling && !ctx->profiling_paused) {
    pevents = cuda_get_events(ctx, "copy_scalar_from_dev");
    CUDA_SUCCEED_FATAL(cuEventRecord(pevents[0], ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpyDtoH(dst, src + offset, size));
  if (pevents != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(pevents[1], ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int gpu_memcpy(struct futhark_context* ctx,
                      gpu_mem dst, int64_t dst_offset,
                      gpu_mem src, int64_t src_offset,
                      int64_t nbytes) {
  CUevent *pevents = NULL;
  if (ctx->profiling && !ctx->profiling_paused) {
    pevents = cuda_get_events(ctx, "copy_dev_to_dev");
    CUDA_SUCCEED_FATAL(cuEventRecord(pevents[0], ctx->stream));
  }
  CUDA_SUCCEED_OR_RETURN(cuMemcpy(dst+dst_offset, src+src_offset, nbytes));
  if (pevents != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(pevents[1], ctx->stream));
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_host2gpu(struct futhark_context* ctx, bool sync,
                           gpu_mem dst, int64_t dst_offset,
                           const unsigned char* src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    CUevent* pevents = NULL;
    if (ctx->profiling && !ctx->profiling_paused) {
      pevents = cuda_get_events(ctx, "copy_host_to_dev");
      CUDA_SUCCEED_FATAL(cuEventRecord(pevents[0], ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoD(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyHtoDAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (pevents != NULL) {
      CUDA_SUCCEED_FATAL(cuEventRecord(pevents[1], ctx->stream));
    }
  }
  return FUTHARK_SUCCESS;
}

static int memcpy_gpu2host(struct futhark_context* ctx, bool sync,
                           unsigned char* dst, int64_t dst_offset,
                           gpu_mem src, int64_t src_offset,
                           int64_t nbytes) {
  if (nbytes > 0) {
    CUevent* pevents = NULL;
    if (ctx->profiling && !ctx->profiling_paused) {
      pevents = cuda_get_events(ctx, "copy_dev_to_host");
      CUDA_SUCCEED_FATAL(cuEventRecord(pevents[0], ctx->stream));
    }
    if (sync) {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoH(dst + dst_offset, src + src_offset, nbytes));
    } else {
      CUDA_SUCCEED_OR_RETURN
        (cuMemcpyDtoHAsync(dst + dst_offset, src + src_offset, nbytes, ctx->stream));
    }
    if (sync &&
        ctx->failure_is_an_option &&
        futhark_context_sync(ctx) != 0) {
      return 1;
    }
  }
  return FUTHARK_SUCCESS;
}

static int gpu_launch_kernel(struct futhark_context* ctx,
                             gpu_kernel kernel, const char *name,
                             const int32_t grid[3],
                             const int32_t block[3],
                             unsigned int local_mem_bytes,
                             int num_args,
                             void* args[num_args],
                             size_t args_sizes[num_args]) {
  (void) args_sizes;
  int64_t time_start = 0, time_end = 0;
  if (ctx->logging) {
    fprintf(ctx->log,
            "Launching kernel %s with\n"
            "  grid=(%d,%d,%d)\n"
            "  block=(%d,%d,%d)\n"
            "  local memory=%d\n",
            name,
            grid[0], grid[1], grid[2],
            block[0], block[1], block[2],
            local_mem_bytes);
    time_start = get_wall_time();
  }

  CUevent *pevents = NULL;
  if (ctx->profiling && !ctx->profiling_paused) {
    pevents = cuda_get_events(ctx, name);
    CUDA_SUCCEED_FATAL(cuEventRecord(pevents[0], ctx->stream));
  }

  CUDA_SUCCEED_OR_RETURN
    (cuLaunchKernel(kernel,
                    grid[0], grid[1], grid[2],
                    block[0], block[1], block[2],
                    local_mem_bytes, ctx->stream,
                    args, NULL));

  if (pevents != NULL) {
    CUDA_SUCCEED_FATAL(cuEventRecord(pevents[1], ctx->stream));
  }

  if (ctx->debugging) {
    CUDA_SUCCEED_FATAL(cuCtxSynchronize());
    time_end = get_wall_time();
    long int time_diff = time_end - time_start;
    fprintf(ctx->log, "  runtime: %ldus\n\n", time_diff);
  }

  return FUTHARK_SUCCESS;
}

static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out) {
  CUresult res = cuMemAlloc(mem_out, size);
  if (res == CUDA_ERROR_OUT_OF_MEMORY) {
    return FUTHARK_OUT_OF_MEMORY;
  }
  CUDA_SUCCEED_OR_RETURN(res);
  return FUTHARK_SUCCESS;
}

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem) {
  (void)ctx;
  CUDA_SUCCEED_OR_RETURN(cuMemFree(mem));
  return FUTHARK_SUCCESS;
}

// End of backends/cuda.h.

// Start of gpu.h

// Generic functions that use our tiny GPU abstraction layer.  The
// entire context must be defined before this header is included.  In
// particular we expect the following functions to be available:

static int gpu_free_actual(struct futhark_context *ctx, gpu_mem mem);
static int gpu_alloc_actual(struct futhark_context *ctx, size_t size, gpu_mem *mem_out);
int gpu_launch_kernel(struct futhark_context* ctx,
                      gpu_kernel kernel, const char *name,
                      const int32_t grid[3],
                      const int32_t block[3],
                      unsigned int local_mem_bytes,
                      int num_args,
                      void* args[num_args],
                      size_t args_sizes[num_args]);
int gpu_memcpy(struct futhark_context* ctx,
               gpu_mem dst, int64_t dst_offset,
               gpu_mem src, int64_t src_offset,
               int64_t nbytes);
int gpu_scalar_from_device(struct futhark_context* ctx,
                           void *dst,
                           gpu_mem src, size_t offset, size_t size);
int gpu_scalar_to_device(struct futhark_context* ctx,
                         gpu_mem dst, size_t offset, size_t size,
                         void *src);
void gpu_create_kernel(struct futhark_context *ctx,
                       gpu_kernel* kernel,
                       const char* name);

// Max number of groups we allow along the second or third dimension
// for transpositions.
#define MAX_TR_GROUPS 65535

struct builtin_kernels {
  // We have a lot of ways to transpose arrays.
  gpu_kernel map_transpose_1b;
  gpu_kernel map_transpose_1b_low_height;
  gpu_kernel map_transpose_1b_low_width;
  gpu_kernel map_transpose_1b_small;
  gpu_kernel map_transpose_1b_large;
  gpu_kernel map_transpose_2b;
  gpu_kernel map_transpose_2b_low_height;
  gpu_kernel map_transpose_2b_low_width;
  gpu_kernel map_transpose_2b_small;
  gpu_kernel map_transpose_2b_large;
  gpu_kernel map_transpose_4b;
  gpu_kernel map_transpose_4b_low_height;
  gpu_kernel map_transpose_4b_low_width;
  gpu_kernel map_transpose_4b_small;
  gpu_kernel map_transpose_4b_large;
  gpu_kernel map_transpose_8b;
  gpu_kernel map_transpose_8b_low_height;
  gpu_kernel map_transpose_8b_low_width;
  gpu_kernel map_transpose_8b_small;
  gpu_kernel map_transpose_8b_large;

  // And a few ways of copying.
  gpu_kernel lmad_copy_1b;
  gpu_kernel lmad_copy_2b;
  gpu_kernel lmad_copy_4b;
  gpu_kernel lmad_copy_8b;
};

struct builtin_kernels* init_builtin_kernels(struct futhark_context* ctx) {
  struct builtin_kernels *kernels = malloc(sizeof(struct builtin_kernels));
  gpu_create_kernel(ctx, &kernels->map_transpose_1b, "map_transpose_1b");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_large, "map_transpose_1b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_height, "map_transpose_1b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_low_width, "map_transpose_1b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_1b_small, "map_transpose_1b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_2b, "map_transpose_2b");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_large, "map_transpose_2b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_height, "map_transpose_2b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_low_width, "map_transpose_2b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_2b_small, "map_transpose_2b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_4b, "map_transpose_4b");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_large, "map_transpose_4b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_height, "map_transpose_4b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_low_width, "map_transpose_4b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_4b_small, "map_transpose_4b_small");

  gpu_create_kernel(ctx, &kernels->map_transpose_8b, "map_transpose_8b");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_large, "map_transpose_8b_large");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_height, "map_transpose_8b_low_height");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_low_width, "map_transpose_8b_low_width");
  gpu_create_kernel(ctx, &kernels->map_transpose_8b_small, "map_transpose_8b_small");

  gpu_create_kernel(ctx, &kernels->lmad_copy_1b, "lmad_copy_1b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_2b, "lmad_copy_2b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_4b, "lmad_copy_4b");
  gpu_create_kernel(ctx, &kernels->lmad_copy_8b, "lmad_copy_8b");

  return kernels;
}

void free_builtin_kernels(struct futhark_context* ctx, struct builtin_kernels* kernels) {
  gpu_free_kernel(ctx, kernels->map_transpose_1b);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_1b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_2b);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_2b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_4b);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_4b_small);

  gpu_free_kernel(ctx, kernels->map_transpose_8b);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_large);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_height);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_low_width);
  gpu_free_kernel(ctx, kernels->map_transpose_8b_small);

  gpu_free_kernel(ctx, kernels->lmad_copy_1b);
  gpu_free_kernel(ctx, kernels->lmad_copy_2b);
  gpu_free_kernel(ctx, kernels->lmad_copy_4b);
  gpu_free_kernel(ctx, kernels->lmad_copy_8b);

  free(kernels);
}

static int gpu_alloc(struct futhark_context *ctx, FILE *log,
                     size_t min_size, const char *tag,
                     gpu_mem *mem_out, size_t *size_out) {
  if (min_size < sizeof(int)) {
    min_size = sizeof(int);
  }

  gpu_mem* memptr;
  if (free_list_find(&ctx->gpu_free_list, min_size, tag, size_out, (fl_mem*)&memptr) == 0) {
    // Successfully found a free block.  Is it big enough?
    if (*size_out >= min_size) {
      if (ctx->cfg->debugging) {
        fprintf(log, "No need to allocate: Found a block in the free list.\n");
      }
      *mem_out = *memptr;
      free(memptr);
      return FUTHARK_SUCCESS;
    } else {
      if (ctx->cfg->debugging) {
        fprintf(log, "Found a free block, but it was too small.\n");
      }
      int error = gpu_free_actual(ctx, *memptr);
      free(memptr);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    }
  }

  *size_out = min_size;

  // We have to allocate a new block from the driver.  If the
  // allocation does not succeed, then we might be in an out-of-memory
  // situation.  We now start freeing things from the free list until
  // we think we have freed enough that the allocation will succeed.
  // Since we don't know how far the allocation is from fitting, we
  // have to check after every deallocation.  This might be pretty
  // expensive.  Let's hope that this case is hit rarely.

  if (ctx->cfg->debugging) {
    fprintf(log, "Actually allocating the desired block.\n");
  }

  int error = gpu_alloc_actual(ctx, min_size, mem_out);

  while (error == FUTHARK_OUT_OF_MEMORY) {
    if (ctx->cfg->debugging) {
      fprintf(log, "Out of GPU memory: releasing entry from the free list...\n");
    }
    gpu_mem* memptr;
    if (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
      gpu_mem mem = *memptr;
      free(memptr);
      error = gpu_free_actual(ctx, mem);
      if (error != FUTHARK_SUCCESS) {
        return error;
      }
    } else {
      break;
    }
    error = gpu_alloc_actual(ctx, min_size, mem_out);
  }

  return error;
}

static int gpu_free(struct futhark_context *ctx,
                    gpu_mem mem, size_t size, const char *tag) {
  gpu_mem* memptr = malloc(sizeof(gpu_mem));
  *memptr = mem;
  free_list_insert(&ctx->gpu_free_list, size, (fl_mem)memptr, tag);
  return FUTHARK_SUCCESS;
}

static int gpu_free_all(struct futhark_context *ctx) {
  free_list_pack(&ctx->gpu_free_list);
  gpu_mem* memptr;
  while (free_list_first(&ctx->gpu_free_list, (fl_mem*)&memptr) == 0) {
    gpu_mem mem = *memptr;
    free(memptr);
    int error = gpu_free_actual(ctx, mem);
    if (error != FUTHARK_SUCCESS) {
      return error;
    }
  }

  return FUTHARK_SUCCESS;
}

static int gpu_map_transpose(struct futhark_context* ctx,
                             gpu_kernel kernel_default,
                             gpu_kernel kernel_low_height,
                             gpu_kernel kernel_low_width,
                             gpu_kernel kernel_small,
                             gpu_kernel kernel_large,
                             const char *name, size_t elem_size,
                             gpu_mem dst, int64_t dst_offset,
                             gpu_mem src, int64_t src_offset,
                             int64_t k, int64_t n, int64_t m) {
  int64_t mulx = TR_BLOCK_DIM / n;
  int64_t muly = TR_BLOCK_DIM / m;
  int32_t mulx32 = mulx;
  int32_t muly32 = muly;
  int32_t k32 = k;
  int32_t n32 = n;
  int32_t m32 = m;

  gpu_kernel kernel = kernel_default;
  int32_t grid[3];
  int32_t block[3];

  void* args[11];
  size_t args_sizes[11] = {
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(gpu_mem), sizeof(int64_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t),
    sizeof(int32_t)
  };

  args[0] = &dst;
  args[1] = &dst_offset;
  args[2] = &src;
  args[3] = &src_offset;
  args[7] = &mulx;
  args[8] = &muly;

  if (dst_offset + k * n * m <= 2147483647L &&
      src_offset + k * n * m <= 2147483647L) {
    if (m <= TR_BLOCK_DIM/2 && n <= TR_BLOCK_DIM/2) {
      if (ctx->logging) { fprintf(ctx->log, "Using small kernel\n"); }
      kernel = kernel_small;
      grid[0] = ((k * n * m) + (TR_BLOCK_DIM*TR_BLOCK_DIM) - 1) / (TR_BLOCK_DIM*TR_BLOCK_DIM);
      grid[1] = 1;
      grid[2] = 1;
      block[0] = TR_BLOCK_DIM*TR_BLOCK_DIM;
      block[1] = 1;
      block[2] = 1;
    } else if (m <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < n) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-width kernel\n"); }
      kernel = kernel_low_width;
      int64_t x_elems = m;
      int64_t y_elems = (n + muly - 1) / muly;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else if (n <= TR_BLOCK_DIM/2 && TR_BLOCK_DIM < m) {
      if (ctx->logging) { fprintf(ctx->log, "Using low-height kernel\n"); }
      kernel = kernel_low_height;
      int64_t x_elems = (m + mulx - 1) / mulx;
      int64_t y_elems = n;
      grid[0] = (x_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[1] = (y_elems + TR_BLOCK_DIM - 1) / TR_BLOCK_DIM;
      grid[2] = k;
      block[0] = TR_BLOCK_DIM;
      block[1] = TR_BLOCK_DIM;
      block[2] = 1;
    } else {
      if (ctx->logging) { fprintf(ctx->log, "Using default kernel\n"); }
      kernel = kernel_default;
      grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
      grid[2] = k;
      block[0] = TR_TILE_DIM;
      block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
      block[2] = 1;
    }
    args[4] = &k32;
    args[5] = &m32;
    args[6] = &n32;
    args[7] = &mulx32;
    args[8] = &muly32;
  } else {
    if (ctx->logging) { fprintf(ctx->log, "Using large kernel\n"); }
    kernel = kernel_large;
    grid[0] = (m+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[1] = (n+TR_TILE_DIM-1)/TR_TILE_DIM;
    grid[2] = k;
    block[0] = TR_TILE_DIM;
    block[1] = TR_TILE_DIM/TR_ELEMS_PER_THREAD;
    block[2] = 1;
    args[4] = &k;
    args[5] = &m;
    args[6] = &n;
    args[7] = &mulx;
    args[8] = &muly;
    args_sizes[4] = sizeof(int64_t);
    args_sizes[5] = sizeof(int64_t);
    args_sizes[6] = sizeof(int64_t);
    args_sizes[7] = sizeof(int64_t);
    args_sizes[8] = sizeof(int64_t);
  }

  // Cap the number of groups we launch and figure out how many
  // repeats we need alongside each dimension.
  int32_t repeat_1 = grid[1] / MAX_TR_GROUPS;
  int32_t repeat_2 = grid[2] / MAX_TR_GROUPS;
  grid[1] = repeat_1 > 0 ? MAX_TR_GROUPS : grid[1];
  grid[2] = repeat_2 > 0 ? MAX_TR_GROUPS : grid[2];
  args[9] = &repeat_1;
  args[10] = &repeat_2;
  args_sizes[9] = sizeof(repeat_1);
  args_sizes[10] = sizeof(repeat_2);

  if (ctx->logging) {
    fprintf(ctx->log, "\n");
  }

  return gpu_launch_kernel(ctx, kernel, name, grid, block,
                           TR_TILE_DIM*(TR_TILE_DIM+1)*elem_size,
                           sizeof(args)/sizeof(args[0]), args, args_sizes);
}

#define GEN_MAP_TRANSPOSE_GPU2GPU(NAME, ELEM_TYPE)                      \
  static int map_transpose_gpu2gpu_##NAME                               \
  (struct futhark_context* ctx,                                         \
   gpu_mem dst, int64_t dst_offset,                                     \
   gpu_mem src, int64_t src_offset,                                     \
   int64_t k, int64_t m, int64_t n)                                     \
  {                                                                     \
    return                                                              \
      gpu_map_transpose                                                 \
      (ctx,                                                             \
       ctx->kernels->map_transpose_##NAME,                              \
       ctx->kernels->map_transpose_##NAME##_low_height,                 \
       ctx->kernels->map_transpose_##NAME##_low_width,                  \
       ctx->kernels->map_transpose_##NAME##_small,                      \
       ctx->kernels->map_transpose_##NAME##_large,                      \
       "map_transpose_" #NAME, sizeof(ELEM_TYPE),                       \
       dst, dst_offset, src, src_offset,                                \
       k, n, m);                                                        \
  }

static int gpu_lmad_copy(struct futhark_context* ctx,
                         gpu_kernel kernel, int r,
                         gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                         gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                         int64_t shape[r]) {
  if (r > 8) {
    set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy array of greater than rank 8.\n"));
    return 1;
  }

  int64_t n = 1;
  for (int i = 0; i < r; i++) { n *= shape[i]; }

  void* args[6+(8*3)];
  size_t args_sizes[6+(8*3)];

  args[0] = &dst;
  args_sizes[0] = sizeof(gpu_mem);
  args[1] = &dst_offset;
  args_sizes[1] = sizeof(dst_offset);
  args[2] = &src;
  args_sizes[2] = sizeof(gpu_mem);
  args[3] = &src_offset;
  args_sizes[3] = sizeof(src_offset);
  args[4] = &n;
  args_sizes[4] = sizeof(n);
  args[5] = &r;
  args_sizes[5] = sizeof(r);

  int64_t zero = 0;

  for (int i = 0; i < 8; i++) {
    args_sizes[6+i*3] = sizeof(int64_t);
    args_sizes[6+i*3+1] = sizeof(int64_t);
    args_sizes[6+i*3+2] = sizeof(int64_t);
    if (i < r) {
      args[6+i*3] = &shape[i];
      args[6+i*3+1] = &dst_strides[i];
      args[6+i*3+2] = &src_strides[i];
    } else {
      args[6+i*3] = &zero;
      args[6+i*3+1] = &zero;
      args[6+i*3+2] = &zero;
    }
  }
  const size_t w = 256; // XXX: hardcoded workgroup size.

  return gpu_launch_kernel(ctx, kernel, "copy_lmad_dev_to_dev",
                           (const int32_t[3]) {(n+w-1)/w,1,1},
                           (const int32_t[3]) {w,1,1},
                           0, 6+(8*3), args, args_sizes);
}

#define GEN_LMAD_COPY_ELEMENTS_GPU2GPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return gpu_lmad_copy(ctx, ctx->kernels->lmad_copy_##NAME, r,        \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \

#define GEN_LMAD_COPY_GPU2GPU(NAME, ELEM_TYPE)                          \
  static int lmad_copy_gpu2gpu_##NAME                                   \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "GPU to GPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return FUTHARK_SUCCESS; }                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                       r, dst_strides, src_strides, shape)) {           \
      log_transpose(ctx, k, n, m);                                      \
      return map_transpose_gpu2gpu_##NAME                               \
        (ctx, dst, dst_offset, src, src_offset, k, n, m);               \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}        \
      return gpu_memcpy(ctx,                                            \
                        dst, dst_offset*sizeof(ELEM_TYPE),              \
                        src, src_offset*sizeof(ELEM_TYPE),              \
                        size * sizeof(ELEM_TYPE));                      \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}     \
      return lmad_copy_elements_gpu2gpu_##NAME                          \
        (ctx, r,                                                        \
         dst, dst_offset, dst_strides,                                  \
         src, src_offset, src_strides,                                  \
         shape);                                                        \
    }                                                                   \
  }

static int
lmad_copy_elements_host2gpu(struct futhark_context *ctx, size_t elem_size,
                            int r,
                            gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                            unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                            int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from host to GPU.\n"));
  return 1;
}

static int
lmad_copy_elements_gpu2host (struct futhark_context *ctx, size_t elem_size,
                             int r,
                             unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                             gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                             int64_t shape[r]) {
  (void)ctx; (void)elem_size; (void)r;
  (void)dst; (void)dst_offset; (void)dst_strides;
  (void)src; (void)src_offset; (void)src_strides;
  (void)shape;
  set_error(ctx, strdup("Futhark runtime limitation:\nCannot copy unstructured array from GPU to host.\n"));
  return 1;
}

#define GEN_LMAD_COPY_ELEMENTS_HOSTGPU(NAME, ELEM_TYPE)                 \
  static int lmad_copy_elements_gpu2gpu_##NAME                          \
  (struct futhark_context* ctx,                                         \
   int r,                                                               \
   gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],             \
   gpu_mem src, int64_t src_offset, int64_t src_strides[r],             \
   int64_t shape[r]) {                                                  \
    return (ctx, ctx->kernels->lmad_copy_##NAME, r,                     \
                         dst, dst_offset, dst_strides,                  \
                         src, src_offset, src_strides,                  \
                         shape);                                        \
  }                                                                     \


static int lmad_copy_host2gpu(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              gpu_mem dst, int64_t dst_offset, int64_t dst_strides[r],
                              unsigned char* src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_host2gpu(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_host2gpu
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

static int lmad_copy_gpu2host(struct futhark_context* ctx, size_t elem_size, bool sync,
                              int r,
                              unsigned char* dst, int64_t dst_offset, int64_t dst_strides[r],
                              gpu_mem src, int64_t src_offset, int64_t src_strides[r],
                              int64_t shape[r]) {
  log_copy(ctx, "Host to GPU", r, dst_offset, dst_strides,
           src_offset, src_strides, shape);
  int64_t size = elem_size;
  for (int i = 0; i < r; i++) { size *= shape[i]; }
  if (size == 0) { return FUTHARK_SUCCESS; }
  int64_t k, n, m;
  if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {
    if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}
    return memcpy_gpu2host(ctx, sync,
                           dst, dst_offset*elem_size,
                           src, src_offset*elem_size,
                           size);
  } else {
    if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}
    int error;
    error = lmad_copy_elements_gpu2host
      (ctx, elem_size, r,
       dst, dst_offset, dst_strides,
       src, src_offset, src_strides,
       shape);
    if (error == 0 && sync) {
      error = futhark_context_sync(ctx);
    }
    return error;
  }
}

GEN_MAP_TRANSPOSE_GPU2GPU(1b, uint8_t)
GEN_MAP_TRANSPOSE_GPU2GPU(2b, uint16_t)
GEN_MAP_TRANSPOSE_GPU2GPU(4b, uint32_t)
GEN_MAP_TRANSPOSE_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS_GPU2GPU(8b, uint64_t)

GEN_LMAD_COPY_GPU2GPU(1b, uint8_t)
GEN_LMAD_COPY_GPU2GPU(2b, uint16_t)
GEN_LMAD_COPY_GPU2GPU(4b, uint32_t)
GEN_LMAD_COPY_GPU2GPU(8b, uint64_t)

// End of gpu.h

static char *get_failure_msg(int failure_idx, int64_t args[])
{
    (void) args;
    switch (failure_idx) {
        
      case 0:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigadd.fut:26:11-16\n   #1  /prelude/functional.fut:9:44-45\n   #2  big-arith-valid.fut:8:1-11:91\n", args[0], args[1]);
            break;
        }
        
      case 1:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigadd.fut:26:18-27\n   #1  /prelude/functional.fut:9:44-45\n   #2  big-arith-valid.fut:8:1-11:91\n", args[0], args[1]);
            break;
        }
        
      case 2:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigadd.fut:26:29-42\n   #1  /prelude/functional.fut:9:44-45\n   #2  big-arith-valid.fut:8:1-11:91\n", args[0], args[1]);
            break;
        }
        
      case 3:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigadd.fut:26:44-57\n   #1  /prelude/functional.fut:9:44-45\n   #2  big-arith-valid.fut:8:1-11:91\n", args[0], args[1]);
            break;
        }
        
      case 4:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigadd.fut:17:46-58\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  big-arith-fut/bigadd.fut:17:76-81\n   #4  big-arith-valid.fut:8:1-11:91\n", args[0], args[1]);
            break;
        }
        
      case 5:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigadd.fut:26:11-16\n   #1  /prelude/functional.fut:9:44-45\n   #2  big-arith-valid.fut:6:8-47\n   #3  big-arith-valid.fut:4:1-6:73\n", args[0], args[1]);
            break;
        }
        
      case 6:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigadd.fut:26:18-27\n   #1  /prelude/functional.fut:9:44-45\n   #2  big-arith-valid.fut:6:8-47\n   #3  big-arith-valid.fut:4:1-6:73\n", args[0], args[1]);
            break;
        }
        
      case 7:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigadd.fut:26:29-42\n   #1  /prelude/functional.fut:9:44-45\n   #2  big-arith-valid.fut:6:8-47\n   #3  big-arith-valid.fut:4:1-6:73\n", args[0], args[1]);
            break;
        }
        
      case 8:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigadd.fut:26:44-57\n   #1  /prelude/functional.fut:9:44-45\n   #2  big-arith-valid.fut:6:8-47\n   #3  big-arith-valid.fut:4:1-6:73\n", args[0], args[1]);
            break;
        }
        
      case 9:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigadd.fut:17:46-58\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  big-arith-fut/bigadd.fut:17:76-81\n   #4  big-arith-valid.fut:6:8-47\n   #5  big-arith-valid.fut:4:1-6:73\n", args[0], args[1]);
            break;
        }
        
      case 10:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:46:30-39\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:17:1-20:91\n", args[0], args[1]);
            break;
        }
        
      case 11:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:58:30-39\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:17:1-20:91\n", args[0], args[1]);
            break;
        }
        
      case 12:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:43:45-51\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:17:1-20:91\n", args[0], args[1]);
            break;
        }
        
      case 13:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:43:38-44\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:17:1-20:91\n", args[0], args[1]);
            break;
        }
        
      case 14:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:44:45-53\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:17:1-20:91\n", args[0], args[1]);
            break;
        }
        
      case 15:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:55:45-51\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:17:1-20:91\n", args[0], args[1]);
            break;
        }
        
      case 16:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:55:38-44\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:17:1-20:91\n", args[0], args[1]);
            break;
        }
        
      case 17:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:56:45-53\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:17:1-20:91\n", args[0], args[1]);
            break;
        }
        
      case 18:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigadd.fut:17:46-58\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  big-arith-fut/bigadd.fut:17:76-81\n   #4  big-arith-valid.fut:17:1-20:91\n", args[0], args[1]);
            break;
        }
        
      case 19:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:46:30-39\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:15:8-46\n   #4  big-arith-valid.fut:13:1-15:72\n", args[0], args[1]);
            break;
        }
        
      case 20:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:58:30-39\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:15:8-46\n   #4  big-arith-valid.fut:13:1-15:72\n", args[0], args[1]);
            break;
        }
        
      case 21:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:43:45-51\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:15:8-46\n   #4  big-arith-valid.fut:13:1-15:72\n", args[0], args[1]);
            break;
        }
        
      case 22:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:43:38-44\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:15:8-46\n   #4  big-arith-valid.fut:13:1-15:72\n", args[0], args[1]);
            break;
        }
        
      case 23:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:44:45-53\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:15:8-46\n   #4  big-arith-valid.fut:13:1-15:72\n", args[0], args[1]);
            break;
        }
        
      case 24:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:55:45-51\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:15:8-46\n   #4  big-arith-valid.fut:13:1-15:72\n", args[0], args[1]);
            break;
        }
        
      case 25:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:55:38-44\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:15:8-46\n   #4  big-arith-valid.fut:13:1-15:72\n", args[0], args[1]);
            break;
        }
        
      case 26:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigmul.fut:56:45-53\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:15:8-46\n   #4  big-arith-valid.fut:13:1-15:72\n", args[0], args[1]);
            break;
        }
        
      case 27:
        {
            return msgprintf("Index [%lld] out of bounds for array of shape [%lld].\n-> #0  big-arith-fut/bigadd.fut:17:46-58\n   #1  /prelude/soacs.fut:67:23-24\n   #2  /prelude/soacs.fut:67:27-37\n   #3  big-arith-fut/bigadd.fut:17:76-81\n   #4  big-arith-valid.fut:15:8-46\n   #5  big-arith-valid.fut:13:1-15:72\n", args[0], args[1]);
            break;
        }
    }
    return strdup("Unknown error.  This is a compiler bug.");
}
struct program {
    gpu_kernel big_add_debugzisegmap_12352;
    gpu_kernel big_add_debugzisegmap_12421;
    gpu_kernel big_add_debugzisegmap_12445;
    gpu_kernel big_add_debugzisegscan_12393;
    gpu_kernel big_add_debugzisegscan_12443;
    gpu_kernel big_add_validationzisegmap_11836;
    gpu_kernel big_add_validationzisegred_nonseg_11887;
    gpu_kernel big_add_validationzisegscan_11877;
    gpu_kernel big_mul_debugzigpuseq_13027;
    gpu_kernel big_mul_debugzisegmap_12635;
    gpu_kernel big_mul_debugzisegmap_12802;
    gpu_kernel big_mul_debugzisegmap_12808;
    gpu_kernel big_mul_debugzisegmap_12834;
    gpu_kernel big_mul_debugzisegmap_12860;
    gpu_kernel big_mul_debugzisegscan_12850;
    gpu_kernel big_mul_debugzisegscan_12858;
    gpu_kernel big_mul_validationzigpuseq_13024;
    gpu_kernel big_mul_validationzisegmap_12073;
    gpu_kernel big_mul_validationzisegmap_12240;
    gpu_kernel big_mul_validationzisegmap_12246;
    gpu_kernel big_mul_validationzisegmap_12272;
    gpu_kernel big_mul_validationzisegred_nonseg_12298;
    gpu_kernel big_mul_validationzisegscan_12288;
    gpu_kernel builtinzhreplicate_i32zireplicate_13090;
    gpu_kernel builtinzhreplicate_i64zireplicate_13010;
    gpu_kernel builtinzhreplicate_i8zireplicate_13116;
};
static void setup_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    ctx->program = malloc(sizeof(struct program));
    gpu_create_kernel(ctx, &ctx->program->big_add_debugzisegmap_12352, "big_add_debugzisegmap_12352");
    gpu_create_kernel(ctx, &ctx->program->big_add_debugzisegmap_12421, "big_add_debugzisegmap_12421");
    gpu_create_kernel(ctx, &ctx->program->big_add_debugzisegmap_12445, "big_add_debugzisegmap_12445");
    gpu_create_kernel(ctx, &ctx->program->big_add_debugzisegscan_12393, "big_add_debugzisegscan_12393");
    gpu_create_kernel(ctx, &ctx->program->big_add_debugzisegscan_12443, "big_add_debugzisegscan_12443");
    gpu_create_kernel(ctx, &ctx->program->big_add_validationzisegmap_11836, "big_add_validationzisegmap_11836");
    gpu_create_kernel(ctx, &ctx->program->big_add_validationzisegred_nonseg_11887, "big_add_validationzisegred_nonseg_11887");
    gpu_create_kernel(ctx, &ctx->program->big_add_validationzisegscan_11877, "big_add_validationzisegscan_11877");
    gpu_create_kernel(ctx, &ctx->program->big_mul_debugzigpuseq_13027, "big_mul_debugzigpuseq_13027");
    gpu_create_kernel(ctx, &ctx->program->big_mul_debugzisegmap_12635, "big_mul_debugzisegmap_12635");
    gpu_create_kernel(ctx, &ctx->program->big_mul_debugzisegmap_12802, "big_mul_debugzisegmap_12802");
    gpu_create_kernel(ctx, &ctx->program->big_mul_debugzisegmap_12808, "big_mul_debugzisegmap_12808");
    gpu_create_kernel(ctx, &ctx->program->big_mul_debugzisegmap_12834, "big_mul_debugzisegmap_12834");
    gpu_create_kernel(ctx, &ctx->program->big_mul_debugzisegmap_12860, "big_mul_debugzisegmap_12860");
    gpu_create_kernel(ctx, &ctx->program->big_mul_debugzisegscan_12850, "big_mul_debugzisegscan_12850");
    gpu_create_kernel(ctx, &ctx->program->big_mul_debugzisegscan_12858, "big_mul_debugzisegscan_12858");
    gpu_create_kernel(ctx, &ctx->program->big_mul_validationzigpuseq_13024, "big_mul_validationzigpuseq_13024");
    gpu_create_kernel(ctx, &ctx->program->big_mul_validationzisegmap_12073, "big_mul_validationzisegmap_12073");
    gpu_create_kernel(ctx, &ctx->program->big_mul_validationzisegmap_12240, "big_mul_validationzisegmap_12240");
    gpu_create_kernel(ctx, &ctx->program->big_mul_validationzisegmap_12246, "big_mul_validationzisegmap_12246");
    gpu_create_kernel(ctx, &ctx->program->big_mul_validationzisegmap_12272, "big_mul_validationzisegmap_12272");
    gpu_create_kernel(ctx, &ctx->program->big_mul_validationzisegred_nonseg_12298, "big_mul_validationzisegred_nonseg_12298");
    gpu_create_kernel(ctx, &ctx->program->big_mul_validationzisegscan_12288, "big_mul_validationzisegscan_12288");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i32zireplicate_13090, "builtinzhreplicate_i32zireplicate_13090");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i64zireplicate_13010, "builtinzhreplicate_i64zireplicate_13010");
    gpu_create_kernel(ctx, &ctx->program->builtinzhreplicate_i8zireplicate_13116, "builtinzhreplicate_i8zireplicate_13116");
}
static void teardown_program(struct futhark_context *ctx)
{
    (void) ctx;
    
    int error = 0;
    
    (void) error;
    gpu_free_kernel(ctx, ctx->program->big_add_debugzisegmap_12352);
    gpu_free_kernel(ctx, ctx->program->big_add_debugzisegmap_12421);
    gpu_free_kernel(ctx, ctx->program->big_add_debugzisegmap_12445);
    gpu_free_kernel(ctx, ctx->program->big_add_debugzisegscan_12393);
    gpu_free_kernel(ctx, ctx->program->big_add_debugzisegscan_12443);
    gpu_free_kernel(ctx, ctx->program->big_add_validationzisegmap_11836);
    gpu_free_kernel(ctx, ctx->program->big_add_validationzisegred_nonseg_11887);
    gpu_free_kernel(ctx, ctx->program->big_add_validationzisegscan_11877);
    gpu_free_kernel(ctx, ctx->program->big_mul_debugzigpuseq_13027);
    gpu_free_kernel(ctx, ctx->program->big_mul_debugzisegmap_12635);
    gpu_free_kernel(ctx, ctx->program->big_mul_debugzisegmap_12802);
    gpu_free_kernel(ctx, ctx->program->big_mul_debugzisegmap_12808);
    gpu_free_kernel(ctx, ctx->program->big_mul_debugzisegmap_12834);
    gpu_free_kernel(ctx, ctx->program->big_mul_debugzisegmap_12860);
    gpu_free_kernel(ctx, ctx->program->big_mul_debugzisegscan_12850);
    gpu_free_kernel(ctx, ctx->program->big_mul_debugzisegscan_12858);
    gpu_free_kernel(ctx, ctx->program->big_mul_validationzigpuseq_13024);
    gpu_free_kernel(ctx, ctx->program->big_mul_validationzisegmap_12073);
    gpu_free_kernel(ctx, ctx->program->big_mul_validationzisegmap_12240);
    gpu_free_kernel(ctx, ctx->program->big_mul_validationzisegmap_12246);
    gpu_free_kernel(ctx, ctx->program->big_mul_validationzisegmap_12272);
    gpu_free_kernel(ctx, ctx->program->big_mul_validationzisegred_nonseg_12298);
    gpu_free_kernel(ctx, ctx->program->big_mul_validationzisegscan_12288);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_13090);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i64zireplicate_13010);
    gpu_free_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_13116);
    free(ctx->program);
}
static void set_tuning_params(struct futhark_context *ctx)
{
    (void) ctx;
    ctx->tuning_params.big_add_debugzisegmap_group_sizze_12302 = &ctx->cfg->tuning_params[0];
    ctx->tuning_params.big_add_debugzisegmap_group_sizze_12397 = &ctx->cfg->tuning_params[1];
    ctx->tuning_params.big_add_debugzisegmap_group_sizze_12447 = &ctx->cfg->tuning_params[2];
    ctx->tuning_params.big_add_debugzisegscan_group_sizze_12387 = &ctx->cfg->tuning_params[3];
    ctx->tuning_params.big_add_debugzisegscan_group_sizze_12437 = &ctx->cfg->tuning_params[4];
    ctx->tuning_params.big_add_debugzisegscan_num_groups_12389 = &ctx->cfg->tuning_params[5];
    ctx->tuning_params.big_add_debugzisegscan_num_groups_12439 = &ctx->cfg->tuning_params[6];
    ctx->tuning_params.big_add_validationzisegmap_group_sizze_11786 = &ctx->cfg->tuning_params[7];
    ctx->tuning_params.big_add_validationzisegred_group_sizze_11879 = &ctx->cfg->tuning_params[8];
    ctx->tuning_params.big_add_validationzisegred_num_groups_11881 = &ctx->cfg->tuning_params[9];
    ctx->tuning_params.big_add_validationzisegscan_group_sizze_11871 = &ctx->cfg->tuning_params[10];
    ctx->tuning_params.big_add_validationzisegscan_num_groups_11873 = &ctx->cfg->tuning_params[11];
    ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12453 = &ctx->cfg->tuning_params[12];
    ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12804 = &ctx->cfg->tuning_params[13];
    ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12810 = &ctx->cfg->tuning_params[14];
    ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12816 = &ctx->cfg->tuning_params[15];
    ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12862 = &ctx->cfg->tuning_params[16];
    ctx->tuning_params.big_mul_debugzisegscan_group_sizze_12844 = &ctx->cfg->tuning_params[17];
    ctx->tuning_params.big_mul_debugzisegscan_group_sizze_12852 = &ctx->cfg->tuning_params[18];
    ctx->tuning_params.big_mul_debugzisegscan_num_groups_12846 = &ctx->cfg->tuning_params[19];
    ctx->tuning_params.big_mul_debugzisegscan_num_groups_12854 = &ctx->cfg->tuning_params[20];
    ctx->tuning_params.big_mul_validationzisegmap_group_sizze_11891 = &ctx->cfg->tuning_params[21];
    ctx->tuning_params.big_mul_validationzisegmap_group_sizze_12242 = &ctx->cfg->tuning_params[22];
    ctx->tuning_params.big_mul_validationzisegmap_group_sizze_12248 = &ctx->cfg->tuning_params[23];
    ctx->tuning_params.big_mul_validationzisegmap_group_sizze_12254 = &ctx->cfg->tuning_params[24];
    ctx->tuning_params.big_mul_validationzisegred_group_sizze_12290 = &ctx->cfg->tuning_params[25];
    ctx->tuning_params.big_mul_validationzisegred_num_groups_12292 = &ctx->cfg->tuning_params[26];
    ctx->tuning_params.big_mul_validationzisegscan_group_sizze_12282 = &ctx->cfg->tuning_params[27];
    ctx->tuning_params.big_mul_validationzisegscan_num_groups_12284 = &ctx->cfg->tuning_params[28];
    ctx->tuning_params.builtinzhreplicate_i32zigroup_sizze_13094 = &ctx->cfg->tuning_params[29];
    ctx->tuning_params.builtinzhreplicate_i64zigroup_sizze_13014 = &ctx->cfg->tuning_params[30];
    ctx->tuning_params.builtinzhreplicate_i8zigroup_sizze_13120 = &ctx->cfg->tuning_params[31];
}
int memblock_unref_device(struct futhark_context *ctx, struct memblock_device *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "space 'device'", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_device -= block->size;
            (void) gpu_free(ctx, block->mem, block->size, desc);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_device);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc_device(struct futhark_context *ctx, struct memblock_device *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "space 'device'", ctx->cur_mem_usage_device);
    
    int ret = memblock_unref_device(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "space 'device'", (long long) ctx->cur_mem_usage_device);
    (void) gpu_alloc(ctx, ctx->log, (size_t) size, desc, &block->mem, (size_t *) &size);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_device + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_device = new_usage;
        if (new_usage > ctx->peak_mem_usage_device) {
            ctx->peak_mem_usage_device = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "space 'device'", (long long) size, (long long) ctx->cur_mem_usage_device, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set_device(struct futhark_context *ctx, struct memblock_device *lhs, struct memblock_device *rhs, const char *lhs_desc)
{
    int ret = memblock_unref_device(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
int memblock_unref(struct futhark_context *ctx, struct memblock *block, const char *desc)
{
    if (block->references != NULL) {
        *block->references -= 1;
        if (ctx->detail_memory)
            fprintf(ctx->log, "Unreferencing block %s (allocated as %s) in %s: %d references remaining.\n", desc, block->desc, "default space", *block->references);
        if (*block->references == 0) {
            ctx->cur_mem_usage_default -= block->size;
            host_free(ctx, (size_t) block->size, desc, (void *) block->mem);
            free(block->references);
            if (ctx->detail_memory)
                fprintf(ctx->log, "%lld bytes freed (now allocated: %lld bytes)\n", (long long) block->size, (long long) ctx->cur_mem_usage_default);
        }
        block->references = NULL;
    }
    return 0;
}
int memblock_alloc(struct futhark_context *ctx, struct memblock *block, int64_t size, const char *desc)
{
    if (size < 0)
        futhark_panic(1, "Negative allocation of %lld bytes attempted for %s in %s.\n", (long long) size, desc, "default space", ctx->cur_mem_usage_default);
    
    int ret = memblock_unref(ctx, block, desc);
    
    if (ret != FUTHARK_SUCCESS)
        return ret;
    if (ctx->detail_memory)
        fprintf(ctx->log, "Allocating %lld bytes for %s in %s (currently allocated: %lld bytes).\n", (long long) size, desc, "default space", (long long) ctx->cur_mem_usage_default);
    host_alloc(ctx, (size_t) size, desc, (size_t *) &size, (void *) &block->mem);
    if (ctx->error == NULL) {
        block->references = (int *) malloc(sizeof(int));
        *block->references = 1;
        block->size = size;
        block->desc = desc;
        
        long long new_usage = ctx->cur_mem_usage_default + size;
        
        if (ctx->detail_memory)
            fprintf(ctx->log, "Received block of %lld bytes; now allocated: %lld bytes", (long long) block->size, new_usage);
        ctx->cur_mem_usage_default = new_usage;
        if (new_usage > ctx->peak_mem_usage_default) {
            ctx->peak_mem_usage_default = new_usage;
            if (ctx->detail_memory)
                fprintf(ctx->log, " (new peak).\n");
        } else if (ctx->detail_memory)
            fprintf(ctx->log, ".\n");
        return FUTHARK_SUCCESS;
    } else {
        // We are naively assuming that any memory allocation error is due to OOM.
        lock_lock(&ctx->error_lock);
        
        char *old_error = ctx->error;
        
        ctx->error = msgprintf("Failed to allocate memory in %s.\nAttempted allocation: %12lld bytes\nCurrently allocated:  %12lld bytes\n%s", "default space", (long long) size, (long long) ctx->cur_mem_usage_default, old_error);
        free(old_error);
        lock_unlock(&ctx->error_lock);
        return FUTHARK_OUT_OF_MEMORY;
    }
}
int memblock_set(struct futhark_context *ctx, struct memblock *lhs, struct memblock *rhs, const char *lhs_desc)
{
    int ret = memblock_unref(ctx, lhs, lhs_desc);
    
    if (rhs->references != NULL)
        (*rhs->references)++;
    *lhs = *rhs;
    return ret;
}
void futhark_context_config_set_debugging(struct futhark_context_config *cfg, int flag)
{
    cfg->profiling = cfg->logging = cfg->debugging = flag;
}
void futhark_context_config_set_profiling(struct futhark_context_config *cfg, int flag)
{
    cfg->profiling = flag;
}
void futhark_context_config_set_logging(struct futhark_context_config *cfg, int flag)
{
    cfg->logging = flag;
}
void futhark_context_config_set_cache_file(struct futhark_context_config *cfg, const char *f)
{
    cfg->cache_fname = f;
}
int futhark_get_tuning_param_count(void)
{
    return num_tuning_params;
}
const char *futhark_get_tuning_param_name(int i)
{
    return tuning_param_names[i];
}
const char *futhark_get_tuning_param_class(int i)
{
    return tuning_param_classes[i];
}
char *futhark_context_report(struct futhark_context *ctx)
{
    if (futhark_context_sync(ctx) != 0)
        return NULL;
    
    struct str_builder builder;
    
    str_builder_init(&builder);
    str_builder(&builder, "Peak memory usage for space 'device': %lld bytes.\n", (long long) ctx->peak_mem_usage_device);
    { }
    if (ctx->profiling) {
        {
            struct cost_centres *ccs = cost_centres_new();
            
            cost_centres_init(ccs, "copy_dev_to_dev");
            cost_centres_init(ccs, "copy_dev_to_host");
            cost_centres_init(ccs, "copy_host_to_dev");
            cost_centres_init(ccs, "copy_scalar_to_dev");
            cost_centres_init(ccs, "copy_scalar_from_dev");
            cost_centres_init(ccs, "big_add_debug.segmap_12352");
            cost_centres_init(ccs, "big_add_debug.segmap_12421");
            cost_centres_init(ccs, "big_add_debug.segmap_12445");
            cost_centres_init(ccs, "big_add_debug.segscan_12393");
            cost_centres_init(ccs, "big_add_debug.segscan_12443");
            cost_centres_init(ccs, "big_add_validation.segmap_11836");
            cost_centres_init(ccs, "big_add_validation.segred_nonseg_11887");
            cost_centres_init(ccs, "big_add_validation.segscan_11877");
            cost_centres_init(ccs, "big_mul_debug.gpuseq_13027");
            cost_centres_init(ccs, "big_mul_debug.segmap_12635");
            cost_centres_init(ccs, "big_mul_debug.segmap_12802");
            cost_centres_init(ccs, "big_mul_debug.segmap_12808");
            cost_centres_init(ccs, "big_mul_debug.segmap_12834");
            cost_centres_init(ccs, "big_mul_debug.segmap_12860");
            cost_centres_init(ccs, "big_mul_debug.segscan_12850");
            cost_centres_init(ccs, "big_mul_debug.segscan_12858");
            cost_centres_init(ccs, "big_mul_validation.gpuseq_13024");
            cost_centres_init(ccs, "big_mul_validation.segmap_12073");
            cost_centres_init(ccs, "big_mul_validation.segmap_12240");
            cost_centres_init(ccs, "big_mul_validation.segmap_12246");
            cost_centres_init(ccs, "big_mul_validation.segmap_12272");
            cost_centres_init(ccs, "big_mul_validation.segred_nonseg_12298");
            cost_centres_init(ccs, "big_mul_validation.segscan_12288");
            cost_centres_init(ccs, "builtin#replicate_i32.replicate_13090");
            cost_centres_init(ccs, "builtin#replicate_i64.replicate_13010");
            cost_centres_init(ccs, "builtin#replicate_i8.replicate_13116");
            tally_profiling_records(ctx, ccs);
            cost_centre_report(ccs, &builder);
            cost_centres_free(ccs);
        }
    }
    return builder.str;
}
char *futhark_context_get_error(struct futhark_context *ctx)
{
    char *error = ctx->error;
    
    ctx->error = NULL;
    return error;
}
void futhark_context_set_logging_file(struct futhark_context *ctx, FILE *f)
{
    ctx->log = f;
}
void futhark_context_pause_profiling(struct futhark_context *ctx)
{
    ctx->profiling_paused = 1;
}
void futhark_context_unpause_profiling(struct futhark_context *ctx)
{
    ctx->profiling_paused = 0;
}
int futhark_context_clear_caches(struct futhark_context *ctx)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    ctx->peak_mem_usage_device = 0;
    ctx->peak_mem_usage_default = 0;
    if (ctx->error == NULL)
        gpu_free_all(ctx);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ctx->error != NULL;
}

// Start of context.h

// Eventually it would be nice to move the context definition in here
// instead of generating it in the compiler.  For now it defines
// various helper functions that must be available.

// Internal functions.

static void set_error(struct futhark_context* ctx, char *error) {
  lock_lock(&ctx->error_lock);
  if (ctx->error == NULL) {
    ctx->error = error;
  } else {
    free(error);
  }
  lock_unlock(&ctx->error_lock);
}

// XXX: should be static, but used in ispc_util.h
void lexical_realloc_error(struct futhark_context* ctx, size_t new_size) {
  set_error(ctx,
            msgprintf("Failed to allocate memory.\nAttempted allocation: %12lld bytes\n",
                      (long long) new_size));
}

static int lexical_realloc(struct futhark_context *ctx,
                           unsigned char **ptr,
                           int64_t *old_size,
                           int64_t new_size) {
  unsigned char *new = realloc(*ptr, (size_t)new_size);
  if (new == NULL) {
    lexical_realloc_error(ctx, new_size);
    return FUTHARK_OUT_OF_MEMORY;
  } else {
    *ptr = new;
    *old_size = new_size;
    return FUTHARK_SUCCESS;
  }
}

static void free_all_in_free_list(struct futhark_context* ctx) {
  fl_mem mem;
  free_list_pack(&ctx->free_list);
  while (free_list_first(&ctx->free_list, (fl_mem*)&mem) == 0) {
    free((void*)mem);
  }
}

static int is_small_alloc(size_t size) {
  return size < 1024*1024;
}

static void host_alloc(struct futhark_context* ctx,
                       size_t size, const char* tag, size_t* size_out, void** mem_out) {
  if (is_small_alloc(size) || free_list_find(&ctx->free_list, size, tag, size_out, (fl_mem*)mem_out) != 0) {
    *size_out = size;
    *mem_out = malloc(size);
  }
}

static void host_free(struct futhark_context* ctx,
                      size_t size, const char* tag, void* mem) {
  // Small allocations are handled by malloc()s own free list.  The
  // threshold here is kind of arbitrary, but seems to work OK.
  // Larger allocations are mmap()ed/munmapped() every time, which is
  // very slow, and Futhark programs tend to use a few very large
  // allocations.
  if (is_small_alloc(size)) {
    free(mem);
  } else {
    free_list_insert(&ctx->free_list, size, (fl_mem)mem, tag);
  }
}

struct futhark_context_config* futhark_context_config_new(void) {
  struct futhark_context_config* cfg = malloc(sizeof(struct futhark_context_config));
  if (cfg == NULL) {
    return NULL;
  }
  cfg->in_use = 0;
  cfg->debugging = 0;
  cfg->profiling = 0;
  cfg->logging = 0;
  cfg->cache_fname = NULL;
  cfg->num_tuning_params = num_tuning_params;
  cfg->tuning_params = malloc(cfg->num_tuning_params * sizeof(int64_t));
  memcpy(cfg->tuning_params, tuning_param_defaults,
         cfg->num_tuning_params * sizeof(int64_t));
  cfg->tuning_param_names = tuning_param_names;
  cfg->tuning_param_vars = tuning_param_vars;
  cfg->tuning_param_classes = tuning_param_classes;
  backend_context_config_setup(cfg);
  return cfg;
}

void futhark_context_config_free(struct futhark_context_config* cfg) {
  assert(!cfg->in_use);
  backend_context_config_teardown(cfg);
  free(cfg->tuning_params);
  free(cfg);
}

struct futhark_context* futhark_context_new(struct futhark_context_config* cfg) {
  struct futhark_context* ctx = malloc(sizeof(struct futhark_context));
  if (ctx == NULL) {
    return NULL;
  }
  assert(!cfg->in_use);
  ctx->cfg = cfg;
  ctx->cfg->in_use = 1;
  create_lock(&ctx->error_lock);
  create_lock(&ctx->lock);
  free_list_init(&ctx->free_list);
  ctx->peak_mem_usage_default = 0;
  ctx->cur_mem_usage_default = 0;
  ctx->constants = malloc(sizeof(struct constants));
  ctx->detail_memory = cfg->debugging;
  ctx->debugging = cfg->debugging;
  ctx->logging = cfg->logging;
  ctx->profiling = cfg->profiling;
  ctx->profiling_paused = 0;
  ctx->error = NULL;
  ctx->log = stderr;
  if (backend_context_setup(ctx) == 0) {
    set_tuning_params(ctx);
    setup_program(ctx);
    init_constants(ctx);
    (void)futhark_context_clear_caches(ctx);
    (void)futhark_context_sync(ctx);
  }
  return ctx;
}

void futhark_context_free(struct futhark_context* ctx) {
  free_constants(ctx);
  teardown_program(ctx);
  backend_context_teardown(ctx);
  free_all_in_free_list(ctx);
  free_list_destroy(&ctx->free_list);
  free(ctx->constants);
  free_lock(&ctx->lock);
  free_lock(&ctx->error_lock);
  ctx->cfg->in_use = 0;
  free(ctx);
}

// End of context.h

// Start of copy.h

// Cache-oblivious map-transpose function.
#define GEN_MAP_TRANSPOSE(NAME, ELEM_TYPE)                              \
  static void map_transpose_##NAME                                      \
  (ELEM_TYPE* dst, ELEM_TYPE* src,                                      \
   int64_t k, int64_t m, int64_t n,                                     \
   int64_t cb, int64_t ce, int64_t rb, int64_t re)                      \
  {                                                                     \
  int32_t r = re - rb;                                                  \
  int32_t c = ce - cb;                                                  \
  if (k == 1) {                                                         \
    if (r <= 64 && c <= 64) {                                           \
      for (int64_t j = 0; j < c; j++) {                                 \
        for (int64_t i = 0; i < r; i++) {                               \
          dst[(j + cb) * n + (i + rb)] = src[(i + rb) * m + (j + cb)];  \
        }                                                               \
      }                                                                 \
    } else if (c <= r) {                                                \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb, rb + r/2);    \
      map_transpose_##NAME(dst, src, k, m, n, cb, ce, rb + r/2, re);    \
    } else {                                                            \
      map_transpose_##NAME(dst, src, k, m, n, cb, cb + c/2, rb, re);    \
      map_transpose_##NAME(dst, src, k, m, n, cb + c/2, ce, rb, re);    \
    }                                                                   \
  } else {                                                              \
  for (int64_t i = 0; i < k; i++) {                                     \
    map_transpose_##NAME(dst + i * m * n, src + i * m * n, 1, m, n, cb, ce, rb, re); \
  }\
} \
}

// Straightforward LMAD copy function.
#define GEN_LMAD_COPY_ELEMENTS(NAME, ELEM_TYPE)                         \
  static void lmad_copy_elements_##NAME(int r,                          \
                                        ELEM_TYPE* dst, int64_t dst_strides[r], \
                                        ELEM_TYPE *src, int64_t src_strides[r], \
                                        int64_t shape[r]) {             \
    if (r == 1) {                                                       \
      for (int i = 0; i < shape[0]; i++) {                              \
        dst[i*dst_strides[0]] = src[i*src_strides[0]];                  \
      }                                                                 \
    } else if (r > 1) {                                                 \
      for (int i = 0; i < shape[0]; i++) {                              \
        lmad_copy_elements_##NAME(r-1,                                  \
                                  dst+i*dst_strides[0], dst_strides+1,  \
                                  src+i*src_strides[0], src_strides+1,  \
                                  shape+1);                             \
      }                                                                 \
    }                                                                   \
  }                                                                     \

// Check whether this LMAD can be seen as a transposed 2D array.  This
// is done by checking every possible splitting point.
static bool lmad_is_tr(int64_t *n_out, int64_t *m_out,
                       int r,
                       const int64_t strides[r],
                       const int64_t shape[r]) {
  for (int i = 1; i < r; i++) {
    int n = 1, m = 1;
    bool ok = true;
    int64_t expected = 1;
    // Check strides before 'i'.
    for (int j = i-1; j >= 0; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      n *= shape[j];
    }
    // Check strides after 'i'.
    for (int j = r-1; j >= i; j--) {
      ok = ok && strides[j] == expected;
      expected *= shape[j];
      m *= shape[j];
    }
    if (ok) {
      *n_out = n;
      *m_out = m;
      return true;
    }
  }
  return false;
}

// This function determines whether the a 'dst' LMAD is row-major and
// 'src' LMAD is column-major.  Both LMADs are for arrays of the same
// shape.  Both LMADs are allowed to have additional dimensions "on
// top".  Essentially, this function determines whether a copy from
// 'src' to 'dst' is a "map(transpose)" that we know how to implement
// efficiently.  The LMADs can have arbitrary rank, and the main
// challenge here is checking whether the src LMAD actually
// corresponds to a 2D column-major layout by morally collapsing
// dimensions.  There is a lot of looping here, but the actual trip
// count is going to be very low in practice.
//
// Returns true if this is indeed a map(transpose), and writes the
// number of arrays, and moral array size to appropriate output
// parameters.
static bool lmad_map_tr(int64_t *num_arrays_out, int64_t *n_out, int64_t *m_out,
                        int r,
                        const int64_t dst_strides[r],
                        const int64_t src_strides[r],
                        const int64_t shape[r]) {
  int64_t rowmajor_strides[r];
  rowmajor_strides[r-1] = 1;

  for (int i = r-2; i >= 0; i--) {
    rowmajor_strides[i] = rowmajor_strides[i+1] * shape[i+1];
  }

  // map_r will be the number of mapped dimensions on top.
  int map_r = 0;
  int64_t num_arrays = 1;
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != rowmajor_strides[i] ||
        src_strides[i] != rowmajor_strides[i]) {
      break;
    } else {
      num_arrays *= shape[i];
      map_r++;
    }
  }

  *num_arrays_out = num_arrays;

  if (memcmp(&rowmajor_strides[map_r],
             &dst_strides[map_r],
             sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(n_out, m_out, r-map_r, src_strides+map_r, shape+map_r);
  } else if (memcmp(&rowmajor_strides[map_r],
                    &src_strides[map_r],
                    sizeof(int64_t)*(r-map_r)) == 0) {
    return lmad_is_tr(m_out, n_out, r-map_r, dst_strides+map_r, shape+map_r);
  }
  return false;
}

// Check if the strides correspond to row-major strides of *any*
// permutation of the shape.  This is done by recursive search with
// backtracking.  This is worst-case exponential, but hopefully the
// arrays we encounter do not have that many dimensions.
static bool lmad_contiguous_search(int checked, int64_t expected,
                                   int r,
                                   int64_t strides[r], int64_t shape[r], bool used[r]) {
  for (int i = 0; i < r; i++) {
    for (int j = 0; j < r; j++) {
      if (!used[j] && strides[j] == expected && strides[j] >= 0) {
        used[j] = true;
        if (checked+1 == r ||
            lmad_contiguous_search(checked+1, expected * shape[j], r, strides, shape, used)) {
          return true;
        }
        used[j] = false;
      }
    }
  }
  return false;
}

// Does this LMAD correspond to an array with positive strides and no
// holes?
static bool lmad_contiguous(int r, int64_t strides[r], int64_t shape[r]) {
  bool used[r];
  for (int i = 0; i < r; i++) {
    used[i] = false;
  }
  return lmad_contiguous_search(0, 1, r, strides, shape, used);
}

// Does this copy correspond to something that could be done with a
// memcpy()-like operation?  I.e. do the LMADs actually represent the
// same in-memory layout and are they contiguous?
static bool lmad_memcpyable(int r,
                            int64_t dst_strides[r], int64_t src_strides[r], int64_t shape[r]) {
  if (!lmad_contiguous(r, dst_strides, shape)) {
    return false;
  }
  for (int i = 0; i < r; i++) {
    if (dst_strides[i] != src_strides[i] && shape[i] != 1) {
      return false;
    }
  }
  return true;
}


static void log_copy(struct futhark_context* ctx,
                     const char *kind, int r,
                     int64_t dst_offset, int64_t dst_strides[r],
                     int64_t src_offset, int64_t src_strides[r],
                     int64_t shape[r]) {
  if (ctx->logging) {
    fprintf(ctx->log, "\n# Copy %s\n", kind);
    fprintf(ctx->log, "Shape: ");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, "[%ld]", (long int)shape[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Dst offset: %ld\n", dst_offset);
    fprintf(ctx->log, "Dst strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)dst_strides[i]); }
    fprintf(ctx->log, "\n");
    fprintf(ctx->log, "Src offset: %ld\n", src_offset);
    fprintf(ctx->log, "Src strides:");
    for (int i = 0; i < r; i++) { fprintf(ctx->log, " %ld", (long int)src_strides[i]); }
    fprintf(ctx->log, "\n");
  }
}

static void log_transpose(struct futhark_context* ctx,
                          int64_t k, int64_t n, int64_t m) {
  if (ctx->logging) {
    fprintf(ctx->log, "## Transpose\n");
    fprintf(ctx->log, "Arrays     : %ld\n", (long int)k);
    fprintf(ctx->log, "X elements : %ld\n", (long int)m);
    fprintf(ctx->log, "Y elements : %ld\n", (long int)n);
    fprintf(ctx->log, "\n");
  }
}

#define GEN_LMAD_COPY(NAME, ELEM_TYPE)                                  \
  static void lmad_copy_##NAME                                          \
  (struct futhark_context *ctx, int r,                                  \
   ELEM_TYPE* dst, int64_t dst_offset, int64_t dst_strides[r],          \
   ELEM_TYPE *src, int64_t src_offset, int64_t src_strides[r],          \
   int64_t shape[r]) {                                                  \
    log_copy(ctx, "CPU to CPU", r, dst_offset, dst_strides,             \
             src_offset, src_strides, shape);                           \
    int64_t size = 1;                                                   \
    for (int i = 0; i < r; i++) { size *= shape[i]; }                   \
    if (size == 0) { return; }                                          \
    int64_t k, n, m;                                                    \
    if (lmad_map_tr(&k, &n, &m,                                         \
                    r, dst_strides, src_strides, shape)) {              \
      log_transpose(ctx, k, n, m);                                      \
      map_transpose_##NAME                                              \
        (dst+dst_offset, src+src_offset, k, n, m, 0, n, 0, m);          \
    } else if (lmad_memcpyable(r, dst_strides, src_strides, shape)) {   \
      if (ctx->logging) {fprintf(ctx->log, "## Flat copy\n\n");}          \
      memcpy(dst+dst_offset, src+src_offset, size*sizeof(*dst));        \
    } else {                                                            \
      if (ctx->logging) {fprintf(ctx->log, "## General copy\n\n");}       \
      lmad_copy_elements_##NAME                                         \
        (r,                                                             \
         dst+dst_offset, dst_strides,                                   \
         src+src_offset, src_strides, shape);                           \
    }                                                                   \
  }

GEN_MAP_TRANSPOSE(1b, uint8_t)
GEN_MAP_TRANSPOSE(2b, uint16_t)
GEN_MAP_TRANSPOSE(4b, uint32_t)
GEN_MAP_TRANSPOSE(8b, uint64_t)

GEN_LMAD_COPY_ELEMENTS(1b, uint8_t)
GEN_LMAD_COPY_ELEMENTS(2b, uint16_t)
GEN_LMAD_COPY_ELEMENTS(4b, uint32_t)
GEN_LMAD_COPY_ELEMENTS(8b, uint64_t)

GEN_LMAD_COPY(1b, uint8_t)
GEN_LMAD_COPY(2b, uint16_t)
GEN_LMAD_COPY(4b, uint32_t)
GEN_LMAD_COPY(8b, uint64_t)

// End of copy.h

#define FUTHARK_FUN_ATTR static

FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_13085, int64_t num_elems_13086, int32_t val_13087);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_13005, int64_t num_elems_13006, int64_t val_13007);
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_13111, int64_t num_elems_13112, int8_t val_13113);
FUTHARK_FUN_ATTR int futrts_entry_big_add_debug(struct futhark_context *ctx, struct memblock_device *mem_out_p_13358, struct memblock_device *mem_out_p_13359, struct memblock_device *mem_out_p_13360, int64_t *out_prim_out_13361, struct memblock_device as_mem_12913, struct memblock_device bs_mem_12914, struct memblock_device exp_res_mem_12915, int64_t m_9060);
FUTHARK_FUN_ATTR int futrts_entry_big_add_validation(struct futhark_context *ctx, bool *out_prim_out_13363, struct memblock_device as_mem_12913, struct memblock_device bs_mem_12914, struct memblock_device exp_res_mem_12915, int64_t m_8724);
FUTHARK_FUN_ATTR int futrts_entry_big_mul_debug(struct futhark_context *ctx, struct memblock_device *mem_out_p_13365, struct memblock_device *mem_out_p_13366, struct memblock_device *mem_out_p_13367, int64_t *out_prim_out_13368, struct memblock_device as_mem_12913, struct memblock_device bs_mem_12914, struct memblock_device exp_res_mem_12915, int64_t m_10188);
FUTHARK_FUN_ATTR int futrts_entry_big_mul_validation(struct futhark_context *ctx, bool *out_prim_out_13370, struct memblock_device as_mem_12913, struct memblock_device bs_mem_12914, struct memblock_device exp_res_mem_12915, int64_t m_9987);

static int init_constants(struct futhark_context *ctx)
{
    (void) ctx;
    
    int err = 0;
    
    #define counters_mem_13188 (ctx->constants->counters_mem_13188)
    #define counters_mem_13253 (ctx->constants->counters_mem_13253)
    #define id_counter_mem_13014 (ctx->constants->id_counter_mem_13014)
    #define id_counter_mem_13017 (ctx->constants->id_counter_mem_13017)
    #define id_counter_mem_13080 (ctx->constants->id_counter_mem_13080)
    #define id_counter_mem_13083 (ctx->constants->id_counter_mem_13083)
    #define id_counter_mem_13202 (ctx->constants->id_counter_mem_13202)
    #define id_counter_mem_13258 (ctx->constants->id_counter_mem_13258)
    counters_mem_13188.references = NULL;
    counters_mem_13253.references = NULL;
    id_counter_mem_13014.references = NULL;
    id_counter_mem_13017.references = NULL;
    id_counter_mem_13080.references = NULL;
    id_counter_mem_13083.references = NULL;
    id_counter_mem_13202.references = NULL;
    id_counter_mem_13258.references = NULL;
    if (memblock_alloc_device(ctx, &id_counter_mem_13014, (int64_t) 4, "id_counter_mem_13014")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, id_counter_mem_13014, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_13188, (int64_t) 40, "counters_mem_13188")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_13188, (int64_t) 10, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &id_counter_mem_13080, (int64_t) 4, "id_counter_mem_13080")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, id_counter_mem_13080, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &counters_mem_13253, (int64_t) 40, "counters_mem_13253")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, counters_mem_13253, (int64_t) 10, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &id_counter_mem_13017, (int64_t) 4, "id_counter_mem_13017")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, id_counter_mem_13017, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &id_counter_mem_13202, (int64_t) 4, "id_counter_mem_13202")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, id_counter_mem_13202, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &id_counter_mem_13083, (int64_t) 4, "id_counter_mem_13083")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, id_counter_mem_13083, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &id_counter_mem_13258, (int64_t) 4, "id_counter_mem_13258")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i32(ctx, id_counter_mem_13258, (int64_t) 1, 0) != 0) {
        err = 1;
        goto cleanup;
    }
    #undef counters_mem_13188
    #undef counters_mem_13253
    #undef id_counter_mem_13014
    #undef id_counter_mem_13017
    #undef id_counter_mem_13080
    #undef id_counter_mem_13083
    #undef id_counter_mem_13202
    #undef id_counter_mem_13258
    
  cleanup:
    return err;
}
static int free_constants(struct futhark_context *ctx)
{
    (void) ctx;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_13188, "ctx->constants->counters_mem_13188") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->counters_mem_13253, "ctx->constants->counters_mem_13253") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->id_counter_mem_13014, "ctx->constants->id_counter_mem_13014") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->id_counter_mem_13017, "ctx->constants->id_counter_mem_13017") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->id_counter_mem_13080, "ctx->constants->id_counter_mem_13080") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->id_counter_mem_13083, "ctx->constants->id_counter_mem_13083") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->id_counter_mem_13202, "ctx->constants->id_counter_mem_13202") != 0)
        return 1;
    if (memblock_unref_device(ctx, &ctx->constants->id_counter_mem_13258, "ctx->constants->id_counter_mem_13258") != 0)
        return 1;
    return 0;
}
static int gpu_kernel_builtinzhreplicate_i32zireplicate_13090(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int32_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i32zireplicate_13090, "builtin#replicate_i32.replicate_13090", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i64zireplicate_13010(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i64zireplicate_13010, "builtin#replicate_i64.replicate_13010", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_builtinzhreplicate_i8zireplicate_13116(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int8_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&arg0, &arg1, &arg2, &arg3, &arg4, &arg5};
        size_t args_sizes[6] = {sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5)};
        
        return gpu_launch_kernel(ctx, ctx->program->builtinzhreplicate_i8zireplicate_13116, "builtin#replicate_i8.replicate_13116", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_add_debugzisegmap_12352(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, int32_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_add_debugzisegmap_12352, "big_add_debug.segmap_12352", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_add_debugzisegscan_12393(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15, gpu_mem arg16, gpu_mem arg17, gpu_mem arg18, gpu_mem arg19)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[21] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15, &arg16, &arg17, &arg18, &arg19};
        size_t args_sizes[21] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15), sizeof(arg16), sizeof(arg17), sizeof(arg18), sizeof(arg19)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_add_debugzisegscan_12393, "big_add_debug.segscan_12393", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 21, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_add_debugzisegmap_12421(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[7] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3};
        size_t args_sizes[7] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_add_debugzisegmap_12421, "big_add_debug.segmap_12421", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 7, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_add_debugzisegscan_12443(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_add_debugzisegscan_12443, "big_add_debug.segscan_12443", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_add_debugzisegmap_12445(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_add_debugzisegmap_12445, "big_add_debug.segmap_12445", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_add_validationzisegmap_11836(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, int32_t arg3, int32_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[18] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14};
        size_t args_sizes[18] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_add_validationzisegmap_11836, "big_add_validation.segmap_11836", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 18, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_add_validationzisegscan_11877(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13, gpu_mem arg14, gpu_mem arg15, gpu_mem arg16, gpu_mem arg17, gpu_mem arg18, gpu_mem arg19)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[21] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13, &arg14, &arg15, &arg16, &arg17, &arg18, &arg19};
        size_t args_sizes[21] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13), sizeof(arg14), sizeof(arg15), sizeof(arg16), sizeof(arg17), sizeof(arg18), sizeof(arg19)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_add_validationzisegscan_11877, "big_add_validation.segscan_11877", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 21, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_add_validationzisegred_nonseg_11887(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, int64_t arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[15] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11};
        size_t args_sizes[15] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_add_validationzisegred_nonseg_11887, "big_add_validation.segred_nonseg_11887", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 15, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_debugzigpuseq_13027(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[3] = {&ctx->global_failure, &arg0, &arg1};
        size_t args_sizes[3] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_debugzigpuseq_13027, "big_mul_debug.gpuseq_13027", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 3, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_debugzisegmap_12635(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[17] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[17] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_debugzisegmap_12635, "big_mul_debug.segmap_12635", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 17, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_debugzisegmap_12802(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_debugzisegmap_12802, "big_mul_debug.segmap_12802", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_debugzisegmap_12808(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_debugzisegmap_12808, "big_mul_debug.segmap_12808", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_debugzisegmap_12834(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_debugzisegmap_12834, "big_mul_debug.segmap_12834", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_debugzisegscan_12850(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_debugzisegscan_12850, "big_mul_debug.segscan_12850", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_debugzisegscan_12858(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[16] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[16] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_debugzisegscan_12858, "big_mul_debug.segscan_12858", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 16, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_debugzisegmap_12860(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, gpu_mem arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[9] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7};
        size_t args_sizes[9] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_debugzisegmap_12860, "big_mul_debug.segmap_12860", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 9, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_validationzigpuseq_13024(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, gpu_mem arg0, gpu_mem arg1)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[3] = {&ctx->global_failure, &arg0, &arg1};
        size_t args_sizes[3] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_validationzigpuseq_13024, "big_mul_validation.gpuseq_13024", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 3, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_validationzisegmap_12073(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int32_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12, gpu_mem arg13)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[17] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12, &arg13};
        size_t args_sizes[17] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12), sizeof(arg13)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_validationzisegmap_12073, "big_mul_validation.segmap_12073", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 17, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_validationzisegmap_12240(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_validationzisegmap_12240, "big_mul_validation.segmap_12240", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_validationzisegmap_12246(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, gpu_mem arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[12] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[12] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_validationzisegmap_12246, "big_mul_validation.segmap_12246", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 12, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_validationzisegmap_12272(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, gpu_mem arg2, gpu_mem arg3, gpu_mem arg4)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[6] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4};
        size_t args_sizes[6] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_validationzisegmap_12272, "big_mul_validation.segmap_12272", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 6, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_validationzisegscan_12288(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, gpu_mem arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10, gpu_mem arg11, gpu_mem arg12)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10, &arg11, &arg12};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10), sizeof(arg11), sizeof(arg12)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_validationzisegscan_12288, "big_mul_validation.segscan_12288", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
static int gpu_kernel_big_mul_validationzisegred_nonseg_12298(struct futhark_context *ctx, unsigned int grid_x, unsigned int grid_y, unsigned int grid_z, unsigned int block_x, unsigned int block_y, unsigned int block_z, unsigned int shared_bytes, int64_t arg0, int64_t arg1, int64_t arg2, int64_t arg3, int64_t arg4, gpu_mem arg5, gpu_mem arg6, gpu_mem arg7, gpu_mem arg8, gpu_mem arg9, gpu_mem arg10)
{
    if (grid_x * grid_y * grid_z * block_x * block_y * block_z != 0) {
        void *args[14] = {&ctx->global_failure, &ctx->failure_is_an_option, &ctx->global_failure_args, &arg0, &arg1, &arg2, &arg3, &arg4, &arg5, &arg6, &arg7, &arg8, &arg9, &arg10};
        size_t args_sizes[14] = {sizeof(ctx->global_failure), sizeof(ctx->failure_is_an_option), sizeof(ctx->global_failure_args), sizeof(arg0), sizeof(arg1), sizeof(arg2), sizeof(arg3), sizeof(arg4), sizeof(arg5), sizeof(arg6), sizeof(arg7), sizeof(arg8), sizeof(arg9), sizeof(arg10)};
        
        return gpu_launch_kernel(ctx, ctx->program->big_mul_validationzisegred_nonseg_12298, "big_mul_validation.segred_nonseg_12298", (const int32_t []) {grid_x, grid_y, grid_z}, (const int32_t []) {block_x, block_y, block_z}, shared_bytes, 14, args, args_sizes);
    }
    return FUTHARK_SUCCESS;
}
struct futhark_u64_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_u64_1d *futhark_new_u64_1d(struct futhark_context *ctx, const uint64_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_u64_1d *bad = NULL;
    struct futhark_u64_1d *arr = (struct futhark_u64_1d *) malloc(sizeof(struct futhark_u64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 8, "arr->mem"))
        return NULL;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_u64_1d *futhark_new_raw_u64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t offset, int64_t dim0)
{
    int err = 0;
    struct futhark_u64_1d *bad = NULL;
    struct futhark_u64_1d *arr = (struct futhark_u64_1d *) malloc(sizeof(struct futhark_u64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 8, "arr->mem"))
        return NULL;
    arr->shape[0] = dim0;
    err = gpu_memcpy(ctx, arr->mem.mem, 0, data, offset, (size_t) dim0 * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_u64_1d(struct futhark_context *ctx, struct futhark_u64_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_u64_1d(struct futhark_context *ctx, struct futhark_u64_1d *arr, uint64_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
CUdeviceptr futhark_values_raw_u64_1d(struct futhark_context *ctx, struct futhark_u64_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_u64_1d(struct futhark_context *ctx, struct futhark_u64_1d *arr)
{
    (void) ctx;
    return arr->shape;
}
struct futhark_i64_1d {
    struct memblock_device mem;
    int64_t shape[1];
};
struct futhark_i64_1d *futhark_new_i64_1d(struct futhark_context *ctx, const int64_t *data, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 8, "arr->mem"))
        return NULL;
    arr->shape[0] = dim0;
    err = memcpy_host2gpu(ctx, false, arr->mem.mem, 0, (const unsigned char *) data, 0, (size_t) dim0 * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    if (err != 0) {
        free(arr);
        return bad;
    }
    return arr;
}
struct futhark_i64_1d *futhark_new_raw_i64_1d(struct futhark_context *ctx, CUdeviceptr data, int64_t offset, int64_t dim0)
{
    int err = 0;
    struct futhark_i64_1d *bad = NULL;
    struct futhark_i64_1d *arr = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d));
    
    if (arr == NULL)
        return bad;
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    arr->mem.references = NULL;
    if (memblock_alloc_device(ctx, &arr->mem, dim0 * 8, "arr->mem"))
        return NULL;
    arr->shape[0] = dim0;
    err = gpu_memcpy(ctx, arr->mem.mem, 0, data, offset, (size_t) dim0 * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return arr;
}
int futhark_free_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    if (memblock_unref_device(ctx, &arr->mem, "arr->mem") != 0)
        return 1;
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    free(arr);
    return 0;
}
int futhark_values_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr, int64_t *data)
{
    int err = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    err = memcpy_gpu2host(ctx, false, (unsigned char *) data, 0, arr->mem.mem, 0, (size_t) arr->shape[0] * 8);
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return err;
}
CUdeviceptr futhark_values_raw_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->mem.mem;
}
const int64_t *futhark_shape_i64_1d(struct futhark_context *ctx, struct futhark_i64_1d *arr)
{
    (void) ctx;
    return arr->shape;
}

FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i32(struct futhark_context *ctx, struct memblock_device mem_13085, int64_t num_elems_13086, int32_t val_13087)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_13188 = ctx->constants->counters_mem_13188;
    struct memblock_device counters_mem_13253 = ctx->constants->counters_mem_13253;
    struct memblock_device id_counter_mem_13014 = ctx->constants->id_counter_mem_13014;
    struct memblock_device id_counter_mem_13017 = ctx->constants->id_counter_mem_13017;
    struct memblock_device id_counter_mem_13080 = ctx->constants->id_counter_mem_13080;
    struct memblock_device id_counter_mem_13083 = ctx->constants->id_counter_mem_13083;
    struct memblock_device id_counter_mem_13202 = ctx->constants->id_counter_mem_13202;
    struct memblock_device id_counter_mem_13258 = ctx->constants->id_counter_mem_13258;
    int64_t replicate_n_13089 = num_elems_13086;
    int64_t group_sizze_13094;
    
    group_sizze_13094 = *ctx->tuning_params.builtinzhreplicate_i32zigroup_sizze_13094;
    
    int64_t virt_num_groups_13095 = sdiv_up64(replicate_n_13089, group_sizze_13094);
    int64_t num_groups_13096 = smin64(virt_num_groups_13095, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i32zireplicate_13090(ctx, num_groups_13096, 1, 1, group_sizze_13094, 1, 1, (int64_t) 0, num_elems_13086, val_13087, replicate_n_13089, virt_num_groups_13095, num_groups_13096, mem_13085.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i64(struct futhark_context *ctx, struct memblock_device mem_13005, int64_t num_elems_13006, int64_t val_13007)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_13188 = ctx->constants->counters_mem_13188;
    struct memblock_device counters_mem_13253 = ctx->constants->counters_mem_13253;
    struct memblock_device id_counter_mem_13014 = ctx->constants->id_counter_mem_13014;
    struct memblock_device id_counter_mem_13017 = ctx->constants->id_counter_mem_13017;
    struct memblock_device id_counter_mem_13080 = ctx->constants->id_counter_mem_13080;
    struct memblock_device id_counter_mem_13083 = ctx->constants->id_counter_mem_13083;
    struct memblock_device id_counter_mem_13202 = ctx->constants->id_counter_mem_13202;
    struct memblock_device id_counter_mem_13258 = ctx->constants->id_counter_mem_13258;
    int64_t replicate_n_13009 = num_elems_13006;
    int64_t group_sizze_13014;
    
    group_sizze_13014 = *ctx->tuning_params.builtinzhreplicate_i64zigroup_sizze_13014;
    
    int64_t virt_num_groups_13015 = sdiv_up64(replicate_n_13009, group_sizze_13014);
    int64_t num_groups_13016 = smin64(virt_num_groups_13015, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i64zireplicate_13010(ctx, num_groups_13016, 1, 1, group_sizze_13014, 1, 1, (int64_t) 0, num_elems_13006, val_13007, replicate_n_13009, virt_num_groups_13015, num_groups_13016, mem_13005.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_builtinzhreplicate_i8(struct futhark_context *ctx, struct memblock_device mem_13111, int64_t num_elems_13112, int8_t val_13113)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device counters_mem_13188 = ctx->constants->counters_mem_13188;
    struct memblock_device counters_mem_13253 = ctx->constants->counters_mem_13253;
    struct memblock_device id_counter_mem_13014 = ctx->constants->id_counter_mem_13014;
    struct memblock_device id_counter_mem_13017 = ctx->constants->id_counter_mem_13017;
    struct memblock_device id_counter_mem_13080 = ctx->constants->id_counter_mem_13080;
    struct memblock_device id_counter_mem_13083 = ctx->constants->id_counter_mem_13083;
    struct memblock_device id_counter_mem_13202 = ctx->constants->id_counter_mem_13202;
    struct memblock_device id_counter_mem_13258 = ctx->constants->id_counter_mem_13258;
    int64_t replicate_n_13115 = num_elems_13112;
    int64_t group_sizze_13120;
    
    group_sizze_13120 = *ctx->tuning_params.builtinzhreplicate_i8zigroup_sizze_13120;
    
    int64_t virt_num_groups_13121 = sdiv_up64(replicate_n_13115, group_sizze_13120);
    int64_t num_groups_13122 = smin64(virt_num_groups_13121, (int64_t) 1048576);
    
    {
        err = gpu_kernel_builtinzhreplicate_i8zireplicate_13116(ctx, num_groups_13122, 1, 1, group_sizze_13120, 1, 1, (int64_t) 0, num_elems_13112, val_13113, replicate_n_13115, virt_num_groups_13121, num_groups_13122, mem_13111.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
  cleanup:
    { }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_big_add_debug(struct futhark_context *ctx, struct memblock_device *mem_out_p_13358, struct memblock_device *mem_out_p_13359, struct memblock_device *mem_out_p_13360, int64_t *out_prim_out_13361, struct memblock_device as_mem_12913, struct memblock_device bs_mem_12914, struct memblock_device exp_res_mem_12915, int64_t m_9060)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_12977;
    
    mem_12977.references = NULL;
    
    struct memblock_device mem_12974;
    
    mem_12974.references = NULL;
    
    struct memblock_device mem_12971;
    
    mem_12971.references = NULL;
    
    struct memblock_device mem_12967;
    
    mem_12967.references = NULL;
    
    struct memblock_device mem_12964;
    
    mem_12964.references = NULL;
    
    struct memblock_device mem_12961;
    
    mem_12961.references = NULL;
    
    struct memblock_device incprefixes_mem_13208;
    
    incprefixes_mem_13208.references = NULL;
    
    struct memblock_device aggregates_mem_13206;
    
    aggregates_mem_13206.references = NULL;
    
    struct memblock_device status_flags_mem_13204;
    
    status_flags_mem_13204.references = NULL;
    
    struct memblock_device mem_12958;
    
    mem_12958.references = NULL;
    
    struct memblock_device mem_12955;
    
    mem_12955.references = NULL;
    
    struct memblock_device mem_12951;
    
    mem_12951.references = NULL;
    
    struct memblock_device incprefixes_mem_13043;
    
    incprefixes_mem_13043.references = NULL;
    
    struct memblock_device aggregates_mem_13041;
    
    aggregates_mem_13041.references = NULL;
    
    struct memblock_device status_flags_mem_13039;
    
    status_flags_mem_13039.references = NULL;
    
    struct memblock_device mem_12947;
    
    mem_12947.references = NULL;
    
    struct memblock_device mem_12944;
    
    mem_12944.references = NULL;
    
    struct memblock_device mem_12940;
    
    mem_12940.references = NULL;
    
    struct memblock_device mem_12937;
    
    mem_12937.references = NULL;
    
    struct memblock_device mem_12934;
    
    mem_12934.references = NULL;
    
    struct memblock_device mem_12931;
    
    mem_12931.references = NULL;
    
    struct memblock_device mem_12928;
    
    mem_12928.references = NULL;
    
    struct memblock_device mem_12925;
    
    mem_12925.references = NULL;
    
    struct memblock_device mem_12922;
    
    mem_12922.references = NULL;
    
    struct memblock_device mem_12919;
    
    mem_12919.references = NULL;
    
    struct memblock_device mem_out_13003;
    
    mem_out_13003.references = NULL;
    
    struct memblock_device mem_out_13002;
    
    mem_out_13002.references = NULL;
    
    struct memblock_device mem_out_13001;
    
    mem_out_13001.references = NULL;
    
    struct memblock_device counters_mem_13188 = ctx->constants->counters_mem_13188;
    struct memblock_device counters_mem_13253 = ctx->constants->counters_mem_13253;
    struct memblock_device id_counter_mem_13014 = ctx->constants->id_counter_mem_13014;
    struct memblock_device id_counter_mem_13017 = ctx->constants->id_counter_mem_13017;
    struct memblock_device id_counter_mem_13080 = ctx->constants->id_counter_mem_13080;
    struct memblock_device id_counter_mem_13083 = ctx->constants->id_counter_mem_13083;
    struct memblock_device id_counter_mem_13202 = ctx->constants->id_counter_mem_13202;
    struct memblock_device id_counter_mem_13258 = ctx->constants->id_counter_mem_13258;
    int64_t prim_out_13004;
    int64_t n_10772 = sdiv64(m_9060, (int64_t) 4);
    int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10773 = mul64((int64_t) 4, n_10772);
    bool dim_match_10774 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773 == m_9060;
    bool empty_or_match_cert_10775;
    
    if (!dim_match_10774) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Value of (core language) shape (", (long long) m_9060, ") cannot match shape of type `[", (long long) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, "]u64`.", "-> #0  big-arith-valid.fut:10:38-52\n   #1  big-arith-valid.fut:8:1-11:91\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool bounds_invalid_upwards_11183 = slt64(n_10772, (int64_t) 0);
    bool valid_11184 = !bounds_invalid_upwards_11183;
    bool range_valid_c_11185;
    
    if (!valid_11184) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..<", (long long) n_10772, " is invalid.", "-> #0  big-arith-fut/bigadd.fut:28:23-28\n   #1  big-arith-valid.fut:8:1-11:91\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int32_t i64_res_11190 = sext_i64_i32(n_10772);
    int32_t zp_lhs_11192 = mul32(3, i64_res_11190);
    int32_t zp_lhs_11191 = mul32(2, i64_res_11190);
    int64_t segmap_group_sizze_12341;
    
    segmap_group_sizze_12341 = *ctx->tuning_params.big_add_debugzisegmap_group_sizze_12302;
    
    int64_t segmap_usable_groups_12342 = sdiv_up64(n_10772, segmap_group_sizze_12341);
    int64_t binop_y_12917 = (int64_t) 8 * n_10772;
    int64_t bytes_12918 = smax64((int64_t) 0, binop_y_12917);
    
    if (memblock_alloc_device(ctx, &mem_12919, bytes_12918, "mem_12919")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12922, bytes_12918, "mem_12922")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12925, bytes_12918, "mem_12925")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12928, bytes_12918, "mem_12928")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12931, bytes_12918, "mem_12931")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12934, bytes_12918, "mem_12934")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12937, bytes_12918, "mem_12937")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12940, bytes_12918, "mem_12940")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_13005 = sext_i64_i32(sdiv_up64(n_10772, segmap_group_sizze_12341));
    
    {
        err = gpu_kernel_big_add_debugzisegmap_12352(ctx, segmap_usable_groups_12342, 1, 1, *ctx->tuning_params.big_add_debugzisegmap_group_sizze_12302, 1, 1, (int64_t) 0, n_10772, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, i64_res_11190, zp_lhs_11191, zp_lhs_11192, as_mem_12913.mem, bs_mem_12914.mem, mem_12919.mem, mem_12922.mem, mem_12925.mem, mem_12928.mem, mem_12931.mem, mem_12934.mem, mem_12937.mem, mem_12940.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    ctx->failure_is_an_option = 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t conc_tmp_11249 = n_10772 + n_10772;
    int64_t conc_tmp_11251 = n_10772 + conc_tmp_11249;
    int64_t conc_tmp_11253 = n_10772 + conc_tmp_11251;
    int64_t segscan_group_sizze_12388;
    
    segscan_group_sizze_12388 = *ctx->tuning_params.big_add_debugzisegscan_group_sizze_12387;
    
    int64_t num_groups_12390;
    int32_t max_num_groups_13014;
    
    max_num_groups_13014 = *ctx->tuning_params.big_add_debugzisegscan_num_groups_12389;
    num_groups_12390 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(conc_tmp_11253, segscan_group_sizze_12388), sext_i32_i64(max_num_groups_13014))));
    
    int64_t binop_y_12942 = (int64_t) 4 * conc_tmp_11253;
    int64_t bytes_12943 = smax64((int64_t) 0, binop_y_12942);
    int64_t binop_y_12945 = (int64_t) 8 * conc_tmp_11253;
    int64_t bytes_12946 = smax64((int64_t) 0, binop_y_12945);
    
    if (memblock_alloc_device(ctx, &mem_12944, bytes_12943, "mem_12944")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12947, bytes_12946, "mem_12947")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, conc_tmp_11253)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t num_groups_13015 = sdiv_up64(conc_tmp_11253, segscan_group_sizze_12388 * (int64_t) 23);
        int64_t num_threads_13016 = num_groups_13015 * segscan_group_sizze_12388;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (m) ", (long long) 23, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory constraint", (long long) 23, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Register constraint", (long long) 31, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "sumT'", (long long) 1, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_13039, num_groups_13015, "status_flags_mem_13039")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_13041, (int64_t) 4 * num_groups_13015, "aggregates_mem_13041")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_13043, (int64_t) 4 * num_groups_13015, "incprefixes_mem_13043")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_13039, num_groups_13015, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_big_add_debugzisegscan_12393(ctx, num_groups_13015, 1, 1, *ctx->tuning_params.big_add_debugzisegscan_group_sizze_12387, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_group_sizze_12388), (int64_t) 23 * segscan_group_sizze_12388 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_group_sizze_12388), (int64_t) 23 * segscan_group_sizze_12388 * (int64_t) 4), (int64_t) 8), (int64_t) 8), (int64_t) 0, n_10772, conc_tmp_11249, conc_tmp_11251, conc_tmp_11253, num_groups_13015, mem_12919.mem, mem_12922.mem, mem_12925.mem, mem_12928.mem, mem_12931.mem, mem_12934.mem, mem_12937.mem, mem_12940.mem, mem_12944.mem, mem_12947.mem, id_counter_mem_13017.mem, status_flags_mem_13039.mem, aggregates_mem_13041.mem, incprefixes_mem_13043.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_12919, "mem_12919") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12922, "mem_12922") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12925, "mem_12925") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12928, "mem_12928") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12931, "mem_12931") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12934, "mem_12934") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12937, "mem_12937") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12940, "mem_12940") != 0)
        return 1;
    
    int64_t segmap_group_sizze_12417;
    
    segmap_group_sizze_12417 = *ctx->tuning_params.big_add_debugzisegmap_group_sizze_12397;
    
    int64_t segmap_usable_groups_12418 = sdiv_up64(conc_tmp_11253, segmap_group_sizze_12417);
    
    if (memblock_alloc_device(ctx, &mem_12951, bytes_12946, "mem_12951")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_13190 = sext_i64_i32(sdiv_up64(conc_tmp_11253, segmap_group_sizze_12417));
    
    {
        err = gpu_kernel_big_add_debugzisegmap_12421(ctx, segmap_usable_groups_12418, 1, 1, *ctx->tuning_params.big_add_debugzisegmap_group_sizze_12397, 1, 1, (int64_t) 0, conc_tmp_11253, mem_12944.mem, mem_12947.mem, mem_12951.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    ctx->failure_is_an_option = 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_12944, "mem_12944") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12947, "mem_12947") != 0)
        return 1;
    
    bool dim_match_11302 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773 == conc_tmp_11253;
    bool empty_or_match_cert_11303;
    
    if (!dim_match_11302) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Value of (core language) shape (", (long long) conc_tmp_11253, ") cannot match shape of type `[", (long long) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, "]u64`.", "-> #0  big-arith-fut/bigadd.fut:35:8-35\n   #1  big-arith-valid.fut:8:1-11:91\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t segscan_group_sizze_12438;
    
    segscan_group_sizze_12438 = *ctx->tuning_params.big_add_debugzisegscan_group_sizze_12437;
    
    int64_t num_groups_12440;
    int32_t max_num_groups_13199;
    
    max_num_groups_13199 = *ctx->tuning_params.big_add_debugzisegscan_num_groups_12439;
    num_groups_12440 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, segscan_group_sizze_12438), sext_i32_i64(max_num_groups_13199))));
    
    int64_t binop_y_12953 = (int64_t) 32 * n_10772;
    int64_t bytes_12954 = smax64((int64_t) 0, binop_y_12953);
    
    if (memblock_alloc_device(ctx, &mem_12955, bytes_12954, "mem_12955")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12958, bytes_12954, "mem_12958")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t num_groups_13200 = sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, segscan_group_sizze_12438 * (int64_t) 11);
        int64_t num_threads_13201 = num_groups_13200 * segscan_group_sizze_12438;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (m) ", (long long) 11, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory constraint", (long long) 11, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Register constraint", (long long) 15, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "sumT'", (long long) 2, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_13204, num_groups_13200, "status_flags_mem_13204")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_13206, (int64_t) 8 * num_groups_13200, "aggregates_mem_13206")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_13208, (int64_t) 8 * num_groups_13200, "incprefixes_mem_13208")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_13204, num_groups_13200, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_big_add_debugzisegscan_12443(ctx, num_groups_13200, 1, 1, *ctx->tuning_params.big_add_debugzisegscan_group_sizze_12437, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_group_sizze_12438), (int64_t) 11 * segscan_group_sizze_12438 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_group_sizze_12438), (int64_t) 11 * segscan_group_sizze_12438 * (int64_t) 8), (int64_t) 8), (int64_t) 8), (int64_t) 0, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, num_groups_13200, exp_res_mem_12915.mem, mem_12951.mem, mem_12955.mem, mem_12958.mem, id_counter_mem_13202.mem, status_flags_mem_13204.mem, aggregates_mem_13206.mem, incprefixes_mem_13208.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    
    int64_t last_index_10799 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773 - (int64_t) 1;
    bool is_empty_10800 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773 == (int64_t) 0;
    bool x_10801 = !is_empty_10800;
    int64_t last_offset_10802;
    
    if (x_10801 == 1) {
        int64_t read_res_13362;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_13362, mem_12955.mem, last_index_10799 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_11626 = read_res_13362;
        
        last_offset_10802 = x_11626;
    } else {
        last_offset_10802 = (int64_t) 0;
    }
    
    int64_t partition_sizze_10804;
    
    if (is_empty_10800 == 1) {
        partition_sizze_10804 = (int64_t) 0;
    } else {
        partition_sizze_10804 = last_offset_10802;
    }
    
    bool eq_x_zz_10819 = (int64_t) 0 == last_offset_10802;
    bool p_and_eq_x_y_10820 = x_10801 && eq_x_zz_10819;
    bool empty_slice_10821 = is_empty_10800 || p_and_eq_x_y_10820;
    int64_t m_10822 = sub64(partition_sizze_10804, (int64_t) 1);
    bool zzero_leq_i_p_m_t_s_10823 = sle64((int64_t) 0, m_10822);
    bool i_p_m_t_s_leq_w_10824 = slt64(m_10822, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);
    bool i_lte_j_10825 = sle64((int64_t) 0, partition_sizze_10804);
    bool y_10826 = zzero_leq_i_p_m_t_s_10823 && i_p_m_t_s_leq_w_10824;
    bool forwards_ok_10827 = i_lte_j_10825 && y_10826;
    bool ok_or_empty_10828 = empty_slice_10821 || forwards_ok_10827;
    bool index_certs_10829;
    
    if (!ok_or_empty_10828) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) partition_sizze_10804, "] out of bounds for array of shape [", (long long) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, "].", "-> #0  /prelude/soacs.fut:173:6-17\n   #1  big-arith-valid.fut:11:39-80\n   #2  big-arith-valid.fut:8:1-11:91\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t binop_y_12969 = (int64_t) 8 * partition_sizze_10804;
    int64_t bytes_12970 = smax64((int64_t) 0, binop_y_12969);
    
    if (memblock_alloc_device(ctx, &mem_12961, bytes_12954, "mem_12961")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12964, bytes_12954, "mem_12964")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12967, bytes_12954, "mem_12967")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_group_sizze_12448;
    
    segmap_group_sizze_12448 = *ctx->tuning_params.big_add_debugzisegmap_group_sizze_12447;
    
    int64_t segmap_usable_groups_12449 = sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, segmap_group_sizze_12448);
    
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_13293 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, segmap_group_sizze_12448));
    
    {
        err = gpu_kernel_big_add_debugzisegmap_12445(ctx, segmap_usable_groups_12449, 1, 1, *ctx->tuning_params.big_add_debugzisegmap_group_sizze_12447, 1, 1, (int64_t) 0, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, exp_res_mem_12915.mem, mem_12951.mem, mem_12955.mem, mem_12958.mem, mem_12961.mem, mem_12964.mem, mem_12967.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_12951, "mem_12951") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12955, "mem_12955") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12958, "mem_12958") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_12971, bytes_12970, "mem_12971")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_12971.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_12961.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {partition_sizze_10804})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &mem_12961, "mem_12961") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_12974, bytes_12970, "mem_12974")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_12974.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_12964.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {partition_sizze_10804})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &mem_12964, "mem_12964") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_12977, bytes_12970, "mem_12977")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_12977.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_12967.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {partition_sizze_10804})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &mem_12967, "mem_12967") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_13001, &mem_12971, "mem_12971") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_13002, &mem_12974, "mem_12974") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_13003, &mem_12977, "mem_12977") != 0)
        return 1;
    prim_out_13004 = partition_sizze_10804;
    if (memblock_set_device(ctx, &*mem_out_p_13358, &mem_out_13001, "mem_out_13001") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_13359, &mem_out_13002, "mem_out_13002") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_13360, &mem_out_13003, "mem_out_13003") != 0)
        return 1;
    *out_prim_out_13361 = prim_out_13004;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_12977, "mem_12977") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12974, "mem_12974") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12971, "mem_12971") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12967, "mem_12967") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12964, "mem_12964") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12961, "mem_12961") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_13208, "incprefixes_mem_13208") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_13206, "aggregates_mem_13206") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_13204, "status_flags_mem_13204") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12958, "mem_12958") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12955, "mem_12955") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12951, "mem_12951") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_13043, "incprefixes_mem_13043") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_13041, "aggregates_mem_13041") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_13039, "status_flags_mem_13039") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12947, "mem_12947") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12944, "mem_12944") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12940, "mem_12940") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12937, "mem_12937") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12934, "mem_12934") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12931, "mem_12931") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12928, "mem_12928") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12925, "mem_12925") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12922, "mem_12922") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12919, "mem_12919") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_13003, "mem_out_13003") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_13002, "mem_out_13002") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_13001, "mem_out_13001") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_big_add_validation(struct futhark_context *ctx, bool *out_prim_out_13363, struct memblock_device as_mem_12913, struct memblock_device bs_mem_12914, struct memblock_device exp_res_mem_12915, int64_t m_8724)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device segred_tmp_mem_13190;
    
    segred_tmp_mem_13190.references = NULL;
    
    struct memblock_device mem_12950;
    
    mem_12950.references = NULL;
    
    struct memblock_device incprefixes_mem_13040;
    
    incprefixes_mem_13040.references = NULL;
    
    struct memblock_device aggregates_mem_13038;
    
    aggregates_mem_13038.references = NULL;
    
    struct memblock_device status_flags_mem_13036;
    
    status_flags_mem_13036.references = NULL;
    
    struct memblock_device mem_12947;
    
    mem_12947.references = NULL;
    
    struct memblock_device mem_12944;
    
    mem_12944.references = NULL;
    
    struct memblock_device mem_12940;
    
    mem_12940.references = NULL;
    
    struct memblock_device mem_12937;
    
    mem_12937.references = NULL;
    
    struct memblock_device mem_12934;
    
    mem_12934.references = NULL;
    
    struct memblock_device mem_12931;
    
    mem_12931.references = NULL;
    
    struct memblock_device mem_12928;
    
    mem_12928.references = NULL;
    
    struct memblock_device mem_12925;
    
    mem_12925.references = NULL;
    
    struct memblock_device mem_12922;
    
    mem_12922.references = NULL;
    
    struct memblock_device mem_12919;
    
    mem_12919.references = NULL;
    
    struct memblock_device counters_mem_13188 = ctx->constants->counters_mem_13188;
    struct memblock_device counters_mem_13253 = ctx->constants->counters_mem_13253;
    struct memblock_device id_counter_mem_13014 = ctx->constants->id_counter_mem_13014;
    struct memblock_device id_counter_mem_13017 = ctx->constants->id_counter_mem_13017;
    struct memblock_device id_counter_mem_13080 = ctx->constants->id_counter_mem_13080;
    struct memblock_device id_counter_mem_13083 = ctx->constants->id_counter_mem_13083;
    struct memblock_device id_counter_mem_13202 = ctx->constants->id_counter_mem_13202;
    struct memblock_device id_counter_mem_13258 = ctx->constants->id_counter_mem_13258;
    bool prim_out_13001;
    int64_t n_10211 = sdiv64(m_8724, (int64_t) 4);
    int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10212 = mul64((int64_t) 4, n_10211);
    bool dim_match_10213 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10212 == m_8724;
    bool empty_or_match_cert_10214;
    
    if (!dim_match_10213) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Value of (core language) shape (", (long long) m_8724, ") cannot match shape of type `[", (long long) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, "]u64`.", "-> #0  big-arith-valid.fut:6:33-47\n   #1  big-arith-valid.fut:4:1-6:73\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool bounds_invalid_upwards_11183 = slt64(n_10211, (int64_t) 0);
    bool valid_11184 = !bounds_invalid_upwards_11183;
    bool range_valid_c_11185;
    
    if (!valid_11184) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..<", (long long) n_10211, " is invalid.", "-> #0  big-arith-fut/bigadd.fut:28:23-28\n   #1  big-arith-valid.fut:6:8-47\n   #2  big-arith-valid.fut:4:1-6:73\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t binop_y_12917 = (int64_t) 8 * n_10211;
    int64_t bytes_12918 = smax64((int64_t) 0, binop_y_12917);
    int64_t conc_tmp_11249 = n_10211 + n_10211;
    int64_t conc_tmp_11251 = n_10211 + conc_tmp_11249;
    int64_t conc_tmp_11253 = n_10211 + conc_tmp_11251;
    int64_t binop_y_12942 = (int64_t) 4 * conc_tmp_11253;
    int64_t bytes_12943 = smax64((int64_t) 0, binop_y_12942);
    int64_t binop_y_12945 = (int64_t) 8 * conc_tmp_11253;
    int64_t bytes_12946 = smax64((int64_t) 0, binop_y_12945);
    bool dim_match_11302 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10212 == conc_tmp_11253;
    bool empty_or_match_cert_11303;
    
    if (!dim_match_11302) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Value of (core language) shape (", (long long) conc_tmp_11253, ") cannot match shape of type `[", (long long) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, "]u64`.", "-> #0  big-arith-fut/bigadd.fut:35:8-35\n   #1  big-arith-valid.fut:6:8-47\n   #2  big-arith-valid.fut:4:1-6:73\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int32_t i64_res_11190 = sext_i64_i32(n_10211);
    int32_t zp_lhs_11192 = mul32(3, i64_res_11190);
    int32_t zp_lhs_11191 = mul32(2, i64_res_11190);
    int64_t segmap_group_sizze_11825;
    
    segmap_group_sizze_11825 = *ctx->tuning_params.big_add_validationzisegmap_group_sizze_11786;
    
    int64_t segmap_usable_groups_11826 = sdiv_up64(n_10211, segmap_group_sizze_11825);
    
    if (memblock_alloc_device(ctx, &mem_12919, bytes_12918, "mem_12919")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12922, bytes_12918, "mem_12922")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12925, bytes_12918, "mem_12925")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12928, bytes_12918, "mem_12928")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12931, bytes_12918, "mem_12931")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12934, bytes_12918, "mem_12934")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12937, bytes_12918, "mem_12937")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12940, bytes_12918, "mem_12940")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_13002 = sext_i64_i32(sdiv_up64(n_10211, segmap_group_sizze_11825));
    
    {
        err = gpu_kernel_big_add_validationzisegmap_11836(ctx, segmap_usable_groups_11826, 1, 1, *ctx->tuning_params.big_add_validationzisegmap_group_sizze_11786, 1, 1, (int64_t) 0, n_10211, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, i64_res_11190, zp_lhs_11191, zp_lhs_11192, as_mem_12913.mem, bs_mem_12914.mem, mem_12919.mem, mem_12922.mem, mem_12925.mem, mem_12928.mem, mem_12931.mem, mem_12934.mem, mem_12937.mem, mem_12940.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    ctx->failure_is_an_option = 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    
    int64_t segscan_group_sizze_11872;
    
    segscan_group_sizze_11872 = *ctx->tuning_params.big_add_validationzisegscan_group_sizze_11871;
    
    int64_t num_groups_11874;
    int32_t max_num_groups_13011;
    
    max_num_groups_13011 = *ctx->tuning_params.big_add_validationzisegscan_num_groups_11873;
    num_groups_11874 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(conc_tmp_11253, segscan_group_sizze_11872), sext_i32_i64(max_num_groups_13011))));
    if (memblock_alloc_device(ctx, &mem_12944, bytes_12943, "mem_12944")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12947, bytes_12946, "mem_12947")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, conc_tmp_11253)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t num_groups_13012 = sdiv_up64(conc_tmp_11253, segscan_group_sizze_11872 * (int64_t) 23);
        int64_t num_threads_13013 = num_groups_13012 * segscan_group_sizze_11872;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (m) ", (long long) 23, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory constraint", (long long) 23, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Register constraint", (long long) 31, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "sumT'", (long long) 1, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_13036, num_groups_13012, "status_flags_mem_13036")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_13038, (int64_t) 4 * num_groups_13012, "aggregates_mem_13038")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_13040, (int64_t) 4 * num_groups_13012, "incprefixes_mem_13040")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_13036, num_groups_13012, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_big_add_validationzisegscan_11877(ctx, num_groups_13012, 1, 1, *ctx->tuning_params.big_add_validationzisegscan_group_sizze_11871, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_group_sizze_11872), (int64_t) 23 * segscan_group_sizze_11872 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_group_sizze_11872), (int64_t) 23 * segscan_group_sizze_11872 * (int64_t) 4), (int64_t) 8), (int64_t) 8), (int64_t) 0, n_10211, conc_tmp_11249, conc_tmp_11251, conc_tmp_11253, num_groups_13012, mem_12919.mem, mem_12922.mem, mem_12925.mem, mem_12928.mem, mem_12931.mem, mem_12934.mem, mem_12937.mem, mem_12940.mem, mem_12944.mem, mem_12947.mem, id_counter_mem_13014.mem, status_flags_mem_13036.mem, aggregates_mem_13038.mem, incprefixes_mem_13040.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_12919, "mem_12919") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12922, "mem_12922") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12925, "mem_12925") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12928, "mem_12928") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12931, "mem_12931") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12934, "mem_12934") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12937, "mem_12937") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12940, "mem_12940") != 0)
        return 1;
    
    int64_t segred_group_sizze_11880;
    
    segred_group_sizze_11880 = *ctx->tuning_params.big_add_validationzisegred_group_sizze_11879;
    
    int64_t num_groups_11882;
    int32_t max_num_groups_13187;
    
    max_num_groups_13187 = *ctx->tuning_params.big_add_validationzisegred_num_groups_11881;
    num_groups_11882 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, segred_group_sizze_11880), sext_i32_i64(max_num_groups_13187))));
    if (memblock_alloc_device(ctx, &mem_12950, (int64_t) 1, "mem_12950")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegRed");
    if (memblock_alloc_device(ctx, &segred_tmp_mem_13190, num_groups_11882, "segred_tmp_mem_13190")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t num_threads_13192 = num_groups_11882 * segred_group_sizze_11880;
    
    {
        err = gpu_kernel_big_add_validationzisegred_nonseg_11887(ctx, num_groups_11882, 1, 1, *ctx->tuning_params.big_add_validationzisegred_group_sizze_11879, 1, 1, segred_group_sizze_11880 + srem64((int64_t) 8 - srem64(segred_group_sizze_11880, (int64_t) 8), (int64_t) 8) + 8, (int64_t) 0, segred_group_sizze_11880 + srem64((int64_t) 8 - srem64(segred_group_sizze_11880, (int64_t) 8), (int64_t) 8), dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, conc_tmp_11253, num_groups_11882, num_threads_13192, exp_res_mem_12915.mem, mem_12944.mem, mem_12947.mem, mem_12950.mem, counters_mem_13188.mem, segred_tmp_mem_13190.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    ctx->failure_is_an_option = 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_12944, "mem_12944") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12947, "mem_12947") != 0)
        return 1;
    
    bool read_res_13364;
    
    if ((err = gpu_scalar_from_device(ctx, &read_res_13364, mem_12950.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
        goto cleanup;
    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool all_equal_11647 = read_res_13364;
    
    if (memblock_unref_device(ctx, &mem_12950, "mem_12950") != 0)
        return 1;
    prim_out_13001 = all_equal_11647;
    *out_prim_out_13363 = prim_out_13001;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &segred_tmp_mem_13190, "segred_tmp_mem_13190") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12950, "mem_12950") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_13040, "incprefixes_mem_13040") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_13038, "aggregates_mem_13038") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_13036, "status_flags_mem_13036") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12947, "mem_12947") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12944, "mem_12944") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12940, "mem_12940") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12937, "mem_12937") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12934, "mem_12934") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12931, "mem_12931") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12928, "mem_12928") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12925, "mem_12925") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12922, "mem_12922") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12919, "mem_12919") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_big_mul_debug(struct futhark_context *ctx, struct memblock_device *mem_out_p_13365, struct memblock_device *mem_out_p_13366, struct memblock_device *mem_out_p_13367, int64_t *out_prim_out_13368, struct memblock_device as_mem_12913, struct memblock_device bs_mem_12914, struct memblock_device exp_res_mem_12915, int64_t m_10188)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device mem_12996;
    
    mem_12996.references = NULL;
    
    struct memblock_device mem_12993;
    
    mem_12993.references = NULL;
    
    struct memblock_device mem_12990;
    
    mem_12990.references = NULL;
    
    struct memblock_device mem_12936;
    
    mem_12936.references = NULL;
    
    struct memblock_device mem_12933;
    
    mem_12933.references = NULL;
    
    struct memblock_device mem_12930;
    
    mem_12930.references = NULL;
    
    struct memblock_device incprefixes_mem_13264;
    
    incprefixes_mem_13264.references = NULL;
    
    struct memblock_device aggregates_mem_13262;
    
    aggregates_mem_13262.references = NULL;
    
    struct memblock_device status_flags_mem_13260;
    
    status_flags_mem_13260.references = NULL;
    
    struct memblock_device mem_12986;
    
    mem_12986.references = NULL;
    
    struct memblock_device mem_12983;
    
    mem_12983.references = NULL;
    
    struct memblock_device mem_12980;
    
    mem_12980.references = NULL;
    
    struct memblock_device incprefixes_mem_13109;
    
    incprefixes_mem_13109.references = NULL;
    
    struct memblock_device aggregates_mem_13107;
    
    aggregates_mem_13107.references = NULL;
    
    struct memblock_device status_flags_mem_13105;
    
    status_flags_mem_13105.references = NULL;
    
    struct memblock_device mem_12976;
    
    mem_12976.references = NULL;
    
    struct memblock_device mem_12973;
    
    mem_12973.references = NULL;
    
    struct memblock_device mem_12969;
    
    mem_12969.references = NULL;
    
    struct memblock_device mem_12963;
    
    mem_12963.references = NULL;
    
    struct memblock_device mem_12960;
    
    mem_12960.references = NULL;
    
    struct memblock_device mem_12957;
    
    mem_12957.references = NULL;
    
    struct memblock_device mem_12954;
    
    mem_12954.references = NULL;
    
    struct memblock_device mem_12951;
    
    mem_12951.references = NULL;
    
    struct memblock_device mem_12948;
    
    mem_12948.references = NULL;
    
    struct memblock_device mem_12945;
    
    mem_12945.references = NULL;
    
    struct memblock_device mem_12942;
    
    mem_12942.references = NULL;
    
    struct memblock_device mem_12938;
    
    mem_12938.references = NULL;
    
    struct memblock_device mem_12927;
    
    mem_12927.references = NULL;
    
    struct memblock_device mem_12924;
    
    mem_12924.references = NULL;
    
    struct memblock_device mem_12921;
    
    mem_12921.references = NULL;
    
    struct memblock_device mem_12918;
    
    mem_12918.references = NULL;
    
    struct memblock_device mem_out_13003;
    
    mem_out_13003.references = NULL;
    
    struct memblock_device mem_out_13002;
    
    mem_out_13002.references = NULL;
    
    struct memblock_device mem_out_13001;
    
    mem_out_13001.references = NULL;
    
    struct memblock_device counters_mem_13188 = ctx->constants->counters_mem_13188;
    struct memblock_device counters_mem_13253 = ctx->constants->counters_mem_13253;
    struct memblock_device id_counter_mem_13014 = ctx->constants->id_counter_mem_13014;
    struct memblock_device id_counter_mem_13017 = ctx->constants->id_counter_mem_13017;
    struct memblock_device id_counter_mem_13080 = ctx->constants->id_counter_mem_13080;
    struct memblock_device id_counter_mem_13083 = ctx->constants->id_counter_mem_13083;
    struct memblock_device id_counter_mem_13202 = ctx->constants->id_counter_mem_13202;
    struct memblock_device id_counter_mem_13258 = ctx->constants->id_counter_mem_13258;
    int64_t prim_out_13004;
    int64_t n_10772 = sdiv64(m_10188, (int64_t) 4);
    int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10773 = mul64((int64_t) 4, n_10772);
    bool dim_match_10774 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773 == m_10188;
    bool empty_or_match_cert_10775;
    
    if (!dim_match_10774) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Value of (core language) shape (", (long long) m_10188, ") cannot match shape of type `[", (long long) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, "]u64`.", "-> #0  big-arith-valid.fut:19:37-51\n   #1  big-arith-valid.fut:17:1-20:91\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t dzlz7bUZLztZRz20U2z20Unz7dUzg_11183 = mul64((int64_t) 2, n_10772);
    int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184 = add64(dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183);
    int64_t dzlz7bUZLzmZRz20UZLZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRZRz20U2z7dUzg_11185 = sub64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184, (int64_t) 2);
    bool bounds_invalid_upwards_11186 = slt64(n_10772, (int64_t) 0);
    bool valid_11187 = !bounds_invalid_upwards_11186;
    bool range_valid_c_11188;
    
    if (!valid_11187) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) n_10772, " is invalid.", "-> #0  /prelude/array.fut:82:3-11\n   #1  big-arith-valid.fut:17:1-20:91\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int32_t i64_res_11190 = sext_i64_i32(n_10772);
    bool y_11191 = slt64((int64_t) 0, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);
    bool index_certs_11192;
    
    if (!y_11191) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 0, "] out of bounds for array of shape [", (long long) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, "].", "-> #0  big-arith-fut/bigmul.fut:46:40-46\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:17:1-20:91\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int32_t zm_lhs_11194 = mul32(4, i64_res_11190);
    int64_t segmap_group_sizze_12624;
    
    segmap_group_sizze_12624 = *ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12453;
    
    int64_t segmap_usable_groups_12625 = sdiv_up64(n_10772, segmap_group_sizze_12624);
    int64_t binop_y_12916 = (int64_t) 16 * n_10772;
    int64_t bytes_12917 = smax64((int64_t) 0, binop_y_12916);
    
    if (memblock_alloc_device(ctx, &mem_12918, bytes_12917, "mem_12918")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_12918, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t w_minus_1_11403 = sub64(n_10772, (int64_t) 1);
    
    if (memblock_alloc_device(ctx, &mem_12921, bytes_12917, "mem_12921")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_12921, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12924, bytes_12917, "mem_12924")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_12924, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12927, bytes_12917, "mem_12927")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_12927, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_group_sizze_12805;
    
    segmap_group_sizze_12805 = *ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12804;
    
    int64_t segmap_usable_groups_12806 = sdiv_up64(n_10772, segmap_group_sizze_12805);
    int64_t segmap_group_sizze_12811;
    
    segmap_group_sizze_12811 = *ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12810;
    
    int64_t segmap_usable_groups_12812 = sdiv_up64(n_10772, segmap_group_sizze_12811);
    bool dim_match_11428 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773 == dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184;
    bool empty_or_match_cert_11429;
    
    if (!dim_match_11428) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Value of (core language) shape (", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184, ") cannot match shape of type `[", (long long) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, "]u64`.", "-> #0  big-arith-fut/bigmul.fut:71:11-87\n   #1  big-arith-valid.fut:17:1-20:91\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t segmap_group_sizze_12830;
    
    segmap_group_sizze_12830 = *ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12816;
    
    int64_t segmap_usable_groups_12831 = sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184, segmap_group_sizze_12830);
    bool empty_slice_11486 = dzlz7bUZLzmZRz20UZLZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRZRz20U2z7dUzg_11185 == (int64_t) 0;
    int64_t m_11487 = sub64(dzlz7bUZLzmZRz20UZLZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRZRz20U2z7dUzg_11185, (int64_t) 1);
    int64_t i_p_m_t_s_11488 = add64((int64_t) 2, m_11487);
    bool zzero_leq_i_p_m_t_s_11489 = sle64((int64_t) 0, i_p_m_t_s_11488);
    bool i_p_m_t_s_leq_w_11490 = slt64(i_p_m_t_s_11488, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184);
    bool i_lte_j_11491 = sle64((int64_t) 2, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184);
    bool y_11492 = zzero_leq_i_p_m_t_s_11489 && i_p_m_t_s_leq_w_11490;
    bool forwards_ok_11493 = i_lte_j_11491 && y_11492;
    bool ok_or_empty_11494 = empty_slice_11486 || forwards_ok_11493;
    bool index_certs_11495;
    
    if (!ok_or_empty_11494) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 2, ":] out of bounds for array of shape [", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184, "].", "-> #0  /prelude/array.fut:46:46-51\n   #1  big-arith-fut/bigmul.fut:74:14-18\n   #2  /prelude/functional.fut:9:44-45\n   #3  big-arith-fut/bigmul.fut:74:14-20\n   #4  big-arith-valid.fut:17:1-20:91\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t segscan_group_sizze_12845;
    
    segscan_group_sizze_12845 = *ctx->tuning_params.big_mul_debugzisegscan_group_sizze_12844;
    
    int64_t num_groups_12847;
    int32_t max_num_groups_13025;
    
    max_num_groups_13025 = *ctx->tuning_params.big_mul_debugzisegscan_num_groups_12846;
    num_groups_12847 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, segscan_group_sizze_12845), sext_i32_i64(max_num_groups_13025))));
    
    int64_t segscan_group_sizze_12853;
    
    segscan_group_sizze_12853 = *ctx->tuning_params.big_mul_debugzisegscan_group_sizze_12852;
    
    int64_t num_groups_12855;
    int32_t max_num_groups_13026;
    
    max_num_groups_13026 = *ctx->tuning_params.big_mul_debugzisegscan_num_groups_12854;
    num_groups_12855 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, segscan_group_sizze_12853), sext_i32_i64(max_num_groups_13026))));
    
    int64_t last_index_10799 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773 - (int64_t) 1;
    bool is_empty_10800 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10773 == (int64_t) 0;
    bool x_10801 = !is_empty_10800;
    int64_t binop_y_12928 = (int64_t) 32 * n_10772;
    int64_t bytes_12929 = smax64((int64_t) 0, binop_y_12928);
    
    if (memblock_alloc_device(ctx, &mem_12938, (int64_t) 8, "mem_12938")) {
        err = 1;
        goto cleanup;
    }
    {
        err = gpu_kernel_big_mul_debugzigpuseq_13027(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, bs_mem_12914.mem, mem_12938.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    
    int64_t binop_y_12940 = (int64_t) 8 * n_10772;
    int64_t bytes_12941 = smax64((int64_t) 0, binop_y_12940);
    
    if (memblock_alloc_device(ctx, &mem_12942, bytes_12941, "mem_12942")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12945, bytes_12941, "mem_12945")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12948, bytes_12941, "mem_12948")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12951, bytes_12941, "mem_12951")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12954, bytes_12941, "mem_12954")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12957, bytes_12941, "mem_12957")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12960, bytes_12941, "mem_12960")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12963, bytes_12941, "mem_12963")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_13033 = sext_i64_i32(sdiv_up64(n_10772, segmap_group_sizze_12624));
    
    {
        err = gpu_kernel_big_mul_debugzisegmap_12635(ctx, segmap_usable_groups_12625, 1, 1, *ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12453, 1, 1, (int64_t) 0, n_10772, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, zm_lhs_11194, as_mem_12913.mem, bs_mem_12914.mem, mem_12938.mem, mem_12942.mem, mem_12945.mem, mem_12948.mem, mem_12951.mem, mem_12954.mem, mem_12957.mem, mem_12960.mem, mem_12963.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    ctx->failure_is_an_option = 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_12938, "mem_12938") != 0)
        return 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_13054 = sext_i64_i32(sdiv_up64(n_10772, segmap_group_sizze_12805));
    
    {
        err = gpu_kernel_big_mul_debugzisegmap_12802(ctx, segmap_usable_groups_12806, 1, 1, *ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12804, 1, 1, (int64_t) 0, n_10772, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, w_minus_1_11403, mem_12918.mem, mem_12921.mem, mem_12924.mem, mem_12927.mem, mem_12942.mem, mem_12948.mem, mem_12954.mem, mem_12960.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_12942, "mem_12942") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12948, "mem_12948") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12954, "mem_12954") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12960, "mem_12960") != 0)
        return 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_13063 = sext_i64_i32(sdiv_up64(n_10772, segmap_group_sizze_12811));
    
    {
        err = gpu_kernel_big_mul_debugzisegmap_12808(ctx, segmap_usable_groups_12812, 1, 1, *ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12810, 1, 1, (int64_t) 0, n_10772, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, w_minus_1_11403, mem_12918.mem, mem_12921.mem, mem_12924.mem, mem_12927.mem, mem_12945.mem, mem_12951.mem, mem_12957.mem, mem_12963.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_12945, "mem_12945") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12951, "mem_12951") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12957, "mem_12957") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12963, "mem_12963") != 0)
        return 1;
    
    int64_t binop_y_12967 = (int64_t) 8 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184;
    int64_t bytes_12968 = smax64((int64_t) 0, binop_y_12967);
    
    if (memblock_alloc_device(ctx, &mem_12969, bytes_12968, "mem_12969")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_13072 = sext_i64_i32(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184, segmap_group_sizze_12830));
    
    {
        err = gpu_kernel_big_mul_debugzisegmap_12834(ctx, segmap_usable_groups_12831, 1, 1, *ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12816, 1, 1, (int64_t) 0, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184, mem_12918.mem, mem_12921.mem, mem_12969.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_12918, "mem_12918") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12921, "mem_12921") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_12973, bytes_12917, "mem_12973")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12976, bytes_12929, "mem_12976")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t num_groups_13081 = sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, segscan_group_sizze_12845 * (int64_t) 23);
        int64_t num_threads_13082 = num_groups_13081 * segscan_group_sizze_12845;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (m) ", (long long) 23, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory constraint", (long long) 23, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Register constraint", (long long) 31, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "sumT'", (long long) 1, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_13105, num_groups_13081, "status_flags_mem_13105")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_13107, (int64_t) 4 * num_groups_13081, "aggregates_mem_13107")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_13109, (int64_t) 4 * num_groups_13081, "incprefixes_mem_13109")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_13105, num_groups_13081, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_big_mul_debugzisegscan_12850(ctx, num_groups_13081, 1, 1, *ctx->tuning_params.big_mul_debugzisegscan_group_sizze_12844, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_group_sizze_12845), (int64_t) 23 * segscan_group_sizze_12845 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_group_sizze_12845), (int64_t) 23 * segscan_group_sizze_12845 * (int64_t) 4), (int64_t) 8), (int64_t) 8), (int64_t) 0, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, num_groups_13081, mem_12924.mem, mem_12927.mem, mem_12969.mem, mem_12973.mem, mem_12976.mem, id_counter_mem_13083.mem, status_flags_mem_13105.mem, aggregates_mem_13107.mem, incprefixes_mem_13109.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_12924, "mem_12924") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12927, "mem_12927") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12969, "mem_12969") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_12980, bytes_12929, "mem_12980")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12983, bytes_12929, "mem_12983")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12986, bytes_12929, "mem_12986")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t num_groups_13256 = sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, segscan_group_sizze_12853 * (int64_t) 11);
        int64_t num_threads_13257 = num_groups_13256 * segscan_group_sizze_12853;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (m) ", (long long) 11, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory constraint", (long long) 11, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Register constraint", (long long) 15, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "sumT'", (long long) 2, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_13260, num_groups_13256, "status_flags_mem_13260")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_13262, (int64_t) 8 * num_groups_13256, "aggregates_mem_13262")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_13264, (int64_t) 8 * num_groups_13256, "incprefixes_mem_13264")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_13260, num_groups_13256, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_big_mul_debugzisegscan_12858(ctx, num_groups_13256, 1, 1, *ctx->tuning_params.big_mul_debugzisegscan_group_sizze_12852, 1, 1, smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_group_sizze_12853), (int64_t) 11 * segscan_group_sizze_12853 * (int64_t) 8) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 288, (int64_t) 8 * segscan_group_sizze_12853), (int64_t) 11 * segscan_group_sizze_12853 * (int64_t) 8), (int64_t) 8), (int64_t) 8), (int64_t) 0, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, num_groups_13256, exp_res_mem_12915.mem, mem_12973.mem, mem_12976.mem, mem_12980.mem, mem_12983.mem, mem_12986.mem, id_counter_mem_13258.mem, status_flags_mem_13260.mem, aggregates_mem_13262.mem, incprefixes_mem_13264.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        ctx->failure_is_an_option = 1;
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_12973, "mem_12973") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12976, "mem_12976") != 0)
        return 1;
    
    int64_t last_offset_10802;
    
    if (x_10801 == 1) {
        int64_t read_res_13369;
        
        if ((err = gpu_scalar_from_device(ctx, &read_res_13369, mem_12980.mem, last_index_10799 * sizeof(int64_t), sizeof(int64_t))) != 0)
            goto cleanup;
        if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
            err = 1;
            goto cleanup;
        }
        
        int64_t x_11757 = read_res_13369;
        
        last_offset_10802 = x_11757;
    } else {
        last_offset_10802 = (int64_t) 0;
    }
    
    int64_t partition_sizze_10804;
    
    if (is_empty_10800 == 1) {
        partition_sizze_10804 = (int64_t) 0;
    } else {
        partition_sizze_10804 = last_offset_10802;
    }
    
    bool eq_x_zz_10819 = (int64_t) 0 == last_offset_10802;
    bool p_and_eq_x_y_10820 = x_10801 && eq_x_zz_10819;
    bool empty_slice_10821 = is_empty_10800 || p_and_eq_x_y_10820;
    int64_t m_10822 = sub64(partition_sizze_10804, (int64_t) 1);
    bool zzero_leq_i_p_m_t_s_10823 = sle64((int64_t) 0, m_10822);
    bool i_p_m_t_s_leq_w_10824 = slt64(m_10822, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773);
    bool i_lte_j_10825 = sle64((int64_t) 0, partition_sizze_10804);
    bool y_10826 = zzero_leq_i_p_m_t_s_10823 && i_p_m_t_s_leq_w_10824;
    bool forwards_ok_10827 = i_lte_j_10825 && y_10826;
    bool ok_or_empty_10828 = empty_slice_10821 || forwards_ok_10827;
    bool index_certs_10829;
    
    if (!ok_or_empty_10828) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [:", (long long) partition_sizze_10804, "] out of bounds for array of shape [", (long long) dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, "].", "-> #0  /prelude/soacs.fut:173:6-17\n   #1  big-arith-valid.fut:20:39-80\n   #2  big-arith-valid.fut:17:1-20:91\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t binop_y_12988 = (int64_t) 8 * partition_sizze_10804;
    int64_t bytes_12989 = smax64((int64_t) 0, binop_y_12988);
    
    if (memblock_alloc_device(ctx, &mem_12930, bytes_12929, "mem_12930")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12933, bytes_12929, "mem_12933")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12936, bytes_12929, "mem_12936")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_group_sizze_12863;
    
    segmap_group_sizze_12863 = *ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12862;
    
    int64_t segmap_usable_groups_12864 = sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, segmap_group_sizze_12863);
    
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_13349 = sext_i64_i32(sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, segmap_group_sizze_12863));
    
    {
        err = gpu_kernel_big_mul_debugzisegmap_12860(ctx, segmap_usable_groups_12864, 1, 1, *ctx->tuning_params.big_mul_debugzisegmap_group_sizze_12862, 1, 1, (int64_t) 0, dzlz7bUZLztZRz20U4z20Unz7dUzg_10773, exp_res_mem_12915.mem, mem_12930.mem, mem_12933.mem, mem_12936.mem, mem_12980.mem, mem_12983.mem, mem_12986.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_12980, "mem_12980") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12983, "mem_12983") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12986, "mem_12986") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_12990, bytes_12989, "mem_12990")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_12990.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_12930.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {partition_sizze_10804})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &mem_12930, "mem_12930") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_12993, bytes_12989, "mem_12993")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_12993.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_12933.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {partition_sizze_10804})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &mem_12933, "mem_12933") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_12996, bytes_12989, "mem_12996")) {
        err = 1;
        goto cleanup;
    }
    if ((err = lmad_copy_gpu2gpu_8b(ctx, 1, mem_12996.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, mem_12936.mem, (int64_t) 0, (int64_t []) {(int64_t) 1}, (int64_t []) {partition_sizze_10804})) != 0)
        goto cleanup;
    if (memblock_unref_device(ctx, &mem_12936, "mem_12936") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_13001, &mem_12990, "mem_12990") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_13002, &mem_12993, "mem_12993") != 0)
        return 1;
    if (memblock_set_device(ctx, &mem_out_13003, &mem_12996, "mem_12996") != 0)
        return 1;
    prim_out_13004 = partition_sizze_10804;
    if (memblock_set_device(ctx, &*mem_out_p_13365, &mem_out_13001, "mem_out_13001") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_13366, &mem_out_13002, "mem_out_13002") != 0)
        return 1;
    if (memblock_set_device(ctx, &*mem_out_p_13367, &mem_out_13003, "mem_out_13003") != 0)
        return 1;
    *out_prim_out_13368 = prim_out_13004;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &mem_12996, "mem_12996") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12993, "mem_12993") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12990, "mem_12990") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12936, "mem_12936") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12933, "mem_12933") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12930, "mem_12930") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_13264, "incprefixes_mem_13264") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_13262, "aggregates_mem_13262") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_13260, "status_flags_mem_13260") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12986, "mem_12986") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12983, "mem_12983") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12980, "mem_12980") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_13109, "incprefixes_mem_13109") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_13107, "aggregates_mem_13107") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_13105, "status_flags_mem_13105") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12976, "mem_12976") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12973, "mem_12973") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12969, "mem_12969") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12963, "mem_12963") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12960, "mem_12960") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12957, "mem_12957") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12954, "mem_12954") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12951, "mem_12951") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12948, "mem_12948") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12945, "mem_12945") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12942, "mem_12942") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12938, "mem_12938") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12927, "mem_12927") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12924, "mem_12924") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12921, "mem_12921") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12918, "mem_12918") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_13003, "mem_out_13003") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_13002, "mem_out_13002") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_out_13001, "mem_out_13001") != 0)
            return 1;
    }
    return err;
}
FUTHARK_FUN_ATTR int futrts_entry_big_mul_validation(struct futhark_context *ctx, bool *out_prim_out_13370, struct memblock_device as_mem_12913, struct memblock_device bs_mem_12914, struct memblock_device exp_res_mem_12915, int64_t m_9987)
{
    (void) ctx;
    
    int err = 0;
    struct memblock_device segred_tmp_mem_13255;
    
    segred_tmp_mem_13255.references = NULL;
    
    struct memblock_device mem_12970;
    
    mem_12970.references = NULL;
    
    struct memblock_device incprefixes_mem_13106;
    
    incprefixes_mem_13106.references = NULL;
    
    struct memblock_device aggregates_mem_13104;
    
    aggregates_mem_13104.references = NULL;
    
    struct memblock_device status_flags_mem_13102;
    
    status_flags_mem_13102.references = NULL;
    
    struct memblock_device mem_12967;
    
    mem_12967.references = NULL;
    
    struct memblock_device mem_12964;
    
    mem_12964.references = NULL;
    
    struct memblock_device mem_12960;
    
    mem_12960.references = NULL;
    
    struct memblock_device mem_12954;
    
    mem_12954.references = NULL;
    
    struct memblock_device mem_12951;
    
    mem_12951.references = NULL;
    
    struct memblock_device mem_12948;
    
    mem_12948.references = NULL;
    
    struct memblock_device mem_12945;
    
    mem_12945.references = NULL;
    
    struct memblock_device mem_12942;
    
    mem_12942.references = NULL;
    
    struct memblock_device mem_12939;
    
    mem_12939.references = NULL;
    
    struct memblock_device mem_12936;
    
    mem_12936.references = NULL;
    
    struct memblock_device mem_12933;
    
    mem_12933.references = NULL;
    
    struct memblock_device mem_12929;
    
    mem_12929.references = NULL;
    
    struct memblock_device mem_12927;
    
    mem_12927.references = NULL;
    
    struct memblock_device mem_12924;
    
    mem_12924.references = NULL;
    
    struct memblock_device mem_12921;
    
    mem_12921.references = NULL;
    
    struct memblock_device mem_12918;
    
    mem_12918.references = NULL;
    
    struct memblock_device counters_mem_13188 = ctx->constants->counters_mem_13188;
    struct memblock_device counters_mem_13253 = ctx->constants->counters_mem_13253;
    struct memblock_device id_counter_mem_13014 = ctx->constants->id_counter_mem_13014;
    struct memblock_device id_counter_mem_13017 = ctx->constants->id_counter_mem_13017;
    struct memblock_device id_counter_mem_13080 = ctx->constants->id_counter_mem_13080;
    struct memblock_device id_counter_mem_13083 = ctx->constants->id_counter_mem_13083;
    struct memblock_device id_counter_mem_13202 = ctx->constants->id_counter_mem_13202;
    struct memblock_device id_counter_mem_13258 = ctx->constants->id_counter_mem_13258;
    bool prim_out_13001;
    int64_t n_10211 = sdiv64(m_9987, (int64_t) 4);
    int64_t dzlz7bUZLztZRz20U4z20Unz7dUzg_10212 = mul64((int64_t) 4, n_10211);
    bool dim_match_10213 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10212 == m_9987;
    bool empty_or_match_cert_10214;
    
    if (!dim_match_10213) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Value of (core language) shape (", (long long) m_9987, ") cannot match shape of type `[", (long long) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, "]u64`.", "-> #0  big-arith-valid.fut:15:32-46\n   #1  big-arith-valid.fut:13:1-15:72\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t dzlz7bUZLztZRz20U2z20Unz7dUzg_11183 = mul64((int64_t) 2, n_10211);
    int64_t dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184 = add64(dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183);
    int64_t dzlz7bUZLzmZRz20UZLZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRZRz20U2z7dUzg_11185 = sub64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184, (int64_t) 2);
    bool bounds_invalid_upwards_11186 = slt64(n_10211, (int64_t) 0);
    bool valid_11187 = !bounds_invalid_upwards_11186;
    bool range_valid_c_11188;
    
    if (!valid_11187) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s%lld%s\n\nBacktrace:\n%s", "Range ", (long long) (int64_t) 0, "..", (long long) (int64_t) 1, "..<", (long long) n_10211, " is invalid.", "-> #0  /prelude/array.fut:82:3-11\n   #1  big-arith-valid.fut:15:8-46\n   #2  big-arith-valid.fut:13:1-15:72\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool y_11191 = slt64((int64_t) 0, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212);
    bool index_certs_11192;
    
    if (!y_11191) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 0, "] out of bounds for array of shape [", (long long) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, "].", "-> #0  big-arith-fut/bigmul.fut:46:40-46\n   #1  big-arith-fut/bigmul.fut:68:31-74\n   #2  big-arith-fut/bigmul.fut:68:78-84\n   #3  big-arith-valid.fut:15:8-46\n   #4  big-arith-valid.fut:13:1-15:72\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t binop_y_12916 = (int64_t) 16 * n_10211;
    int64_t bytes_12917 = smax64((int64_t) 0, binop_y_12916);
    bool dim_match_11428 = dzlz7bUZLztZRz20U4z20Unz7dUzg_10212 == dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184;
    bool empty_or_match_cert_11429;
    
    if (!dim_match_11428) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Value of (core language) shape (", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184, ") cannot match shape of type `[", (long long) dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, "]u64`.", "-> #0  big-arith-fut/bigmul.fut:71:11-87\n   #1  big-arith-valid.fut:15:8-46\n   #2  big-arith-valid.fut:13:1-15:72\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    bool empty_slice_11486 = dzlz7bUZLzmZRz20UZLZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRZRz20U2z7dUzg_11185 == (int64_t) 0;
    int64_t m_11487 = sub64(dzlz7bUZLzmZRz20UZLZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRZRz20U2z7dUzg_11185, (int64_t) 1);
    int64_t i_p_m_t_s_11488 = add64((int64_t) 2, m_11487);
    bool zzero_leq_i_p_m_t_s_11489 = sle64((int64_t) 0, i_p_m_t_s_11488);
    bool i_p_m_t_s_leq_w_11490 = slt64(i_p_m_t_s_11488, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184);
    bool i_lte_j_11491 = sle64((int64_t) 2, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184);
    bool y_11492 = zzero_leq_i_p_m_t_s_11489 && i_p_m_t_s_leq_w_11490;
    bool forwards_ok_11493 = i_lte_j_11491 && y_11492;
    bool ok_or_empty_11494 = empty_slice_11486 || forwards_ok_11493;
    bool index_certs_11495;
    
    if (!ok_or_empty_11494) {
        set_error(ctx, msgprintf("Error: %s%lld%s%lld%s\n\nBacktrace:\n%s", "Index [", (long long) (int64_t) 2, ":] out of bounds for array of shape [", (long long) dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184, "].", "-> #0  /prelude/array.fut:46:46-51\n   #1  big-arith-fut/bigmul.fut:74:14-18\n   #2  /prelude/functional.fut:9:44-45\n   #3  big-arith-fut/bigmul.fut:74:14-20\n   #4  big-arith-valid.fut:15:8-46\n   #5  big-arith-valid.fut:13:1-15:72\n"));
        err = FUTHARK_PROGRAM_ERROR;
        goto cleanup;
    }
    
    int64_t binop_y_12931 = (int64_t) 8 * n_10211;
    int64_t bytes_12932 = smax64((int64_t) 0, binop_y_12931);
    int64_t binop_y_12958 = (int64_t) 8 * dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184;
    int64_t bytes_12959 = smax64((int64_t) 0, binop_y_12958);
    int64_t binop_y_12965 = (int64_t) 32 * n_10211;
    int64_t bytes_12966 = smax64((int64_t) 0, binop_y_12965);
    int32_t i64_res_11190 = sext_i64_i32(n_10211);
    int32_t zm_lhs_11194 = mul32(4, i64_res_11190);
    int64_t segmap_group_sizze_12062;
    
    segmap_group_sizze_12062 = *ctx->tuning_params.big_mul_validationzisegmap_group_sizze_11891;
    
    int64_t segmap_usable_groups_12063 = sdiv_up64(n_10211, segmap_group_sizze_12062);
    
    if (memblock_alloc_device(ctx, &mem_12918, bytes_12917, "mem_12918")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_12918, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t w_minus_1_11403 = sub64(n_10211, (int64_t) 1);
    
    if (memblock_alloc_device(ctx, &mem_12921, bytes_12917, "mem_12921")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_12921, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12924, bytes_12917, "mem_12924")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_12924, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12927, bytes_12917, "mem_12927")) {
        err = 1;
        goto cleanup;
    }
    if (futrts_builtinzhreplicate_i64(ctx, mem_12927, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, (int64_t) 0) != 0) {
        err = 1;
        goto cleanup;
    }
    
    int64_t segmap_group_sizze_12243;
    
    segmap_group_sizze_12243 = *ctx->tuning_params.big_mul_validationzisegmap_group_sizze_12242;
    
    int64_t segmap_usable_groups_12244 = sdiv_up64(n_10211, segmap_group_sizze_12243);
    int64_t segmap_group_sizze_12249;
    
    segmap_group_sizze_12249 = *ctx->tuning_params.big_mul_validationzisegmap_group_sizze_12248;
    
    int64_t segmap_usable_groups_12250 = sdiv_up64(n_10211, segmap_group_sizze_12249);
    int64_t segmap_group_sizze_12268;
    
    segmap_group_sizze_12268 = *ctx->tuning_params.big_mul_validationzisegmap_group_sizze_12254;
    
    int64_t segmap_usable_groups_12269 = sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184, segmap_group_sizze_12268);
    int64_t segscan_group_sizze_12283;
    
    segscan_group_sizze_12283 = *ctx->tuning_params.big_mul_validationzisegscan_group_sizze_12282;
    
    int64_t num_groups_12285;
    int32_t max_num_groups_13022;
    
    max_num_groups_13022 = *ctx->tuning_params.big_mul_validationzisegscan_num_groups_12284;
    num_groups_12285 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, segscan_group_sizze_12283), sext_i32_i64(max_num_groups_13022))));
    
    int64_t segred_group_sizze_12291;
    
    segred_group_sizze_12291 = *ctx->tuning_params.big_mul_validationzisegred_group_sizze_12290;
    
    int64_t num_groups_12293;
    int32_t max_num_groups_13023;
    
    max_num_groups_13023 = *ctx->tuning_params.big_mul_validationzisegred_num_groups_12292;
    num_groups_12293 = sext_i64_i32(smax64((int64_t) 1, smin64(sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, segred_group_sizze_12291), sext_i32_i64(max_num_groups_13023))));
    if (memblock_alloc_device(ctx, &mem_12929, (int64_t) 8, "mem_12929")) {
        err = 1;
        goto cleanup;
    }
    {
        err = gpu_kernel_big_mul_validationzigpuseq_13024(ctx, (int64_t) 1, 1, 1, (int64_t) 1, 1, 1, (int64_t) 0, bs_mem_12914.mem, mem_12929.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12933, bytes_12932, "mem_12933")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12936, bytes_12932, "mem_12936")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12939, bytes_12932, "mem_12939")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12942, bytes_12932, "mem_12942")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12945, bytes_12932, "mem_12945")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12948, bytes_12932, "mem_12948")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12951, bytes_12932, "mem_12951")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12954, bytes_12932, "mem_12954")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_13030 = sext_i64_i32(sdiv_up64(n_10211, segmap_group_sizze_12062));
    
    {
        err = gpu_kernel_big_mul_validationzisegmap_12073(ctx, segmap_usable_groups_12063, 1, 1, *ctx->tuning_params.big_mul_validationzisegmap_group_sizze_11891, 1, 1, (int64_t) 0, n_10211, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, zm_lhs_11194, as_mem_12913.mem, bs_mem_12914.mem, mem_12929.mem, mem_12933.mem, mem_12936.mem, mem_12939.mem, mem_12942.mem, mem_12945.mem, mem_12948.mem, mem_12951.mem, mem_12954.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    ctx->failure_is_an_option = 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_12929, "mem_12929") != 0)
        return 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_13051 = sext_i64_i32(sdiv_up64(n_10211, segmap_group_sizze_12243));
    
    {
        err = gpu_kernel_big_mul_validationzisegmap_12240(ctx, segmap_usable_groups_12244, 1, 1, *ctx->tuning_params.big_mul_validationzisegmap_group_sizze_12242, 1, 1, (int64_t) 0, n_10211, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, w_minus_1_11403, mem_12918.mem, mem_12921.mem, mem_12924.mem, mem_12927.mem, mem_12933.mem, mem_12939.mem, mem_12945.mem, mem_12951.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_12933, "mem_12933") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12939, "mem_12939") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12945, "mem_12945") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12951, "mem_12951") != 0)
        return 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_13060 = sext_i64_i32(sdiv_up64(n_10211, segmap_group_sizze_12249));
    
    {
        err = gpu_kernel_big_mul_validationzisegmap_12246(ctx, segmap_usable_groups_12250, 1, 1, *ctx->tuning_params.big_mul_validationzisegmap_group_sizze_12248, 1, 1, (int64_t) 0, n_10211, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, w_minus_1_11403, mem_12918.mem, mem_12921.mem, mem_12924.mem, mem_12927.mem, mem_12936.mem, mem_12942.mem, mem_12948.mem, mem_12954.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_12936, "mem_12936") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12942, "mem_12942") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12948, "mem_12948") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12954, "mem_12954") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_12960, bytes_12959, "mem_12960")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegMap");
    
    int32_t virt_num_groups_13069 = sext_i64_i32(sdiv_up64(dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184, segmap_group_sizze_12268));
    
    {
        err = gpu_kernel_big_mul_validationzisegmap_12272(ctx, segmap_usable_groups_12269, 1, 1, *ctx->tuning_params.big_mul_validationzisegmap_group_sizze_12254, 1, 1, (int64_t) 0, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, dzlz7bUZLzpZRz20UZLZLztZRz20U2z20UnZRz20UZLZLztZRz20U2z20UnZRz7dUzg_11184, mem_12918.mem, mem_12921.mem, mem_12960.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_12918, "mem_12918") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12921, "mem_12921") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_12964, bytes_12917, "mem_12964")) {
        err = 1;
        goto cleanup;
    }
    if (memblock_alloc_device(ctx, &mem_12967, bytes_12966, "mem_12967")) {
        err = 1;
        goto cleanup;
    }
    if (slt64((int64_t) 0, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212)) {
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "\n# SegScan");
        
        int64_t num_groups_13078 = sdiv_up64(dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, segscan_group_sizze_12283 * (int64_t) 23);
        int64_t num_threads_13079 = num_groups_13078 * segscan_group_sizze_12283;
        
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Sequential elements per thread (m) ", (long long) 23, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Memory constraint", (long long) 23, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "Register constraint", (long long) 31, '\n');
        if (ctx->debugging)
            fprintf(ctx->log, "%s: %llu%c", "sumT'", (long long) 1, '\n');
        if (memblock_alloc_device(ctx, &status_flags_mem_13102, num_groups_13078, "status_flags_mem_13102")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &aggregates_mem_13104, (int64_t) 4 * num_groups_13078, "aggregates_mem_13104")) {
            err = 1;
            goto cleanup;
        }
        if (memblock_alloc_device(ctx, &incprefixes_mem_13106, (int64_t) 4 * num_groups_13078, "incprefixes_mem_13106")) {
            err = 1;
            goto cleanup;
        }
        if (futrts_builtinzhreplicate_i8(ctx, status_flags_mem_13102, num_groups_13078, (int8_t) 0) != 0) {
            err = 1;
            goto cleanup;
        }
        {
            err = gpu_kernel_big_mul_validationzisegscan_12288(ctx, num_groups_13078, 1, 1, *ctx->tuning_params.big_mul_validationzisegscan_group_sizze_12282, 1, 1, smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_group_sizze_12283), (int64_t) 23 * segscan_group_sizze_12283 * (int64_t) 4) + srem64((int64_t) 8 - srem64(smax64(smax64((int64_t) 160, (int64_t) 4 * segscan_group_sizze_12283), (int64_t) 23 * segscan_group_sizze_12283 * (int64_t) 4), (int64_t) 8), (int64_t) 8), (int64_t) 0, dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, dzlz7bUZLztZRz20U2z20Unz7dUzg_11183, num_groups_13078, mem_12924.mem, mem_12927.mem, mem_12960.mem, mem_12964.mem, mem_12967.mem, id_counter_mem_13080.mem, status_flags_mem_13102.mem, aggregates_mem_13104.mem, incprefixes_mem_13106.mem);
            if (err != FUTHARK_SUCCESS)
                goto cleanup;
        }
        if (ctx->debugging)
            fprintf(ctx->log, "%s\n", "");
    }
    if (memblock_unref_device(ctx, &mem_12924, "mem_12924") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12927, "mem_12927") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12960, "mem_12960") != 0)
        return 1;
    if (memblock_alloc_device(ctx, &mem_12970, (int64_t) 1, "mem_12970")) {
        err = 1;
        goto cleanup;
    }
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "\n# SegRed");
    if (memblock_alloc_device(ctx, &segred_tmp_mem_13255, num_groups_12293, "segred_tmp_mem_13255")) {
        err = 1;
        goto cleanup;
    }
    
    int64_t num_threads_13257 = num_groups_12293 * segred_group_sizze_12291;
    
    {
        err = gpu_kernel_big_mul_validationzisegred_nonseg_12298(ctx, num_groups_12293, 1, 1, *ctx->tuning_params.big_mul_validationzisegred_group_sizze_12290, 1, 1, segred_group_sizze_12291 + srem64((int64_t) 8 - srem64(segred_group_sizze_12291, (int64_t) 8), (int64_t) 8) + 8, (int64_t) 0, segred_group_sizze_12291 + srem64((int64_t) 8 - srem64(segred_group_sizze_12291, (int64_t) 8), (int64_t) 8), dzlz7bUZLztZRz20U4z20Unz7dUzg_10212, num_groups_12293, num_threads_13257, exp_res_mem_12915.mem, mem_12964.mem, mem_12967.mem, mem_12970.mem, counters_mem_13253.mem, segred_tmp_mem_13255.mem);
        if (err != FUTHARK_SUCCESS)
            goto cleanup;
    }
    ctx->failure_is_an_option = 1;
    if (ctx->debugging)
        fprintf(ctx->log, "%s\n", "");
    if (memblock_unref_device(ctx, &mem_12964, "mem_12964") != 0)
        return 1;
    if (memblock_unref_device(ctx, &mem_12967, "mem_12967") != 0)
        return 1;
    
    bool read_res_13371;
    
    if ((err = gpu_scalar_from_device(ctx, &read_res_13371, mem_12970.mem, (int64_t) 0 * sizeof(bool), sizeof(bool))) != 0)
        goto cleanup;
    if (ctx->failure_is_an_option && futhark_context_sync(ctx) != 0) {
        err = 1;
        goto cleanup;
    }
    
    bool all_equal_11762 = read_res_13371;
    
    if (memblock_unref_device(ctx, &mem_12970, "mem_12970") != 0)
        return 1;
    prim_out_13001 = all_equal_11762;
    *out_prim_out_13370 = prim_out_13001;
    
  cleanup:
    {
        if (memblock_unref_device(ctx, &segred_tmp_mem_13255, "segred_tmp_mem_13255") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12970, "mem_12970") != 0)
            return 1;
        if (memblock_unref_device(ctx, &incprefixes_mem_13106, "incprefixes_mem_13106") != 0)
            return 1;
        if (memblock_unref_device(ctx, &aggregates_mem_13104, "aggregates_mem_13104") != 0)
            return 1;
        if (memblock_unref_device(ctx, &status_flags_mem_13102, "status_flags_mem_13102") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12967, "mem_12967") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12964, "mem_12964") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12960, "mem_12960") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12954, "mem_12954") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12951, "mem_12951") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12948, "mem_12948") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12945, "mem_12945") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12942, "mem_12942") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12939, "mem_12939") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12936, "mem_12936") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12933, "mem_12933") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12929, "mem_12929") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12927, "mem_12927") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12924, "mem_12924") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12921, "mem_12921") != 0)
            return 1;
        if (memblock_unref_device(ctx, &mem_12918, "mem_12918") != 0)
            return 1;
    }
    return err;
}

int futhark_entry_big_add_debug(struct futhark_context *ctx, struct futhark_u64_1d **out0, struct futhark_u64_1d **out1, struct futhark_i64_1d **out2, const struct futhark_u64_1d *in0, const struct futhark_u64_1d *in1, const struct futhark_u64_1d *in2)
{
    int64_t m_9060 = (int64_t) 0;
    int64_t prim_out_13004 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_13003;
    
    mem_out_13003.references = NULL;
    
    struct memblock_device mem_out_13002;
    
    mem_out_13002.references = NULL;
    
    struct memblock_device mem_out_13001;
    
    mem_out_13001.references = NULL;
    
    struct memblock_device exp_res_mem_12915;
    
    exp_res_mem_12915.references = NULL;
    
    struct memblock_device bs_mem_12914;
    
    bs_mem_12914.references = NULL;
    
    struct memblock_device as_mem_12913;
    
    as_mem_12913.references = NULL;
    as_mem_12913 = in0->mem;
    m_9060 = in0->shape[0];
    bs_mem_12914 = in1->mem;
    m_9060 = in1->shape[0];
    exp_res_mem_12915 = in2->mem;
    m_9060 = in2->shape[0];
    if (!(m_9060 == in0->shape[0] && (m_9060 == in1->shape[0] && m_9060 == in2->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_big_add_debug(ctx, &mem_out_13001, &mem_out_13002, &mem_out_13003, &prim_out_13004, as_mem_12913, bs_mem_12914, exp_res_mem_12915, m_9060);
        if (ret == 0) {
            struct memblock_device counters_mem_13188 = ctx->constants->counters_mem_13188;
            struct memblock_device counters_mem_13253 = ctx->constants->counters_mem_13253;
            struct memblock_device id_counter_mem_13014 = ctx->constants->id_counter_mem_13014;
            struct memblock_device id_counter_mem_13017 = ctx->constants->id_counter_mem_13017;
            struct memblock_device id_counter_mem_13080 = ctx->constants->id_counter_mem_13080;
            struct memblock_device id_counter_mem_13083 = ctx->constants->id_counter_mem_13083;
            struct memblock_device id_counter_mem_13202 = ctx->constants->id_counter_mem_13202;
            struct memblock_device id_counter_mem_13258 = ctx->constants->id_counter_mem_13258;
            
            assert((*out0 = (struct futhark_u64_1d *) malloc(sizeof(struct futhark_u64_1d))) != NULL);
            (*out0)->mem = mem_out_13001;
            (*out0)->shape[0] = prim_out_13004;
            assert((*out1 = (struct futhark_u64_1d *) malloc(sizeof(struct futhark_u64_1d))) != NULL);
            (*out1)->mem = mem_out_13002;
            (*out1)->shape[0] = prim_out_13004;
            assert((*out2 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out2)->mem = mem_out_13003;
            (*out2)->shape[0] = prim_out_13004;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_big_add_validation(struct futhark_context *ctx, bool *out0, const struct futhark_u64_1d *in0, const struct futhark_u64_1d *in1, const struct futhark_u64_1d *in2)
{
    int64_t m_8724 = (int64_t) 0;
    bool prim_out_13001 = 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device exp_res_mem_12915;
    
    exp_res_mem_12915.references = NULL;
    
    struct memblock_device bs_mem_12914;
    
    bs_mem_12914.references = NULL;
    
    struct memblock_device as_mem_12913;
    
    as_mem_12913.references = NULL;
    as_mem_12913 = in0->mem;
    m_8724 = in0->shape[0];
    bs_mem_12914 = in1->mem;
    m_8724 = in1->shape[0];
    exp_res_mem_12915 = in2->mem;
    m_8724 = in2->shape[0];
    if (!(m_8724 == in0->shape[0] && (m_8724 == in1->shape[0] && m_8724 == in2->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_big_add_validation(ctx, &prim_out_13001, as_mem_12913, bs_mem_12914, exp_res_mem_12915, m_8724);
        if (ret == 0) {
            struct memblock_device counters_mem_13188 = ctx->constants->counters_mem_13188;
            struct memblock_device counters_mem_13253 = ctx->constants->counters_mem_13253;
            struct memblock_device id_counter_mem_13014 = ctx->constants->id_counter_mem_13014;
            struct memblock_device id_counter_mem_13017 = ctx->constants->id_counter_mem_13017;
            struct memblock_device id_counter_mem_13080 = ctx->constants->id_counter_mem_13080;
            struct memblock_device id_counter_mem_13083 = ctx->constants->id_counter_mem_13083;
            struct memblock_device id_counter_mem_13202 = ctx->constants->id_counter_mem_13202;
            struct memblock_device id_counter_mem_13258 = ctx->constants->id_counter_mem_13258;
            
            *out0 = prim_out_13001;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_big_mul_debug(struct futhark_context *ctx, struct futhark_u64_1d **out0, struct futhark_u64_1d **out1, struct futhark_i64_1d **out2, const struct futhark_u64_1d *in0, const struct futhark_u64_1d *in1, const struct futhark_u64_1d *in2)
{
    int64_t m_10188 = (int64_t) 0;
    int64_t prim_out_13004 = (int64_t) 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device mem_out_13003;
    
    mem_out_13003.references = NULL;
    
    struct memblock_device mem_out_13002;
    
    mem_out_13002.references = NULL;
    
    struct memblock_device mem_out_13001;
    
    mem_out_13001.references = NULL;
    
    struct memblock_device exp_res_mem_12915;
    
    exp_res_mem_12915.references = NULL;
    
    struct memblock_device bs_mem_12914;
    
    bs_mem_12914.references = NULL;
    
    struct memblock_device as_mem_12913;
    
    as_mem_12913.references = NULL;
    as_mem_12913 = in0->mem;
    m_10188 = in0->shape[0];
    bs_mem_12914 = in1->mem;
    m_10188 = in1->shape[0];
    exp_res_mem_12915 = in2->mem;
    m_10188 = in2->shape[0];
    if (!(m_10188 == in0->shape[0] && (m_10188 == in1->shape[0] && m_10188 == in2->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_big_mul_debug(ctx, &mem_out_13001, &mem_out_13002, &mem_out_13003, &prim_out_13004, as_mem_12913, bs_mem_12914, exp_res_mem_12915, m_10188);
        if (ret == 0) {
            struct memblock_device counters_mem_13188 = ctx->constants->counters_mem_13188;
            struct memblock_device counters_mem_13253 = ctx->constants->counters_mem_13253;
            struct memblock_device id_counter_mem_13014 = ctx->constants->id_counter_mem_13014;
            struct memblock_device id_counter_mem_13017 = ctx->constants->id_counter_mem_13017;
            struct memblock_device id_counter_mem_13080 = ctx->constants->id_counter_mem_13080;
            struct memblock_device id_counter_mem_13083 = ctx->constants->id_counter_mem_13083;
            struct memblock_device id_counter_mem_13202 = ctx->constants->id_counter_mem_13202;
            struct memblock_device id_counter_mem_13258 = ctx->constants->id_counter_mem_13258;
            
            assert((*out0 = (struct futhark_u64_1d *) malloc(sizeof(struct futhark_u64_1d))) != NULL);
            (*out0)->mem = mem_out_13001;
            (*out0)->shape[0] = prim_out_13004;
            assert((*out1 = (struct futhark_u64_1d *) malloc(sizeof(struct futhark_u64_1d))) != NULL);
            (*out1)->mem = mem_out_13002;
            (*out1)->shape[0] = prim_out_13004;
            assert((*out2 = (struct futhark_i64_1d *) malloc(sizeof(struct futhark_i64_1d))) != NULL);
            (*out2)->mem = mem_out_13003;
            (*out2)->shape[0] = prim_out_13004;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
int futhark_entry_big_mul_validation(struct futhark_context *ctx, bool *out0, const struct futhark_u64_1d *in0, const struct futhark_u64_1d *in1, const struct futhark_u64_1d *in2)
{
    int64_t m_9987 = (int64_t) 0;
    bool prim_out_13001 = 0;
    int ret = 0;
    
    lock_lock(&ctx->lock);
    CUDA_SUCCEED_FATAL(cuCtxPushCurrent(ctx->cu_ctx));
    
    struct memblock_device exp_res_mem_12915;
    
    exp_res_mem_12915.references = NULL;
    
    struct memblock_device bs_mem_12914;
    
    bs_mem_12914.references = NULL;
    
    struct memblock_device as_mem_12913;
    
    as_mem_12913.references = NULL;
    as_mem_12913 = in0->mem;
    m_9987 = in0->shape[0];
    bs_mem_12914 = in1->mem;
    m_9987 = in1->shape[0];
    exp_res_mem_12915 = in2->mem;
    m_9987 = in2->shape[0];
    if (!(m_9987 == in0->shape[0] && (m_9987 == in1->shape[0] && m_9987 == in2->shape[0]))) {
        ret = 1;
        set_error(ctx, msgprintf("Error: entry point arguments have invalid sizes.\n"));
    }
    if (ret == 0) {
        ret = futrts_entry_big_mul_validation(ctx, &prim_out_13001, as_mem_12913, bs_mem_12914, exp_res_mem_12915, m_9987);
        if (ret == 0) {
            struct memblock_device counters_mem_13188 = ctx->constants->counters_mem_13188;
            struct memblock_device counters_mem_13253 = ctx->constants->counters_mem_13253;
            struct memblock_device id_counter_mem_13014 = ctx->constants->id_counter_mem_13014;
            struct memblock_device id_counter_mem_13017 = ctx->constants->id_counter_mem_13017;
            struct memblock_device id_counter_mem_13080 = ctx->constants->id_counter_mem_13080;
            struct memblock_device id_counter_mem_13083 = ctx->constants->id_counter_mem_13083;
            struct memblock_device id_counter_mem_13202 = ctx->constants->id_counter_mem_13202;
            struct memblock_device id_counter_mem_13258 = ctx->constants->id_counter_mem_13258;
            
            *out0 = prim_out_13001;
        }
    }
    CUDA_SUCCEED_FATAL(cuCtxPopCurrent(&ctx->cu_ctx));
    lock_unlock(&ctx->lock);
    return ret;
}
  
